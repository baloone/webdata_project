{"id":"335444640_Self-Adaptive_Particle_Swarm_Optimization_for_Large-Scale_Feature_Selection_in_Classification","abstract":"3 Many evolutionary computation (EC) methods have been used to solve feature selection problems and they 4 perform well on most small-scale feature selection problems. However, as the dimensionality of feature se-5 lection problems increases, the solution space increases exponentially. Meanwhile, there are more irrelevant 6 features than relevant features in datasets, which leads to many local optima in the huge solution space. 7 Therefore, the existing EC methods still suffer from the problem of stagnation in local optima on large-scale 8 feature selection problems. Furthermore, large-scale feature selection problems with different datasets may 9 have different properties. Thus, it may be of low performance to solve different large-scale feature selection 10 problems with an existing EC method that has only one candidate solution generation strategy (CSGS). In 11 addition, it is time-consuming to find a suitable EC method and corresponding suitable parameter values for 12 a given large-scale feature selection problem if we want to solve it effectively and efficiently. In this article, 13 we propose a self-adaptive particle swarm optimization (SaPSO) algorithm for feature selection, particularly 14 for large-scale feature selection. First, an encoding scheme for the feature selection problem is employed in 15 the SaPSO. Second, three important issues related to self-adaptive algorithms are investigated. After that, the 16 SaPSO algorithm with a typical self-adaptive mechanism is proposed. The experimental results on 12 datasets 17 show that the solution size obtained by the SaPSO algorithm is smaller than its EC counterparts on all datasets. 18 The SaPSO algorithm performs better than its non-EC and EC counterparts in terms of classification accuracy 19 not only on most training sets but also on most test sets. Furthermore, as the dimensionality of the feature se-20 lection problem increases, the advantages of SaPSO become more prominent. This highlights that the SaPSO 21 algorithm is suitable for solving feature selection problems, particularly large-scale feature selection prob-22 lems. Q1 Q2 23","authors":["Yu Xue","Bing Xue","Mengjie Zhang"],"meta":["September 2019ACM Transactions on Knowledge Discovery from Data 13(5):1-27","DOI:10.1145/3340848"],"references":["321344234_Self-adaptive_particle_swarm_optimization_a_review_and_analysis_of_convergence","315498175_A_self-adaptive_arti_cial_bee_colony_algorithm_based_on_global_best_for_global_optimization","319115899_A_Return-Cost-based_Binary_Firefly_Algorithm_for_Feature_Selection","313749844_Particle_swarm_optimization","313706874_Adaptation_in_natural_and_artificial_systems","311448516_Scalable_and_Accurate_Online_Feature_Selection_for_Big_Data","308809400_Effects_of_ensemble_action_selection_with_different_usage_of_player's_memory_resource_on_the_evolution_of_cooperative_strategies_for_iterated_prisoner's_dilemma_game","307800676_How_to_Make_a_Decision_The_Analytic_Hierarchy_Process","305908156_Feature_selection_with_Ant_Colony_Optimization_and_its_applications_for_pattern_recognition_in_space_imagery","305523153_Convex_Sparse_PCA_for_Unsupervised_Feature_Learning","304425270_Differential_Evolution_-_A_Simple_and_Efficient_Heuristic_for_global_Optimization_over_Continuous_Spaces","291954506_Opposition_chaotic_fitness_mutation_based_adaptive_inertia_weight_BPSO_for_feature_selection_in_text_clustering","291078443_CoSelect_Feature_Selection_with_Instance_Selection_for_Social_Media_Data","291017723_Hybrid_Feature_Selection_based_on_Enhanced_Genetic_Algorithm_for_Text_Categorization","286243918_Feature_Selection_for_Social_Media_Data"]}