{"id":"261502915_XKaapi_A_Runtime_System_for_Data-Flow_Task_Programming_on_Heterogeneous_Architectures","abstract":"Most recent HPC platforms have heterogeneous nodes composed of multi-core CPUs and accelerators, like GPUs. Programming such nodes is typically based on a combination of OpenMP and CUDA/OpenCL codes; scheduling relies on a static partitioning and cost model. We present the XKaapi runtime system for data-flow task programming on multi-CPU and multi-GPU architectures, which supports a data-flow task model and a locality-aware work stealing scheduler. XKaapi enables task multi-implementation on CPU or GPU and multi-level parallelism with different grain sizes. We show performance results on two dense linear algebra kernels, matrix product (GEMM) and Cholesky factorization (POTRF), to evaluate XKaapi on a heterogeneous architecture composed of two hexa-core CPUs and eight NVIDIA Fermi GPUs. Our conclusion is two-fold. First, fine grained parallelism and online scheduling achieve performance results as good as static strategies, and in most cases outperform them. This is due to an improved work stealing strategy that includes locality information; a very light implementation of the tasks in XKaapi; and an optimized search for ready tasks. Next, the multi-level parallelism on multiple CPUs and GPUs enabled by XKaapi led to a highly efficient Cholesky factorization. Using eight NVIDIA Fermi GPUs and four CPUs, we measure up to 2.43 TFlop/s on double precision matrix product and 1.79 TFlop/s on Cholesky factorization; and respectively 5.09 TFlop/s and 3.92 TFlop/s in single precision.","authors":["Thierry Gautier","Jo√£o V. F. Lima","Nicolas Maillard","Bruno Raffin"],"meta":["May 2013","DOI:10.1109/IPDPS.2013.66","Conference: Parallel & Distributed Processing (IPDPS), 2013 IEEE 27th International Symposium on"],"references":["261486404_Exploiting_Concurrent_GPU_Operations_for_Efficient_Work_Stealing_on_Multi-GPUs","254463468_A_scalable_framework_for_heterogeneous_GPU-based_clusters","234787466_Solving_dense_linear_systems_on_platforms_with_multiple_hardware_accelerators","224140648_SLAW_A_scalable_locality-aware_adaptive_work-stealing_scheduler","222429664_A_Class_of_Parallel_Tiled_Linear_Algebra_Algorithms_for_Multicore_Architectures","262276063_libKOMP_an_Efficient_OpenMP_Runtime_System_for_Both_Fork-Join_and_Data_Flow_Paradigms","261355859_Productive_Programming_of_GPU_Clusters_with_OmpSs","232806862_Parallelizing_dense_and_banded_linear_algebra_libraries_using_SMPSs","222820605_Towards_dense_linear_algebra_for_hybrid_GPU_accelerated_manycore_systems","221643440_Solving_Dense_Linear_Systems_on_Platforms_with_Multiple_Hardware_Accelerators"]}