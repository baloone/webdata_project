{"id":"259933342_A_Stochastic_Quasi-Newton_Method_for_Large-Scale_Optimization","abstract":"The question of how to incorporate curvature information in stochastic\napproximation methods is challenging. The direct application of classical\nquasi- Newton updating techniques for deterministic optimization leads to noisy\ncurvature estimates that have harmful effects on the robustness of the\niteration. In this paper, we propose a stochastic quasi-Newton method that is\nefficient, robust and scalable. It employs the classical BFGS update formula in\nits limited memory form, and is based on the observation that it is beneficial\nto collect curvature information pointwise, and at regular intervals, through\n(sub-sampled) Hessian-vector products. This technique differs from the\nclassical approach that would compute differences of gradients, and where\ncontrolling the quality of the curvature estimates can be difficult. We present\nnumerical results on problems arising in machine learning that suggest that the\nproposed method shows much promise.","authors":["R. H. Byrd","S. L. Hansen","Jorge Nocedal","Y. Singer"],"meta":["January 2014SIAM Journal on Optimization 26(2)","DOI:10.1137/140954362","SourcearXiv"],"references":["259954350_RES_Regularized_stochastic_BFGS_algorithm","237082619_Non-strongly-convex_smooth_stochastic_approximation_with_convergence_rate_O1n","221618614_The_Tradeoffs_of_Large_Scale_Learning","220416221_Mining_Data_Streams_A_Review","220320677_Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization","220320442_RCV1_A_New_Benchmark_Collection_for_Text_Categorization_Research","220320158_SGD-QN_Careful_Quasi-Newton_Stochastic_Gradient_Descent","220319999_A_Stochastic_Quasi-Newton_Method_for_Online_Convex_Optimization","37146447_A_Stochastic_Approximation_Algorithm_with_Step-Size_Adaptation","2666659_A_Statistical_Study_on_On-line_Learning","265727384_Stochastic_Simulation_Algorithms_and_Analysis","262376970_Parallel_Boosting_with_Momentum","257480049_Sample_Size_Selection_in_Optimization_Methods_for_Machine_Learning","243767297_Springer_Series_in_Operations_Research","236736791_A_Stochastic_Approximation_Method","230873264_Numerical_Optimization_Second_Edition","226174686_On_the_Limited_Memory_BFGS_Method_for_Large_Scale_Optimization","221669733_Practical_Methods_of_Optimization_I","221619092_Topmoumoute_Online_Natural_Gradient_Algorithm","221497515_Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization","221344828_A_fast_natural_Newton_method","220589055_A_Coordinate_Gradient_Descent_Method_for_Nonsmooth_Separable_Minimization","216300613_Practical_Methods_of_Optimization","51893201_On_Stochastic_Gradient_and_Subgradient_Methods_with_Adaptive_Steplength_Sequences","12177687_Adaptive_natural_gradient_learning_algorithms_for_various_stochastic_models","2441527_Convergence_Rate_of_Incremental_Subgradient_Algorithms","2433873_Natural_Gradient_Works_Efficiently_in_Learning"]}