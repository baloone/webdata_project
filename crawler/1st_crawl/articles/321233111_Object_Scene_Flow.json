{"id":"321233111_Object_Scene_Flow","abstract":"This work investigates the estimation of dense three-dimensional motion fields, commonly referred to as scene flow. While great progress has been made in recent years, large displacements and adverse imaging conditions as observed in natural outdoor environments are still very challenging for current approaches to reconstruction and motion estimation. In this paper, we propose a unified random field model which reasons jointly about 3D scene flow as well as the location, shape and motion of vehicles in the observed scene. We formulate the problem as the task of decomposing the scene into a small number of rigidly moving objects sharing the same motion parameters. Thus, our formulation effectively introduces long-range spatial dependencies which commonly employed local rigidity priors are lacking. Our inference algorithm then estimates the association of image segments and object hypotheses together with their three-dimensional shape and motion. We demonstrate the potential of the proposed approach by introducing a novel challenging scene flow benchmark which allows for a thorough comparison of the proposed scene flow approach with respect to various baseline models. In contrast to previous benchmarks, our evaluation is the first to provide stereo and optical flow ground truth for dynamic real-world urban scenes at large scale. Our experiments reveal that rigid motion segmentation can be utilized as an effective regularizer for the scene flow problem, improving upon existing two-frame scene flow methods. At the same time, our method yields plausible object segmentations without requiring an explicitly trained recognition model for a specific object class. Â© 2017 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS).","authors":["Moritz Menze","Christian Heipke","Andreas Geiger"],"meta":["November 2017ISPRS Journal of Photogrammetry and Remote Sensing 140","DOI:10.1016/j.isprsjprs.2017.09.013"],"references":["300412719_Exploiting_Object_Similarity_in_3D_Reconstruction","262219579_A_Quantitative_Analysis_of_Current_Practices_in_Optical_Flow_Estimation_and_The_Principles_Behind_Them","258140919_Vision_meets_robotics_the_KITTI_dataset","222450615_Determining_Optical_Flow","221364039_Multi-View_Scene_Flow_Estimation_A_View_Centered_Variational_Approach","220660141_Energy-Based_Geometric_Multi-model_Fitting","7986042_Three-dimensional_scene_flow","312831234_Stereo_Ground_Truth_with_Error_Bars","308854455_EpicFlow_Edge-preserving_interpolation_of_correspondences_for_optical_flow","308278471_A_Continuous_Optimization_Approach_for_Efficient_and_Accurate_Scene_Flow","307090687_A_Prediction-Correction_Approach_for_Real-Time_Optical_Flow_Computation_Using_Stereo","304604590_Object_scene_flow_for_autonomous_vehicles","300253819_Discrete_Optimization_for_Optical_Flow","290109880_Efficient_Joint_Segmentation_Occlusion_Labeling_Stereo_and_Flow_Estimation","286594310_SphereFlow_6_DoF_scene_flow_from_RGB-D_pairs","276886622_An_Evaluation_of_Data_Costs_for_Optical_Flow","276886264_View-Consistent_3D_Scene_Flow_Estimation_over_Multiple_Frames","276366161_3D_Scene_Flow_Estimation_with_a_Piecewise_Rigid_Scene_Model","271551075_Understanding_High-Level_Semantics_by_Modeling_Traffic_Patterns","268689302_Towards_Scene_Understanding_with_Detailed_3D_Object_Representations","262402347_Piecewise_Rigid_Scene_Flow","257485030_Active_Shape_Models-Their_Training_and_Application","257249132_3D_Traffic_Scene_Understanding_From_Movable_Platforms","256837351_Detailed_3D_Representations_for_Object_Recognition_and_Modeling","220659435_Multi-View_Stereo_Reconstruction_and_Scene_Flow_Estimation_with_a_Global_Image-Based_Matching_Score","45660312_Large_Displacement_Optical_Flow_Descriptor_Matching_in_Variational_Motion_Estimation","6806973_Convergent_Tree-Reweighted_Message_Passing_for_Energy_Minimization","5764827_Hirschmller_H_Stereo_processing_by_semiglobal_matching_and_mutual_information_IEEE_PAMI_302_328-341"]}