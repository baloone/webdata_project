{"id":"321211014_Multichannel_Source_Separation_and_Speech_Enhancement_Using_the_Convolutive_Transfer_Function","abstract":"This paper addresses the problem of audio source recovery from multichannel noisy convolutive mixture for source separation and speech enhancement, assuming known mixing filters. We propose to conduct the source recovery in the short-time Fourier transform domain, and based on the convolutive transfer function (CTF) approximation. Compared to the time domain filters, CTF has much less taps, and thus less near-common zeros among channels and less computational complexity. This work proposes three source recovery methods, i) the multichannel inverse filtering method, i.e. multiple input/output inverse theorem (MINT), is exploited in the CTF domain, and for the multisource case, ii) a beamforming-like multichannel inverse filtering method is proposed appling the single source MINT and power minimization, which is suitable for the case that not the CTFs of all the sources are known, iii) a constrained Lasso method. The sources are recovered by minimizing their $\\ell_1$-norm to impose the spectral sparsity, with the constraint that the $\\ell_2$-norm fitting cost between the microphone signals and the mixture model involving the unknown source signals is less than a tolerance. The noise can be reduced by setting the tolerance to the noise power. Experiments under various acoustic conditions are conducted to evaluate the three proposed methods. The comparison among them and with the baseline methods are presented.","authors":["Xiaofei li","Laurent Girin","Sharon Gannot","Radu Horaud"],"meta":["November 2017IEEE/ACM Transactions on Audio, Speech, and Language Processing PP(99)","DOI:10.1109/TASLP.2019.2892412"],"references":["317949713_Separating_Time-Frequency_Sources_from_Time-Domain_Convolutive_Mixtures_Using_Non-negative_Matrix_Factorization","311617537_Multichannel_audio_source_separation_Variational_inference_of_time-frequency_sources_from_time-domain_observations","309730116_Multiple-Speaker_Localization_Based_on_Direct-Path_Features_and_Likelihood_Maximization_with_Spatial_Sparsity_Regularization","308863917_Estimation_of_Relative_Transfer_Function_in_the_Presence_of_Stationary_Noise_Based_on_Segmental_Power_Spectral_Density_Matrix_Subtraction","327805677_Multisource_Mint_Using_Convolutive_Transfer_Function","321785729_An_em_algorithm_for_audio_source_separation_based_on_the_convolutive_transfer_function","317725190_Audio_source_separation_based_on_convolutive_transfer_function_and_frequency-domain_lasso_optimization","317558814_Blind_MultiChannel_Identification_and_Equalization_for_Dereverberation_and_Noise_Reduction_based_on_Convolutive_Transfer_Function","313312351_Multichannel_Equalization_in_Subbands","311611961_A_Consolidated_Perspective_on_Multi-Microphone_Speech_Enhancement_and_Source_Separation"]}