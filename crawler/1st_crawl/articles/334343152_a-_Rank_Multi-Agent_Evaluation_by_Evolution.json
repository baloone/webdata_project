{"id":"334343152_a-_Rank_Multi-Agent_Evaluation_by_Evolution","abstract":"We introduce α-Rank, a principled evolutionary dynamics methodology, for the evaluation and ranking of agents in large-scale multi-agent interactions, grounded in a novel dynamical game-theoretic solution concept called Markov-Conley chains (MCCs). The approach leverages continuous-time and discrete-time evolutionary dynamical systems applied to empirical games, and scales tractably in the number of agents, in the type of interactions (beyond dyadic), and the type of empirical games (symmetric and asymmetric). Current models are fundamentally limited in one or more of these dimensions, and are not guaranteed to converge to the desired game-theoretic solution concept (typically the Nash equilibrium). α-Rank automatically provides a ranking over the set of agents under evaluation and provides insights into their strengths, weaknesses, and long-term dynamics in terms of basins of attraction and sink components. This is a direct consequence of the correspondence we establish to the dynamical MCC solution concept when the underlying evolutionary model’s ranking-intensity parameter, α, is chosen to be large, which exactly forms the basis of α-Rank. In contrast to the Nash equilibrium, which is a static solution concept based solely on fixed points, MCCs are a dynamical solution concept based on the Markov chain formalism, Conley’s Fundamental Theorem of Dynamical Systems, and the core ingredients of dynamical systems: fixed points, recurrent sets, periodic orbits, and limit cycles. Our α-Rank method runs in polynomial time with respect to the total number of pure strategy profiles, whereas computing a Nash equilibrium for a general-sum game is known to be intractable. We introduce mathematical proofs that not only provide an overarching and unifying perspective of existing continuous- and discrete-time evolutionary evaluation models, but also reveal the formal underpinnings of the α-Rank methodology. We illustrate the method in canonical games and empirically validate it in several domains, including AlphaGo, AlphaZero, MuJoCo Soccer, and Poker.","authors":["Shayegan Omidshafiei","Christos Papadimitriou","Georgios Piliouras","Karl Tuyls"],"meta":["July 2019Scientific Reports 9(1):9937","DOI:10.1038/s41598-019-45619-9"],"references":["337753743_Bounds_and_dynamics_for_empirical_game_theoretic_analysis","321095192_Symmetric_Decomposition_of_Asymmetric_Games","339004553_Multiplicative_Weights_Update_with_Constant_Step-Size_in_Congestion_Games_Convergence_Limit_Cycles_and_Chaos","333227860_The_Exact_Computational_Complexity_of_Evolutionarily_Stable_Strategies","332958478_Game_dynamics_as_the_meaning_of_a_game","331477508_A_Unified_Game-Theoretic_Approach_to_Multiagent_Reinforcement_Learning","331307423_Game_Theory_Evolving_A_Problem-Centered_Introduction_to_Modeling_Strategic_Interaction_-_Second_Edition","329473176_A_general_reinforcement_learning_algorithm_that_masters_chess_shogi_and_Go_through_self-play","323867301_A_Generalised_Method_for_Empirical_Game_Theoretic_Analysis","321180180_Learning_Dynamics_and_the_Co-Evolution_of_Competing_Sexual_Species"]}