{"id":"326729680_Deep_Appearance_Models_for_Face_Rendering","abstract":"We introduce a deep appearance model for rendering the human face. Inspired by Active Appearance Models, we develop a data-driven rendering pipeline that learns a joint representation of facial geometry and appearance from a multiview capture setup. Vertex positions and view-specific textures are modeled using a deep variational autoencoder that captures complex nonlinear effects while producing a smooth and compact latent representation. View-specific texture enables the modeling of view-dependent effects such as specularity. In addition, it can also correct for imperfect geometry stemming from biased or low resolution estimates. This is a significant departure from the traditional graphics pipeline, which requires highly accurate geometry as well as all elements of the shading model to achieve realism through physically-inspired light transport. Acquiring such a high level of accuracy is difficult in practice, especially for complex and intricate parts of the face, such as eyelashes and the oral cavity. These are handled naturally by our approach, which does not rely on precise estimates of geometry. Instead, the shading model accommodates deficiencies in geometry though the flexibility afforded by the neural network employed. At inference time, we condition the decoding network on the viewpoint of the camera in order to generate the appropriate texture for rendering. The resulting system can be implemented simply using existing rendering engines through dynamic textures with flat lighting. This representation, together with a novel unsupervised technique for mapping images to facial states, results in a system that is naturally suited to real-time interactive settings such as Virtual Reality (VR).","authors":["Stephen Lombardi","Jason Saragih","Tomas Simon","Yaser Sheikh"],"meta":["July 2018ACM Transactions on Graphics 37(4):1-13","DOI:10.1145/3197517.3201401"],"references":["322060135_Unpaired_Image-to-Image_Translation_Using_Cycle-Consistent_Adversarial_Networks","320967151_Unsupervised_Pixel-Level_Domain_Adaptation_with_Generative_Adversarial_Networks","320032704_Unsupervised_Learning_of_Disentangled_and_Interpretable_Representations_from_Sequential_Data","315710637_Unpaired_Image-to-Image_Translation_using_Cycle-Consistent_Adversarial_Networks","326079223_FaceVR_Real-Time_Gaze-Aware_Facial_Reenactment_in_Virtual_Reality","321236162_Avatar_digitization_from_a_single_image_for_real-time_rendering","319770229_Auto-Encoding_Variational_Bayes","319770144_Unsupervised_Representation_Learning_with_Deep_Convolutional_Generative_Adversarial_Networks","318717523_Production-level_facial_performance_capture_using_deep_convolutional_neural_networks","316948620_Deep_Feature_Consistent_Variational_Autoencoder"]}