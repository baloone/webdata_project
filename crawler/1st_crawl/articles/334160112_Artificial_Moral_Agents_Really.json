{"id":"334160112_Artificial_Moral_Agents_Really","abstract":"How can we plausibly refer to robots as artificial moral agents? Considering the useful classification of the philosopher of the field of artificial intelligence James H. Moor, who identified four different kinds of ethical, I will argue that the term of artificial moral agent is philosophically illegitimate. My argumentation is developed in three stages: the first stage addresses the actual choice of the ethical principles to be programmed into the machine; the second stage explores the difficulties inherent in giving these principles an algorithmic form; and the third focuses on the supreme difficulty arising from the very nature of moral reasoning. This analysis aims at encouraging the research on the concepts of moral reasoning and judgement. Indeed, a fine understanding of these notions should reveal the full extent of the problem with artificial moral agents; before we can discuss machine ethics or artificial ethics, we must, if we are to avoid speculation and ideology, have a clear understanding of what ethics is, what type of rationality it implements, and what is the nature of ethics and ethical conduct in general.","authors":["Mark Hunyadi"],"meta":["July 2019","DOI:10.1007/978-3-030-17974-8_5","In book: Wording Robotics (pp.59-69)"],"references":["220629129_The_Nature_Importance_and_Difficulty_of_Machine_Ethics","220605213_Machine_Ethics_Creating_an_Ethical_Intelligent_Agent","257931380_Moral_Machines_Teaching_Robots_Right_From_Wrong"]}