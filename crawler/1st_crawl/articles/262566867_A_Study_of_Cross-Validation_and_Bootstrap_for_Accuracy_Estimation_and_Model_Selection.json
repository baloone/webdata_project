{"id":"262566867_A_Study_of_Cross-Validation_and_Bootstrap_for_Accuracy_Estimation_and_Model_Selection","abstract":"We review accuracy estimation methods and compare the two most common methods: crossvalidation and bootstrap. Recent experimental results on arti cial data and theoretical results in restricted settings have shown that for selecting a good classi er from a set of classiers (model selection), ten-fold cross-validation may be better than the more expensive leaveone-out cross-validation. We report on a largescale experiment|over half a million runs of C4.5 and a Naive-Bayes algorithm|to estimate the e ects of di erent parameters on these algorithms on real-world datasets. For crossvalidation, we vary the number of folds and whether the folds are strati ed or not ï¿½ for bootstrap, we vary the number of bootstrap samples. Our results indicate that for real-word datasets similar to ours, the best method to use for model selection is ten-fold strati ed cross validation, even if computation power allows using more folds. 1","authors":["Ron Kohavi"],"meta":["January 1995","Conference: International joint conference on Artificial intelligenceAt: Montreal"],"references":["224378047_Bootstrap_Techniques_for_Error_Estimation","222467943_Stacked_Generalization","221604155_Decision_Tree_Pruning_Biased_or_Optimal","247035706_On_the_Distributional_Properties_of_Model_Selection_Criteria","244446198_UCI_Repository_of_machine_learning_databases_Machine-readable_data_repository","243679109_Estimating_the_Error_Rate_of_a_Prediction_Rule_Improvement_on_Cross-Validation","239064656_Submodel_selection_and_evaluation_in_regression-The_X-random_case","239063723_Linear_Model_Selection_by_Cross-Validation","224839810_An_Introduction_to_the_Boot-Strap","221345735_A_Conservation_Law_for_Generalization_Performance"]}