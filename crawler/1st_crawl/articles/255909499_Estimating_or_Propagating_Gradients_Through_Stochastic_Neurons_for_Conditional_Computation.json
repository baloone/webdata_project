{"id":"255909499_Estimating_or_Propagating_Gradients_Through_Stochastic_Neurons_for_Conditional_Computation","abstract":"Stochastic neurons and hard non-linearities can be useful for a number of\nreasons in deep learning models, but in many cases they pose a challenging\nproblem: how to estimate the gradient of a loss function with respect to the\ninput of such stochastic or non-smooth neurons? I.e., can we \"back-propagate\"\nthrough these stochastic neurons? We examine this question, existing\napproaches, and compare four families of solutions, applicable in different\nsettings. One of them is the minimum variance unbiased gradient estimator for\nstochatic binary neurons (a special case of the REINFORCE algorithm). A second\napproach, introduced here, decomposes the operation of a binary stochastic\nneuron into a stochastic binary part and a smooth differentiable part, which\napproximates the expected effect of the pure stochatic binary neuron to first\norder. A third approach involves the injection of additive or multiplicative\nnoise in a computational graph that is otherwise differentiable. A fourth\napproach heuristically copies the gradient with respect to the stochastic\noutput directly as an estimator of the gradient with respect to the sigmoid\nargument (we call this the straight-through estimator). To explore a context\nwhere these estimators are useful, we consider a small-scale version of {\\em\nconditional computation}, where sparse stochastic units form a distributed\nrepresentation of gaters that can turn off in combinatorially many ways large\nchunks of the computation performed in the rest of the neural network. In this\ncase, it is important that the gating units produce an actual 0 most of the\ntime. The resulting sparsity can be potentially be exploited to greatly reduce\nthe computational cost of large deep networks for which conditional computation\nwould be useful.","authors":["Y. Bengio","Nicholas LÃ©onard","Aaron Courville"],"meta":["August 2013","SourcearXiv"],"references":["236597372_Deep_Learning_of_Representations_Looking_Forward","235639035_Maxout_Networks","228102719_Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors","221346269_Extracting_and_composing_robust_features_with_denoising_autoencoders","215616967_Deep_Sparse_Rectifier_Neural_Networks","6879150_Gradient_Learning_in_Spiking_Neural_Networks_by_Dynamic_Perturbation_of_Conductances","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","300939445_Reinforcement_Comparison","279964320_Simple_statistical_gradient-following_algorithms_for_connectionist_reinforcement_learning","267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks","265414448_Multivariate_Stochastic_Approximation_Using_a_Simultaneous_Perturbation_Gradient_Approximation","239574281_Boltzmann_machines_Constraint_satisfaction_networks_that_learn","234108854_The_Optimal_Reward_Baseline_for_Gradient-Based_Reinforcement_Learning","229091480_Learning_Representations_by_Back_Propagating_Errors","221345737_Rectified_Linear_Units_Improve_Restricted_Boltzmann_Machines_Vinod_Nair","220554980_Semantic_hashing","3021008_Multivariate_stochastic_approximation_using_a_simultaneous_perturbation_gradient_approximation","2818396_Hierarchical_Recurrent_Neural_Networks_for_Long-Term_Dependencies"]}