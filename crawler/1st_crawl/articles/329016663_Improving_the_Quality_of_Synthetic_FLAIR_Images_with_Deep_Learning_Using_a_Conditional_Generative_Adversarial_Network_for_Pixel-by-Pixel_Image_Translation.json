{"id":"329016663_Improving_the_Quality_of_Synthetic_FLAIR_Images_with_Deep_Learning_Using_a_Conditional_Generative_Adversarial_Network_for_Pixel-by-Pixel_Image_Translation","abstract":"BACKGROUND AND PURPOSE: Synthetic FLAIR images are of lower quality than conventional FLAIR images. Here, we aimed to improve the synthetic FLAIR image quality using deep learning with pixel-by-pixel translation through conditional generative adversarial network training.\n\nMATERIALS AND METHODS: Forty patients with MS were prospectively included and scanned (3T) to acquire synthetic MR imaging and conventional FLAIR images. Synthetic FLAIR images were created with the SyMRI software. Acquired data were divided into 30 training and 10 test datasets. A conditional generative adversarial network was trained to generate improved FLAIR images from raw synthetic MR imaging data using conventional FLAIR images as targets. The peak signal-to-noise ratio, normalized root mean square error, and the Dice index of MS lesion maps were calculated for synthetic and deep learning FLAIR images against conventional FLAIR images, respectively. Lesion conspicuity and the existence of artifacts were visually assessed.\n\nRESULTS: The peak signal-to-noise ratio and normalized root mean square error were significantly higher and lower, respectively, in generated-versus-synthetic FLAIR images in aggregate intracranial tissues and all tissue segments (all P < .001). The Dice index of lesion maps and visual lesion conspicuity were comparable between generated and synthetic FLAIR images (P = 1 and .59, respectively). Generated FLAIR images showed fewer granular artifacts (P = .003) and swelling artifacts (in all cases) than synthetic FLAIR images.\n\nCONCLUSIONS: Using deep learning, we improved the synthetic FLAIR image quality by generating FLAIR images that have contrast closer to that of conventional FLAIR images and fewer granular and swelling artifacts, while preserving the lesion contrast.","authors":["Akifumi Hagiwara","Yujiro Otsuka","Masaaki Hori","Yasuhiko Tachibana"],"meta":["February 2019American Journal of Neuroradiology 40(2):224-230","DOI:10.3174/ajnr.A5927","Project: Synthetic MRI"],"references":["326655363_Linearity_Bias_Intra-Scanner_Repeatability_and_Inter-Scanner_Reproducibility_of_Quantitative_Multi-Dynamic_Multi-Echo_Sequence_for_Rapid_Simultaneous_Relaxometry_at_3T_A_Validation_Study_with_a_Standa","320698719_The_Advantage_of_Synthetic_MRI_for_the_Visualization_of_Anterior_Temporal_Pole_Lesions_by_Double_Inversion_recovery_DIR_Phase-Sensitive_Inversion_Recovery_PSIR_and_Myelin_Images_in_a_Patient_with_CADA","318888409_Analysis_of_White_Matter_Damage_in_Patients_with_Multiple_Sclerosis_via_a_Novel_In_Vivo_MR_Method_for_Measuring_Myelin_Axons_and_G-Ratio","324967501_Improving_Resolution_of_MR_images_with_an_Adversarial_Network_Incorporating_Images_with_Different_Contrast","324265863_MR_fingerprinting_deep_reconstruction_network_DRONE_COHEN_et_al","323914410_3D_conditional_generative_adversarial_networks_for_high-quality_PET_image_estimation_at_low_dose","323496361_Deep_learning_with_convolutional_neural_network_in_radiology","319770355_Generative_Adversarial_Nets","319268855_Deep_neural_network-based_computer-assisted_detection_of_cerebral_aneurysms_in_MR_angiography","317201852_Generative_Adversarial_Networks_for_Noise_Reduction_in_Low-Dose_CT"]}