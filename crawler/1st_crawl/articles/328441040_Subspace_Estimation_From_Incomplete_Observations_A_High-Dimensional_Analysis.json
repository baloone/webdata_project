{"id":"328441040_Subspace_Estimation_From_Incomplete_Observations_A_High-Dimensional_Analysis","abstract":"We present a high-dimensional analysis of three popular algorithms, namely, Oja's method, GROUSE and PETRELS, for subspace estimation from streaming and highly incomplete observations. We show that, with proper time scaling, the time-varying principal angles between the true subspace and its estimates given by the algorithms converge weakly to deterministic processes when the ambient dimension\n$n$ \ntends to infinity. Moreover, the limiting processes can be exactly characterized as the unique solutions of certain ordinary differential equations (ODEs). A finite sample bound is also given, showing that the rate of convergence towards such limits is\n$\\mathcal{O}(1/\\sqrt{n})$ \n. In addition to providing asymptotically exact predictions of the dynamic performance of the algorithms, our high-dimensional analysis yields several insights, including an asymptotic equivalence between Oja's method and GROUSE, and a precise scaling relationship linking the amount of missing data to the signal-to-noise ratio. By analyzing the solutions of the limiting ODEs, we also establish phase transition phenomena associated with the steady-state performance of these techniques.","authors":["Chuang Wang","Yonina Eldar","Yue M. Lu"],"meta":["October 2018IEEE Journal of Selected Topics in Signal Processing PP(99):1-1","DOI:10.1109/JSTSP.2018.2877405"],"references":["321768393_Scaling_Limit_Exact_and_Tractable_Analysis_of_Online_Learning_Algorithms_with_Applications_to_Regularized_Regression_and_PCA","308786147_Convergence_of_a_Grassmannian_Gradient_Descent_Algorithm_for_Subspace_Estimation_From_Undersampled_Data","301844935_An_Improved_Gap-Dependency_Analysis_of_the_Noisy_Power_Method","279310281_Global_Convergence_of_a_Grassmannian_Gradient_Descent_Algorithm_for_Subspace_Estimation","247760913_The_Angle_Between_Subspaces_of_a_Hilbert_Space","230569064_PETRELS_Parallel_Subspace_Estimation_and_Tracking_by_Recursive_LeastSquares_from_Partial_Observations","228912364_The_Angle_Between_Complementary_Subspaces","216637120_Solutions_of_Ordinary_Differential_Equations_as_Limits_of_Pure_Jump_Markov_Processes","3027980_Analysis_of_recursive_stochastic_algorithms","326565199_Streaming_PCA_and_Subspace_Tracking_The_Missing_Data_Case","321067253_First_Efficient_Convergence_for_Streaming_k-PCA_A_Global_Gap-Free_and_Near-Optimal_Rate","320442312_The_Scaling_Limit_of_High-Dimensional_Online_Independent_Component_Analysis","309498868_Online_Learning_for_Sparse_PCA_in_High_Dimensions_Exact_Dynamics_and_Phase_Transitions","308824403_Online_matrix_completion_and_online_robust_PCA","306173009_Subspace_learning_with_partial_information","303545269_Provable_Efficient_Online_Matrix_Completion_via_Non-convex_Stochastic_Gradient_Descent","301844923_Streaming_PCA_Matching_Matrix_Bernstein_and_Near-Optimal_Finite_Sample_Guarantees_for_Oja's_Algorithm","301839900_Near-Optimal_Stochastic_Approximation_for_Online_Principal_Component_Estimation","286687323_The_noisy_power_method_A_meta_algorithm_with_applications","282403342_Convergence_of_Stochastic_Gradient_Descent_for_PCA","273471701_Online_Matrix_Completion_and_Online_Robust_PCA","270905679_The_Fast_Convergence_of_Incremental_PCA","243963661_Memory_limited_streaming_PCA","239666534_Topics_in_propagation_of_chaos","239066678_Limit_Theorems_for_Stochastic_Processes","237843093_Local_Convergence_of_an_Algorithm_for_Subspace_Identification_from_Partial_Data","236203779_Low-Rank_Matrix_and_Tensor_Completion_via_Adaptive_Sampling","227424198_A_propagation_of_chaos_result_for_a_system_of_particles_with_moderate_interaction","227101649_Exact_Matrix_Completion_via_Convex_Optimization","226965853_Simplified_neuron_model_as_a_principal_component_analyzer","224216535_Online_Identification_and_Tracking_of_Subspaces_from_Highly_Incomplete_Information","222896634_Asymptotic_convergence_analysis_of_the_projection_approximation_subspace_tracking_algorithms","3315295_Projection_Approximation_Subspace_Tracking"]}