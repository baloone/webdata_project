{"id":"303749956_OpenSalicon_An_Open_Source_Implementation_of_the_Salicon_Saliency_Model","abstract":"In this technical report, we present our publicly downloadable implementation of the SALICON saliency model. At the time of this writing, SALICON is one of the top performing saliency models on the MIT 300 fixation prediction dataset which evaluates how well an algorithm is able to predict where humans would look in a given image. Recently, numerous models have achieved state-of-the-art performance on this benchmark, but none of the top 5 performing models (including SALICON) are available for download. To address this issue, we have created a publicly downloadable implementation of the SALICON model. It is our hope that our model will engender further research in visual attention modeling by providing a baseline for comparison of other algorithms and a platform for extending this implementation. The model we provide supports both training and testing, enabling researchers to quickly fine-tune the model on their own dataset. We also provide a pre-trained model and code for those users who only need to generate saliency maps for images without training their own model.","authors":["Christopher Thomas"],"meta":["June 2016"],"references":["264979485_Caffe_Convolutional_Architecture_for_Fast_Feature_Embedding","259961066_Predicting_human_gaze_beyond_pixels","319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition","300412448_SALICON_Reducing_the_Semantic_Gap_in_Saliency_Prediction_by_Adapting_Deep_Neural_Networks","265385906_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition"]}