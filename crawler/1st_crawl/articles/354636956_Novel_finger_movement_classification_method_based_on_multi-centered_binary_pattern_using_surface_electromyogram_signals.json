{"id":"354636956_Novel_finger_movement_classification_method_based_on_multi-centered_binary_pattern_using_surface_electromyogram_signals","abstract":"A R T I C L E I N F O Keywords: Multi-centered binary pattern (MCBP) Surface electromyogram (sEMG) Finger movements classification Machine learning A B S T R A C T The number of individuals who have lost their fingers in our world is quite high and these individuals experience great difficulties in performing their daily work. Finger movements classification and prediction are one of the hot-topic research areas for biomedical engineering, machine learning and computer sciences. This study purposes finger movements classification and prediction. For this purpose, a novel finger movements classification method is presented by using surface electromyogram (sEMG) signals. To accurately classify these movements, a novel binary pattern like textural feature extractor is presented and this textural micro pattern is called as multi-centered binary pattern (MCBP). In the MCBP, five odd-indexed values of a block are utilized as center. The proposed MCBP based multileveled finger movements classification method evaluate by three cases. In the first case, the raw sEMG signals are utilized as input. In the second and third case, sEMG signals are divided into frames and these frames are utilized as input. A two-layered feature selector is used to choose the most valuable features. The purpose of using these two feature selectors together is to choose the optimum number of features. In the classification phase, two fine-tuned classifiers have been used and they are k-nearest neighbor (k-NN) and support vector machine (SVM). The proposed MCBP based method achieved 99.17%, 99.70% and 99.62% classification rates using SVM classifier according to Case 1, Case 2 and Case3 respectively. The results show that the study is a highly accurate method.","authors":["Turker Tuncer","Sengul Dogan","Abdulhamit Subasi"],"meta":["January 2022Biomedical Signal Processing and Control 71(Part A):103153","DOI:10.1016/j.bspc.2021.103153","Project: sEMG based man–machine interaction—A Platform for Classification of Myoelectric Signals for Prosthesis Control"],"references":["340928687_Surface_EMG_signal_classification_using_TQWT_Bagging_and_Boosting_for_hand_movement_recognition","339975443_Finger_Movement_Classification_Based_on_Statistical_and_Frequency_Features_Extracted_from_Surface_EMG_Signals","338813302_A_Wearable_and_Wirelessly_Powered_System_for_Multiple_Finger_Tracking","338582027_Deep_learning_approach_to_control_of_prosthetic_hands_with_electromyography_signals","340357071_Surface_EMG_signal_classification_using_ternary_pattern_and_discrete_wavelet_transform_based_feature_extraction_for_hand_movement_recognition","339044903_Classification_of_human_hand_movements_based_on_EMG_signals_using_nonlinear_dimensionality_reduction_and_data_fusion_techniques","338972067_Enhanced_EEG-EMG_coherence_analysis_based_on_hand_movements","338151668_EMG_Signals_based_Human_Action_Recognition_via_Deep_Belief_Networks","337659346_Novel_dynamic_center_based_binary_and_ternary_pattern_network_using_M4_pooling_for_real_world_voice_recognition","335990949_An_experimental_study_on_upper_limb_position_invariant_EMG_signal_classification_based_on_deep_neural_network"]}