{"id":"265471265_Automated_essay_scoring_and_the_future_of_educational_assessment_in_medical_education","abstract":"Context: \nConstructed-response tasks, which range from short-answer tests to essay questions, are included in assessments of medical knowledge because they allow educators to measure students' ability to think, reason, solve complex problems, communicate and collaborate through their use of writing. However, constructed-response tasks are also costly to administer and challenging to score because they rely on human raters. One alternative to the manual scoring process is to integrate computer technology with writing assessment. The process of scoring written responses using computer programs is known as 'automated essay scoring' (AES).\n\nMethods: \nAn AES system uses a computer program that builds a scoring model by extracting linguistic features from a constructed-response prompt that has been pre-scored by human raters and then, using machine learning algorithms, maps the linguistic features to the human scores so that the computer can be used to classify (i.e. score or grade) the responses of a new group of students. The accuracy of the score classification can be evaluated using different measures of agreement.\n\nResults: \nAutomated essay scoring provides a method for scoring constructed-response tests that complements the current use of selected-response testing in medical education. The method can serve medical educators by providing the summative scores required for high-stakes testing. It can also serve medical students by providing them with detailed feedback as part of a formative assessment process.\n\nConclusions: \nAutomated essay scoring systems yield scores that consistently agree with those of human raters at a level as high, if not higher, as the level of agreement among human raters themselves. The system offers medical educators many benefits for scoring constructed-response tasks, such as improving the consistency of scoring, reducing the time required for scoring and reporting, minimising the costs of scoring, and providing students with immediate feedback on constructed-response tasks.","authors":["Mark J Gierl","Syed Latifi","Hollis Lai","Andr√© Boulais"],"meta":["October 2014Medical Education 48(10)","DOI:10.1111/medu.12517"],"references":["286557045_Focuson_formative_feedback","232458848_The_Effects_of_Feedback_Interventions_on_Performance_A_Historical_Review_a_Meta-Analysis_and_a_Preliminary_Feedback_Intervention_Theory","220637892_A_survey_on_feature_extraction_for_pattern_recognition","220017728_Focus_on_Formative_Feedback","200111340_Speech_and_Language_Processing_An_Introduction_to_Natural_Language_Processing_Computational_Linguistics_and_Speech_Recognition","49610031_How_the_Internet_Will_Help_Large-Scale_Assessment_Reinvent_Itself","44836144_Inside_the_Black_Box_Raising_Standards_Through_Classroom_Assessment","2624239_Sequential_Minimal_Optimization_A_Fast_Algorithm_for_Training_Support_Vector_Machines","342183905_A_Coefficient_of_Agreement_for_Nominal_Scales","331563221_Automated_evaluation_of_discourse_coherence_quality_in_essay_writing","313430456_Assessment_and_classroom_learning","312458009_Introduction_to_automated_essay_scoring","308468610_Speech_and_language_processing_An_introduction_to_natural_language_processing_computational_linguistics_and_speech_recognition","296028248_Applied_Natural_Language_Processing_Identification_Investigation_and_Resolution","288962564_LightSIDE_Open_source_machine_learning_for_text","285641086_The_e-raterR_automated_essay_scoring_system","284072023_Test_development","283923791_Contrasting_state-of-the-art_automated_scoring_of_essays","282799175_Automated_Essay_Scoring_Writing_Assessment_and_Instruction","266196025_Linear_Models_for_Optimal_Test_Design","262258948_Elements_of_Adaptive_Testing","256980514_Automated_scoring_and_annotation_of_essays_with_the_Intelligent_Essay_Assessor","256980419_Implementation_and_Applications_of_the_Intelligent_Essay_Assessor","256980213_Automated_scoring_and_annotation_of_essays_with_the_Intelligent_Essay_Assessor","245566910_Automated_Essay_Scoring_A_Cross-Disciplinary_Perspective","239060594_The_computer_moves_into_essay_grading_Updating_the_ancient_test","233067274_Assessment_and_Classroom_Learning","220017685_The_Imminence_of_Grading_Essays_by_Computer","220017506_A_Coefficient_of_Agreement_For_Nominal_Scales","200110749_A_Coefficient_of_Agreement_for_Nominal_Scales","29469094_Formative_Assessment_and_the_Design_of_Instructional_Systems","28798514_An_Overview_of_Automated_Scoring_of_Essays","22310512_The_Measurement_Of_Observer_Agreement_For_Categorical_Data","7857005_Understanding_Interobserver_Agreement_The_Kappa_Statistic"]}