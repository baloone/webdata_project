{"id":"324717586_Fully_Convolutional_Adaptation_Networks_for_Semantic_Segmentation","abstract":"The recent advances in deep neural networks have convincingly demonstrated high capability in learning vision models on large datasets. Nevertheless, collecting expert labeled datasets especially with pixel-level annotations is an extremely expensive process. An appealing alternative is to render synthetic data (e.g., computer games) and generate ground truth automatically. However, simply applying the models learnt on synthetic images may lead to high generalization error on real images due to domain shift. In this paper, we facilitate this issue from the perspectives of both visual appearance-level and representation-level domain adaptation. The former adapts source-domain images to appear as if drawn from the \"style\" in the target domain and the latter attempts to learn domain-invariant representations. Specifically, we present Fully Convolutional Adaptation Networks (FCAN), a novel deep architecture for semantic segmentation which combines Appearance Adaptation Networks (AAN) and Representation Adaptation Networks (RAN). AAN learns a transformation from one domain to the other in the pixel space and RAN is optimized in an adversarial learning manner to maximally fool the domain discriminator with the learnt source and target representations. Extensive experiments are conducted on the transfer from GTA5 (game videos) to Cityscapes (urban street scenes) on semantic segmentation and our proposal achieves superior results when comparing to state-of-the-art unsupervised adaptation techniques. More remarkably, we obtain a new record: mIoU of 47.5% on BDDS (drive-cam videos) in an unsupervised setting.","authors":["Yiheng Zhang","Zhaofan Qiu","Ting Yao","Dong Liu"],"meta":["April 2018"],"references":["305196650_Going_deeper_with_convolutions","302305068_Multi-Scale_Context_Aggregation_by_Dilated_Convolutions","301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding","288714023_Learning_Transferrable_Knowledge_for_Semantic_Segmentation_with_Deep_Convolutional_Neural_Network","265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge","264979485_Caffe_Convolutional_Architecture_for_Fast_Feature_Embedding","322060416_Boosting_Image_Captioning_with_Attributes","320968233_RefineNet_Multi-path_Refinement_Networks_for_High-Resolution_Semantic_Segmentation","320968206_Pyramid_Scene_Parsing_Network","320252862_Learning_Deep_Spatio-Temporal_Dependency_for_Semantic_Video_Segmentation","319770355_Generative_Adversarial_Nets","319770331_ParseNet_Looking_Wider_to_See_Better","319770168_Fully_Convolutional_Networks_for_Semantic_Segmentation","319769911_Faster_R-CNN_Towards_Real-Time_Object_Detection_with_Region_Proposal_Networks","319646709_Simultaneous_Deep_Transfer_Across_Domains_and_Tasks","319501512_Squeeze-and-Excitation_Networks","313845134_Adversarial_Discriminative_Domain_Adaptation","311610841_Image_Style_Transfer_Using_Convolutional_Neural_Networks","308850633_From_image-level_to_pixel-level_labeling_with_Convolutional_Networks","308191670_Zoom_Better_to_See_Clearer_Human_and_Object_Parsing_with_Hierarchical_Auto-Zoom_Net","307831241_Semi-supervised_Domain_Adaptation_with_Subspace_Learning_for_visual_recognition","305994826_Playing_for_Data_Ground_Truth_from_Computer_Games","303812083_DeepLab_Semantic_Image_Segmentation_with_Deep_Convolutional_Nets_Atrous_Convolution_and_Fully_Connected_CRFs","300412742_Weakly-and_Semi-Supervised_Learning_of_a_Deep_Convolutional_Network_for_Semantic_Image_Segmentation","286512696_Deep_Residual_Learning_for_Image_Recognition","284219466_Return_of_Frustratingly_Easy_Domain_Adaptation","275669302_Fast_r-cnn","273157570_BoxSup_Exploiting_Bounding_Boxes_to_Supervise_Convolutional_Networks_for_Semantic_Segmentation","272194892_Learning_Transferable_Features_with_Deep_Adaptation_Networks","265385906_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition","263002356_Microsoft_COCO_Common_Objects_in_Context"]}