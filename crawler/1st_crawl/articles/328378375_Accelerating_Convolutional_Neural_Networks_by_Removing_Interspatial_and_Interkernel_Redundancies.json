{"id":"328378375_Accelerating_Convolutional_Neural_Networks_by_Removing_Interspatial_and_Interkernel_Redundancies","abstract":"Recently, the high computational resource demands of convolutional neural networks (CNNs) have hindered a wide range of their applications. To solve this problem, many previous works attempted to reduce the redundant calculations during the evaluation of CNNs. However, these works mainly focused on either interspatial or interkernel redundancy. In this paper, we further accelerate existing CNNs by removing both types of redundancies. First, we convert interspatial redundancy into interkernel redundancy by decomposing one convolutional layer to one block that we design. Then, we adopt rank-selection and pruning methods to remove the interkernel redundancy. The rank-selection method, which considerably reduces manpower, contributes to determining the number of kernels to be pruned in the pruning method. We apply a layer-wise training algorithm rather than the traditional end-to-end training to overcome the difficulty of convergence. Finally, we fine-tune the entire network to achieve better performance. Our method is applied on three widely used datasets of an image classification task. We achieve better results in terms of accuracy and compression rate compared with previous state-of-the-art methods.","authors":["Linghua Zeng","Xinmei Tian"],"meta":["October 2018IEEE Transactions on Cybernetics PP(99):1-13","DOI:10.1109/TCYB.2018.2873762"],"references":["310610589_Learning_the_Number_of_Neurons_in_Deep_Networks","307536925_Pruning_Filters_for_Efficient_ConvNets","305196650_Going_deeper_with_convolutions","303409435_Residual_Networks_Behave_Like_Ensembles_of_Relatively_Shallow_Networks","280329902_Data-free_Parameter_Pruning_for_Deep_Neural_Networks","275669366_PerforatedCNNs_Acceleration_through_Elimination_of_Redundant_Convolutions","269935399_Speeding-up_Convolutional_Neural_Networks_Using_Fine-tuned_CP-Decomposition","265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge","215616968_Understanding_the_difficulty_of_training_deep_feedforward_neural_networks","2441749_Optimal_Brain_Damage","320632983_Layer-Wise_Training_to_Create_Efficient_Convolutional_Neural_Networks","319770387_Deep_Sparse_Rectifier_Neural_Networks","319770367_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation","319770343_Predicting_Parameters_in_Deep_Learning","319770252_TensorFlow_Large-Scale_Machine_Learning_on_Heterogeneous_Distributed_Systems","319770191_FitNets_Hints_for_Thin_Deep_Nets","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","319770146_Second_Order_Derivatives_for_Network_Pruning_Optimal_Brain_Surgeon","319770132_Dynamic_Network_Surgery_for_Efficient_DNNs","319770109_Fast_ConvNets_Using_Group-wise_Brain_Damage","319769909_Distilling_the_Knowledge_in_a_Neural_Network","318830415_Classification_and_Representation_Joint_Learning_via_Deep_Networks","315773376_Ultrasound_Standard_Plane_Detection_Using_a_Composite_Neural_Network_Framework","310610828_Pruning_Convolutional_Neural_Networks_for_Resource_Efficient_Transfer_Learning","309605839_Multi-view_Convolutional_Neural_Networks_for_Multi-document_Extractive_Summarization","306218037_Learning_multiple_layers_of_features_from_tiny_images","301835574_Training_CNNs_with_Low-Rank_Filters_for_Efficient_Image_Classification","286794765_Dropout_A_Simple_Way_to_Prevent_Neural_Networks_from_Overfitting","286512696_Deep_Residual_Learning_for_Image_Recognition","286271944_On_the_importance_of_initialization_and_momentum_in_deep_learning","285648386_Rethinking_the_Inception_Architecture_for_Computer_Vision","284476399_Compression_of_Deep_Convolutional_Neural_Networks_for_Fast_and_Low_Power_Mobile_Applications","284218991_Convolutional_neural_networks_with_low-rank_regularization","277959043_Learning_both_Weights_and_Connections_for_Efficient_Neural_Networks","277334635_Accelerating_Very_Deep_Convolutional_Networks_for_Classification_and_Detection","270705723_Fully_Connected_Cascade_Artificial_Neural_Network_Architecture_for_Attention_Deficit_Hyperactivity_Disorder_Classification_From_Functional_Magnetic_Resonance_Imaging_Data","269935079_Adam_A_Method_for_Stochastic_Optimization","269117228_Convolutional_Neural_Networks_at_Constrained_Time_Cost","265385906_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition","262380602_Speeding_up_Convolutional_Neural_Networks_with_Low_Rank_Expansions","257599662_Radial_Basis_Function_Based_Neural_Network_for_Motion_Detection_in_Dynamic_Scenes","242554268_The_Organization_of_Behavior","237148034_Lateral_Inhibition_Pyramidal_Neural_Network_for_Image_Classification","237000567_Predicting_Parameters_in_Deep_Learning","229091480_Learning_Representations_by_Back_Propagating_Errors","23253323_80_Million_Tiny_Images_A_Large_Data_Set_for_Nonparametric_Object_and_Scene_Recognition","7017915_A_Fast_Learning_Algorithm_for_Deep_Belief_Nets"]}