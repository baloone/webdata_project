{"id":"334960552_Neural_networks_with_focus_on_image_recognition_Neurale_netvaerk_med_fokus_pa_billedgenkendelse","abstract":"The aim of this paper is to describe convolutional neural networks in relation to image recognition and classification. In particular, the theory behind CNNs will be examined in depth — with tensors, opti-mization, convolution, gradients and transformation as the mathematical motive, and hyperparameters, learning theory and coding as the computer science perspective. Moreover, a gradient theorem will be proved by mathematical deduction.\nThe optimization task of training a CNN will be investigated and explained in mathematical terms. The same applies to the task of making a computer train and recognise images with graphical examples.\nThe operational and structural principles of a convolutional layer will be discovered and analysed by programming a simple model using Python. This programme will only contain a layer function which can create n layers with different hyperparameters. The output of the layer will then be analysed to further understand what goes on in a convolutional layer. Through this experiment, it is shown that the kernel/filter plays a crucial role in convolution, as it is what transforms the image input into more abstract and focused feature maps.\nThe effect of hyperparameters, such as the learning rate, network depth, batch size and activation, will be examined further by looking at a variation of CNNs: the DenseNet — programmed in Python based on the ML libraries Keras and TensorFlow. The research shows that precision is a logarithmically growing function in relation to epochs (which converges toward 100 % precision), whereas the loss is a logarithmically decreasing function. A method of cross-over augmentation, using genetic algorithms to assist neural networks, will also be discovered.\nFinally, the image recognition with CNNs will be set in relation to other technologies and the perfor-mance evaluated. Conclusionally, all major points will be summed up.","authors":["Sebastian Winkelmann"],"meta":["December 2018","Project: Studieretningsprojekt 2018"],"references":["281033482_A_Comparison_between_Multi-Layer_Perceptrons_and_Convolutional_Neural_Networks_for_Text_Image_Super-Resolution","277411157_Deep_Learning","264197576_scikit-image_Image_processing_in_Python","326084761_Pro_Machine_Learning_Algorithms","316613582_A_comparison_study_between_MLP_and_Convolutional_Neural_Network_models_for_character_recognition","301453216_A_Continuum_among_Logarithmic_Linear_and_Exponential_Functions_and_Its_Potential_to_Improve_Generalization_in_Neural_Networks","274041803_Projections_onto_translation-invariant_subspaces_of","272837232_Human-level_control_through_deep_reinforcement_learning","267665795_Understanding_machine_learning_From_theory_to_algorithms"]}