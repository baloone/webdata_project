{"id":"328773481_Variable_generalization_performance_of_a_deep_learning_model_to_detect_pneumonia_in_chest_radiographs_A_cross-sectional_study","abstract":"BACKGROUND:There is interest in using convolutional neural networks (CNNs) to analyze medical imaging to provide computer-aided diagnosis (CAD). Recent work has suggested that image classification CNNs may not generalize to new data as well as previously believed. We assessed how well CNNs generalized across three hospital systems for a simulated pneumonia screening task. METHODS AND FINDINGS:A cross-sectional design with multiple model training cohorts was used to evaluate model generalizability to external sites using split-sample validation. A total of 158,323 chest radiographs were drawn from three institutions: National Institutes of Health Clinical Center (NIH; 112,120 from 30,805 patients), Mount Sinai Hospital (MSH; 42,396 from 12,904 patients), and Indiana University Network for Patient Care (IU; 3,807 from 3,683 patients). These patient populations had an age mean (SD) of 46.9 years (16.6), 63.2 years (16.5), and 49.6 years (17) with a female percentage of 43.5%, 44.8%, and 57.3%, respectively. We assessed individual models using the area under the receiver operating characteristic curve (AUC) for radiographic findings consistent with pneumonia and compared performance on different test sets with DeLong's test. The prevalence of pneumonia was high enough at MSH (34.2%) relative to NIH and IU (1.2% and 1.0%) that merely sorting by hospital system achieved an AUC of 0.861 (95% CI 0.855-0.866) on the joint MSH-NIH dataset. Models trained on data from either NIH or MSH had equivalent performance on IU (P values 0.580 and 0.273, respectively) and inferior performance on data from each other relative to an internal test set (i.e., new data from within the hospital system used for training data; P values both","authors":["John R. Zech","Marcus Badgeley","Manway Liu","Anthony B. Costa"],"meta":["November 2018PLoS Medicine 15(11):e1002683","DOI:10.1371/journal.pmed.1002683"],"references":["321160832_Detecting_hip_fractures_with_radiologist-level_performance_using_deep_neural_networks","321095969_CheXNet_Radiologist-Level_Pneumonia_Detection_on_Chest_X-Rays_with_Deep_Learning","319770123_Densely_Connected_Convolutional_Networks","318067410_CONSORT_2010_statement_Extension_checklist_for_reporting_within_person_randomised_trials","316740882_ChestX-Ray8_Hospital-Scale_Chest_X-Ray_Database_and_Benchmarks_on_Weakly-Supervised_Classification_and_Localization_of_Common_Thorax_Diseases","323373904_Identifying_Medical_Diagnoses_and_Treatable_Diseases_by_Image-Based_Deep_Learning","322948555_MABAL_a_Novel_Deep-Learning_Architecture_for_Machine-Assisted_Bone_Age_Labeling","322810991_Natural_Language-based_Machine_Learning_Models_for_the_Annotation_of_Clinical_Radiology_Reports","321755280_Development_and_Validation_of_a_Deep_Learning_System_for_Diabetic_Retinopathy_and_Related_Eye_Diseases_Using_Retinal_Images_From_Multiethnic_Populations_With_Diabetes","318575915_Unintended_Consequences_of_Machine_Learning_in_Medicine"]}