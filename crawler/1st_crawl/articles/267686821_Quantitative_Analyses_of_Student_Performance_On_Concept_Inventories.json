{"id":"267686821_Quantitative_Analyses_of_Student_Performance_On_Concept_Inventories","abstract":"This paper reports statistical and psychometric analyses that were part of an overall principled approach to designing concept inventories (CIs) using evidentiary arguments about claims that can be made about what students know and can do. An evidence-centered design (ECD) framework (Mislevy, Almond, & Lukas, 2004) was applied to a pre-existing CI, the Thermal and Transport Concept Inventory (TTCI), to demonstrate a principled approach to assessment design by multidisciplinary team including engineering content experts, engineering education researchers, cognitive scientists, and educational measurement experts. This process consists of an iterative design cycle and can be seen as directly related to the assessment triangle, a model for reasoning from assessment evidence (Pellegrino et al., 2001). Developing an ECD domain framework and design template provides a foundation for linking all three vertices of the assessment triangle: (a) the domain framework provides a reasoned argument for specifying important focal knowledge (FK) to be the target of assessment; (b) the Q matrix coding (see Denick et al., 2014) and scoring rules is represented by the interpretation vertex; and (c) the design template and new items and new test form represent the observation vertex (see Figure 1). The framework informs the types of observations instructors want to see as evidence of this pre-specified cognition model, ways in which the evidence may be interpreted.\n\nAn initial data analysis of the first version of the TTCI provided a clear picture of the functioning of the TTCI and its items relative to its purposes and use and indicated potential areas of improvement. Engineering domain experts, engineering education researchers, cognitive scientists and educational measurement experts then worked together to use ECD to modify existing questions and create new questions within each FK category. Psychometric analyses provided complementary information on how items are functioning in an instrument (see Figure 2), which will then inform another cycle of edits on the TTCI. Jorion et al. (2014) provide more details about the decision-making process of using statistical analyses to investigate CIs. \n\nThe design and analysis of the TTCI heat section serves as an excellent case study of employing the ECD and analytical frameworks. Moreover, such ECD and analytical work together should be widely applicable to any CI with a well-defined conceptual framework for specified inventory uses. A preliminary analysis of the TTCI showed that the inventory demonstrated less-than-optimal reliability and validity properties potentially because of the low number of items, which was exacerbated by the use of \"two-part\" items (see Figure 3 for an example of a two-part item). The TTCI heat section consisted of five single items and six paired items (i.e. 12 items in 6 pairs). Although these two-part items did an adequate job of tapping into conceptual understanding, they were problematic to analyze psychometrically. All of the two-part items were more difficult than the one-part items (as one might expect). A variety of scoring schemes were investigated, such as: (1) partial credit of either part, (2) partial credit only if the second part was answered correctly, and (3) full credit only if both parts were answered correctly. All of these scoring methods had different properties than the \"singlet\" items. In addition, since students were completing the test all at once and could go back and change answers, it was possible that students were going back and answering first part of the item based on second part, introducing construct irrelevant variance. So the decision was made to revise the paired items as single items and eliminate paired items through the inventory, the research team included the TTCI developers. In this way, there could be a collaborative effort with content experts, psychometricians, and learning scientists applying the ECD approach to help produce a more valid inventory, one that would improve diagnostic performance for formative use in engineering classrooms. This iterative process with the TTCI demonstrates how both to create and modify existing CIs to produce more valid instruments of conceptual understanding.","authors":["James W. Pellegrino","Natalie Jorion","Brian D. Gane","Katie James"],"meta":["April 2014","DOI:10.13140/2.1.1786.7206","Conference: American Educational Research Association"],"references":["267687209_Conceptual_and_Analytical_Frameworks_for_Examining_Validity_and_Utility_of_Concept_Inventories","209835856_Best_Practices_in_Exploratory_Factor_Analysis_Four_Recommendations_for_Getting_the_Most_From_Your_Analysis","270584995_Knowing_What_Students_Know_The_Science_and_Design_of_Educational_Assessment","268505623_Classroom_application_of_educational_measurement","234591969_A_Brief_Introduction_to_Evidence-Centered_Design_CSE_Report_632"]}