{"id":"316650852_Sensing_and_Handling_Engagement_Dynamics_in_Human-Robot_Interaction_Involving_Peripheral_Computing_Devices","abstract":"When human partners attend to peripheral computing devices while interacting with conversational robots, the inability of the robots to determine the actual engagement level of the human partners after gaze shift may cause communication breakdown. In this paper, we propose a real-time perception model for robots to estimate human partners' engagement dynamics, and investigate different robot behavior strategies to handle ambiguities in humans' status and ensure the flow of the conversation. In particular, we define four novel types of engagement status and propose a real-time engagement inference model that weighs humans' social signals dynamically according to the involvement of the computing devices. We further design two robot behavior strategies (explicit and implicit) to help resolve uncertainties in engagement inference and mitigate the impact of uncoupling, based on an annotated human-human interaction video corpus. We conducted a within-subject experiment to assess the efficacy and usefulness of the proposed engagement inference model and behavior strategies. Results show that robots with our engagement model can deliver better service and smoother conversations as an assistant, and people find the implicit strategy more polite and appropriate.","authors":["Mingfei Sun","Zhenjie Zhao","Xiaojuan Ma"],"meta":["May 2017","DOI:10.1145/3025453.3025469","Conference: the 2017 CHI Conference","Project: Language Grounding"],"references":["301938133_See_You_See_Me_the_Role_of_Eye_Contact_in_Multimodal_Human-Robot_Interaction","301931092_Help_Me_Please_Robot_Politeness_Strategies_for_Soliciting_Help_From_Humans","301466521_Deciphering_the_Silent_Participant_On_the_Use_of_Audio-Visual_Cues_for_the_Classification_of_Listener_Categories_in_Group_Discussions","280266268_Combining_dynamic_head_pose-gaze_mapping_with_the_robot_conversational_state_for_attention_recognition_in_human-robot_interactions","273670084_Too_Much_Humanness_for_Human-Robot_Interaction_Exposure_to_Highly_Humanlike_Robots_Elicits_Aversive_Responding_in_Observers","270340907_Design_and_Evaluation_of_a_Peripheral_Robotic_Conversation_Companion","262348209_Smartphone_use_does_not_have_to_be_rude_making_phones_a_collaborative_presence_in_meetings","262238822_Designing_engagement-aware_agents_for_multiparty_conversations","240696437_Expressing_uncertainty_with_a_talking_head_in_a_multimodal_question-answering_system","235838918_Pay_Attention_Designing_Adaptive_Agents_that_Monitor_and_Improve_User_Engagement","228658102_Sorry_I_didn't_Catch_That_An_Investigation_of_Non-understanding_Errors_and_Recovery_Strategies","225466225_The_lecture_and_the_laptop_Multitasking_in_wireless_learning_environments","224623164_Integrating_vision_and_speech_for_conversations_with_multiple_persons","221517776_Revealing_gauguin_Engaging_visitors_in_robot_guide's_explanation_in_an_art_museum","221513829_Peripheral_computing_during_presentations_Perspectives_on_costs_and_preferences","221473135_Gracefully_mitigating_breakdowns_in_robotic_services","221052562_Facilitating_Multiparty_Dialog_with_Gaze_Gesture_and_Speech","221052546_Detecting_user_engagement_with_a_robot_companion_using_task_and_social_interaction-based_features","221052384_A_probabilistic_inference_of_multiparty-Conversation_structure_based_on_markov-Switching_models_of_gaze_patterns_head_directions_and_utterances","221052207_Dialog_in_the_open_world_platform_and_applications","4212112_Towards_a_humanoid_museum_guide_robot_that_interacts_with_multiple_persons","2313001_ambientROOM_Integrating_Ambient_Media_with_Architectural_Space","314468996_Toward_Better_Understanding_of_Engagement_in_Multiparty_Spoken_Interaction_with_Children","311473278_Laptops_in_the_classroom","303901684_The_Frustrations_and_Benefits_of_Mobile_Device_Usage_in_the_Home_when_Co-Present_with_Family_Members","301913050_From_Real-time_Attention_Assessment_to_With-me-ness_in_Human-Robot_Interaction","289927086_Managing_Human-Robot_Engagement_with_Forecasts_and_um_Hesitations","289926989_Natural_Communication_about_Uncertainties_in_Situated_Interaction","288021470_Generating_Robot_Gaze_on_the_Basis_of_Participation_Roles_and_Dominance_Estimation_in_Multiparty_Interaction","275004526_Transformed_Social_Interaction_Augmented_Gaze_and_Social_Influence_in_Immersive_Virtual_Environments","266655397_Combining_body_pose_gaze_and_gesture_to_determine_intention_to_interact_in_vision-based_interfaces","262328114_Gaze_awareness_in_conversational_agents_Estimating_a_user's_conversational_engagement_from_eye_gaze","262294535_Spatial_and_other_social_engagement_cues_in_a_child-robot_interaction_Effects_of_a_sidekick","262277230_Meet_me_where_i'm_gazing_How_shared_attention_gaze_affects_human-robot_handover_timing","261091849_How_a_robot_should_give_advice","257987168_How_Can_I_Help_You_Comparing_Engagement_Classification_Strategies_for_a_Robot_Bartender","255564577_Displaying_Mobile_Feedback_During_a_Presentation","254007796_Vision-based_attention_estimation_and_selection_for_social_robot_to_perform_natural_interaction_in_the_open_world","227619474_Transformed_Social_Interaction_Augmented_Gaze_and_Social_Influence_in_Immersive_Virtual_Environments","222414417_Explorations_in_engagement_for_humans_and_robots","221607926_Estimating_user's_engagement_from_eye-gaze_behaviors_in_human-agent_conversations","221517515_Disruption_of_meetings_by_laptop_use_Is_there_a_10-second_solution","220877092_Interactive_public_ambient_displays_Transitioning_from_implicit_to_explicit_public_to_personal_interaction_with_multiple_users","220729032_Bring_your_own_laptop_unless_you_want_to_follow_the_lecture_Alternative_communication_in_the_classroom","220382314_Must_electronic_gadgets_disrupt_our_face-to-face_conversations","220054910_Interpersonal_Communication_and_Human-Computer_Interaction_An_Examination_of_the_Use_of_Computers_in_Medical_Consultations"]}