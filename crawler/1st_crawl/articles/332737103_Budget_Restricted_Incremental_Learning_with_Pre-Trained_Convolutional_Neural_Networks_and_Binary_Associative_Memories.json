{"id":"332737103_Budget_Restricted_Incremental_Learning_with_Pre-Trained_Convolutional_Neural_Networks_and_Binary_Associative_Memories","abstract":"For the past few years, Deep Neural Networks (DNNs) have achieved state-of-art performance in numerous challenging domains. To reach this performance, DNNs consist in large sets of parameters and complex architectures, which are trained offline on huge datasets. The complexity and size of DNNs architectures make it difficult to implement such approaches for budget-restricted applications such as embedded systems. Furthermore, DNNs cannot learn incrementally new data, without forgetting previously acquired knowledge, which makes embedded applications even more challenging due to the need of storing the whole dataset. To tackle this problem, we introduce an incremental learning method that combines pre-trained DNNs, binary associative memories, and product quantizing (PQ) as a bridge between them. The obtained method requires less computational power and memory requirements, and reaches good performances on challenging vision datasets. Moreover, we present a hardware implementation validated on a FPGA target, which uses few hardware resources, while providing substantial processing acceleration compared to a CPU counterpart.","authors":["Ghouthi Boukli Hacene","Vincent Gripon","Nicolas Farrugia","Matthieu Arzel"],"meta":["September 2019Journal of Signal Processing Systems 91(6)","DOI:10.1007/s11265-019-01450-z"],"references":["310769730_iCaRL_Incremental_Classifier_and_Representation_Learning","320971202_iCaRL_Incremental_Classifier_and_Representation_Learning","319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation","319770342_Compressing_Deep_Convolutional_Networks_using_Vector_Quantization","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","312532410_Incremental_and_decremental_support_vector_machine_learning","311609205_Quantized_Convolutional_Neural_Networks_for_Mobile_Devices","311491247_Going_Deeper_with_Embedded_FPGA_Platform_for_Convolutional_Neural_Network","311488529_Throughput-Optimized_OpenCL-based_FPGA_Accelerator_for_Large-Scale_Convolutional_Neural_Networks","311458156_Towards_the_Limit_of_Network_Quantization","307908645_Comparing_Incremental_Learning_Strategies_for_Convolutional_Neural_Networks","301878495_SqueezeNet_AlexNet-level_accuracy_with_50x_fewer_parameters_and_05MB_model_size","308813493_Curriculum_learning_of_multiple_tasks","306281834_Rethinking_the_Inception_Architecture_for_Computer_Vision","306081371_Compression_of_Deep_Neural_Networks_on_the_Fly"]}