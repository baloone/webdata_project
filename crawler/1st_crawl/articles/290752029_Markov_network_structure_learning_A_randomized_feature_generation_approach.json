{"id":"290752029_Markov_network_structure_learning_A_randomized_feature_generation_approach","abstract":"The structure of a Markov network is typically learned in one of two ways. The first approach is to treat this task as a global search problem. However, these algorithms are slow as they require running the expensive operation of weight (i.e., parameter) learning many times. The second approach involves learning a set of local models and then combining them into a global model. However, it can be computationally expensive to learn the local models for datasets that contain a large number of variables and/or examples. This paper pursues a third approach that views Markov network structure learning as a feature generation problem. The algorithm combines a data-driven, specific-to-general search strategy with randomization to quickly generate a large set of candidate features that all have support in the data. It uses weight learning, with L1 regularization, to select a subset of generated features to include in the model. On a large empirical study, we find that our algorithm is equivalently accurate to other state-of-the-art methods while exhibiting a much faster run time. Copyright Â© 2012, Association for the Advancement of Artificial Intelligence. All rights reserved.","authors":["Jan Van Haaren","J. Davis"],"meta":["January 2012"],"references":["221619001_Efficient_structure_learning_of_Markov_networks_using_L_1-_regularization","221344727_Discriminative_structure_and_parameter_learning_for_Markov_logic_networks","220766435_Learning_Markov_Network_Structure_with_Decision_Trees","271076887_Markov_Chain_Monte_Carlo_In_Practice","253174288_High-dimensional_Ising_model_selection_using_-regularized_logistic_regression","243769716_Statistical_Analysis_of_Non-Lattice_Data","221618559_Structured_Learning_with_Approximate_Inference","221345311_Bottom-up_learning_of_Markov_logic_network_structure","221344850_Scalable_training_of_L","215991928_Bottom-Up_Learning_of_Markov_Network_Structure"]}