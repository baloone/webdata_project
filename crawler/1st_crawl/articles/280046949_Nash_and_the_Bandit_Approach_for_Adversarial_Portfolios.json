{"id":"280046949_Nash_and_the_Bandit_Approach_for_Adversarial_Portfolios","abstract":"In this paper we study the use of a portfolio of policies for adversarial problems. We use two different portfolios of policies and apply it to the game of Go. The first portfolio is composed of different version of the GnuGo agent. The second portfolio is composed of fixed random seeds. First we demonstrate that learning an offline combination of these policies using the notion of Nash Equilibrium generates a stronger opponent. Second, we show that we can learn online such distributions through a bandit approach. The advantages of our approach are (i) diversity (the Nash-Portfolio is more variable than its components) (ii) adaptivity (the Bandit-Portfolio adapts to the opponent) (iii) simplicity (no computational overhead) (iv) increased performance. Due to the importance of games on mobile devices, designing artificial intelligences for small computational power is crucial; our approach is particularly suited for mobile device since it create a stronger opponent simply by biaising the distribution over the policies and moreover it generalizes quite well.","authors":["David L. Saint-Pierre","Olivier Teytaud"],"meta":["August 2014","DOI:10.1109/CIG.2014.6932897"],"references":["270632692_Self-Adaptation_of_Playing_Strategies_in_General_Game_Playing","267832745_Hydra-MIP_Automated_Algorithm_Configuration_and_Selection_for_Mixed_Integer_Programming","261931031_Hedging_Algorithms_and_Repeated_Matrix_Games","254054237_Voronoi_coverage_control_with_time-driven_communication_for_mobile_sensing_networks_with_obstacles","224678061_Dynamic_Algorithm_Selection_Using_Reinforcement_Learning","221633486_Understanding_Random_SAT_Beyond_the_Clauses-to-Variables_Ratio","221633386_Algorithm_Selection_and_Scheduling","221606454_Learning_to_solve_QBF","220862431_Coevolving_Partial_Strategies_for_the_Game_of_Go","220780437_Confronting_Hardness_Using_a_Hybrid_Approach","220343796_Finite-time_Analysis_of_the_Multiarmed_Bandit_Problem","220151284_Exploration-exploitation_tradeoff_using_variance_estimates_in_multi-armed_bandits","47685417_SATzilla_Portfolio-based_Algorithm_Selection_for_SAT","43797817_A_Principled_Method_for_Exploiting_Opening_Books","14265324_Coevolutionary_Computation","2742554_Towards_a_Formal_Framework_for_Comparing_Constraint_Satisfaction_Problem_Formulations","2265004_Gambling_in_a_rigged_casino_The_adversarial_multi-armed_bandit_problem","313716869_Perceptron_trees_A_case_study_in_hybrid_concept_representations","246697515_Linear_programming_and_the_theory_of_games","239292007_Asymptotically_efficient_adaptive_allocation_rules1","232735414_Algorithm_Selection_for_Combinatorial_Search_Problems_A_Survey","229142880_Representation_in_Case-Based_Reasoning_Applied_to_Control_Reconfiguration","223057065_A_sublinear-time_randomized_approximation_algorithm_for_matrix_games","221606222_Perceptron_Trees_A_Case_Study_In_Hybrid_Concept_Representations","221499155_Gambling_in_a_Rigged_Casino_The_Adversarial_Multi-Arm_Bandit_Problem","202051293_Learning_Dynamic_Algorithm_Portfolios","29648128_Efficient_Selectivity_and_Backup_Operators_in_Monte-Carlo_Tree_Search","4249915_Discovering_Chinese_Chess_Strategies_through_Coevolutionary_Approaches","2281319_Generalizing_from_Case_Studies_A_Case_Study"]}