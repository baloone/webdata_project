{"id":"315472546_Music_synchronization_with_video_using_emotion_similarity","authors":["Ki-Ho Shin","In-Kwon Lee"],"meta":["February 2017","DOI:10.1109/BIGCOMP.2017.7881714","Conference: 2017 IEEE International Conference on Big Data and Smart Computing (BigComp)"],"references":["262286497_User_preference-aware_music_video_generation_based_on_modeling_scene_moods","262221330_The_acousticvisual_emotion_guassians_model_for_automatic_generation_of_music_video","220723083_jAudio_An_Feature_Extraction_Library","220663961_Automated_music_video_generation_using_multi-level_feature-based_segmentation","305658501_Art_of_Color_The_Subjective_Experience_and_Objective_Rationale_of_Color","304824205_Regression_Shrinkage_and_Selection_via_the_LASSO","262220011_1000_songs_for_emotional_analysis_of_music","239064516_Combining_color_and_spatial_information_for_content-based_image_retrieval","231383409_The_Biopsychology_of_Mood_and_Arousal","221997039_Regression_shrinkage_and_selection_via_the_LASSO","3863771_Automatic_audio_segmentation_using_a_measure_of_audio_novelty","2407014_Automatic_Extraction_of_Tempo_and_Beat_From_Expressive_Performances"]}