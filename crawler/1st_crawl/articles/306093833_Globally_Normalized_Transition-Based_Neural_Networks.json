{"id":"306093833_Globally_Normalized_Transition-Based_Neural_Networks","abstract":"We introduce a globally normalized transition-based neural network model that achieves state-of-the-art part-of-speech tagging, dependency parsing and sentence compression results. Our model is a simple feed-forward neural network that operates on a task-specific transition system, yet achieves comparable or better accuracies than recurrent models. The key insight is based on a novel proof illustrating the label bias problem and showing that globally normalized models can be strictly more expressive than locally normalized models.","authors":["Daniel Andor","Christopher Alberti","David Wei√ü","Aliaksei Severyn"],"meta":["March 2016","DOI:10.18653/v1/P16-1231","Conference: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)"],"references":["304409176_Conditional_Random_Fields_as_Recurrent_Neural_Networks","301446508_Incremental_Recurrent_Neural_Network_Dependency_Parser_with_Search-based_Discriminative_Training","329977305_Efficient_Structured_Inference_for_Transition-Based_Parsing_with_Neural_Networks_and_Error_States","309076254_Gradientbased_learning_applied_to_document_recognition","303157008_Training_Deterministic_Parsers_with_Non-Deterministic_Oracles","301446020_Improved_Transition-Based_Parsing_and_Tagging_with_Neural_Networks","301445791_Sentence_Compression_by_Deletion_with_LSTMs","301404517_Transition-based_Neural_Constituent_Parsing","299487682_A_Fast_and_Accurate_Dependency_Parser_using_Neural_Networks","283842725_A_Neural_Probabilistic_Structured-Prediction_Model_for_Transition-Based_Dependency_Parsing"]}