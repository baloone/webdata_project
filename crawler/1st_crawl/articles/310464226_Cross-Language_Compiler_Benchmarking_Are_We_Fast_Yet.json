{"id":"310464226_Cross-Language_Compiler_Benchmarking_Are_We_Fast_Yet","abstract":"Comparing the performance of programming languages is difficult because they differ in many aspects including preferred programming abstractions, available frameworks, and their runtime systems. Nonetheless, the question about relative performance comes up repeatedly in the research community, industry, and wider audience of enthusiasts.\nThis paper presents 14 benchmarks and a novel methodology to assess the compiler effectiveness across language implementations. Using a set of common language abstractions, the benchmarks are implemented in Java, JavaScript, Ruby, Crystal, Newspeak, and Smalltalk. We show that the benchmarks exhibit a wide range of characteristics using language-agnostic metrics. Using four different languages on top of the same compiler, we show that the benchmarks perform similarly and therefore allow for a comparison of compiler effectiveness across languages. Based on anecdotes, we argue that these benchmarks help language implementers to identify performance bugs and optimization potential by comparing to other language implementations.","authors":["Stefan Marr","Benoit Daloze","Hanspeter Mössenböck"],"meta":["November 2016ACM SIGPLAN Notices","DOI:10.1145/2989225.2989232","Conference: 12th Symposium on Dynamic Languages","Project: Project MetaConc: Towards Meta-Level Engineering and Tooling for Complex Concurrent Systems"],"references":["266078363_An_object_storage_model_for_the_truffle_language_implementation_framework","262170315_One_VM_to_rule_them_all","319770385_Loop_Recognition_in_C_Java_Go_Scala","314818400_Dynamic_metrics_for_java","305259072_Space_Efficient_Conservative_Garbage_Collection","278256723_Space_efficient_conservative_garbage_collection","269148316_The_DaCapo_benchmarks","269132251_Da_capo_con_scala","262351526_Self-optimizing_AST_interpreters","262243968_Characteristics_of_dynamic_JVM_languages"]}