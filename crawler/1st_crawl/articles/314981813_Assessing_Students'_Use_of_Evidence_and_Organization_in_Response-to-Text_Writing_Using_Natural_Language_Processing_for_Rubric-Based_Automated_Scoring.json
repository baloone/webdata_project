{"id":"314981813_Assessing_Students'_Use_of_Evidence_and_Organization_in_Response-to-Text_Writing_Using_Natural_Language_Processing_for_Rubric-Based_Automated_Scoring","abstract":"This paper presents an investigation of score prediction based on natural language processing for two targeted constructs within analytic text-based writing: 1) students’ effective use of evidence and, 2) their organization of ideas and evidence in support of their claim. With the long-term goal of producing feedback for students and teachers, we designed a task-dependent model, for each dimension, that aligns with the scoring rubric and makes use of the source material. We believe the model will be meaningful and easy to interpret given the writing task. We used two datasets of essays written by students in grades 5–6 and 6–8. Our experimental results show that our task-dependent model (consistent with the rubric) performs as well as if not outperforms competitive baselines. We also show the potential generalizability of the rubric-based model by performing cross-corpus experiments. Finally, we show that the predictive utility of different feature groups in our rubric-based modeling approach is related to how much each feature group covers a rubric’s criteria.","authors":["Zahra Rahimi","Diane Litman","Richard Correnti","Elaine L. Wang"],"meta":["March 2017International Journal of Artificial Intelligence in Education 27(2)","DOI:10.1007/s40593-017-0143-2","Project: Automated Essay Scoring and Writing Assessment (eRevise)"],"references":["306093756_Automatically_Extracting_Topical_Components_for_a_Response-to-Text_Writing_Assessment","301404658_Encoding_World_Knowledge_in_the_Evaluation_of_Local_Coherence","301404359_Feature_selection_for_automated_speech_scoring","301404207_Incorporating_Coherence_of_Topics_as_a_Criterion_in_Automatic_Response-to-Text_Assessment_of_the_Organization_of_Writing","285269745_Analytic_Scoring_of_TOEFL_R_CBT_Essays_Scores_from_Humans_and_E-rater_R","282650063_Automated_Essay_Scoring_in_Innovative_Assessments_of_Writing_From_Sources","275465146_Applying_Argumentation_Schemes_for_Essay_Scoring","267949121_Text_Coherence_and_Judgments_of_Essay_Quality_Models_of_Quality_and_Coherence","267623546_Identifying_Argumentative_Discourse_Structures_in_Persuasive_Essays","259727128_Assessing_Students'_Skills_at_Writing_Analytically_in_Response_to_Texts","257483763_On_the_relation_between_automated_essay_scoring_and_modern_views_of_the_writing_construct","234807240_Lexical_cohesion_computed_by_thesaural_relations_as_an_indicator_of_the_structure_of_text","231965976_Identifying_off-topic_student_essays_without_topic-specific_training_data","228908625_Automated_evaluation_of_coherence_in_student_essays","220875179_Using_Syntax_to_Disambiguate_Explicit_Discourse_Connectives_in_Text","220817329_Evaluating_Multiple_Aspects_of_Coherence_in_Student_Essays","220543125_SMOTE_Synthetic_Minority_Over-sampling_Technique","215835918_CriterionSM_Online_essay_evaluation_An_application_for_automated_evaluation_of_student_essays","200045222_An_Introduction_to_Latent_Semantic_Analysis","313244048_Feature_selection_for_automated_speech_scoring","307632243_Annotating_argument_components_and_relations_in_persuasive_essays","301648630_Parsing_Argumentation_Structures_in_Persuasive_Essays","290105191_Using_Automated_Indices_of_Cohesion_to_Evaluate_an_Intelligent_Tutoring_System_and_an_Automated_Writing_Evaluation_System","286335617_Assessing_Writing","284624808_Construct_validity_length_score_and_time_in_holistically_graded_writing_assessments_The_case_against_automated_essay_scoring_AES","283923791_Contrasting_state-of-the-art_automated_scoring_of_essays","283649923_Modeling_Argument_Strength_in_Student_Essays","282237243_Ontology-Based_Argument_Mining_and_Automatic_Essay_Scoring","281495868_Evaluating_the_Replicability_of_Significance_Tests_for_Comparing_Learning_Algorithms","277788627_Off-topic_essay_detection_using_short_prompt_texts","273594315_Scoring_with_the_computer_Alternative_procedures_for_improving_the_reliability_of_holistic_essay_scoring","273520897_Automatic_Scoring_of_an_Analytical_Response-To-Text_Assessment","272673765_Holistic_Discourse_Coherence_Annotation_for_Noisy_Essay_Writing","270878655_Modeling_Prompt_Adherence_in_Student_Essays","270878179_Modeling_Prompt_Adherence_in_Student_Essays","270877394_Content_Importance_Models_for_Scoring_Writing_From_Sources","265237557_A_Developmental_Writing_Scale","265188565_A_Differential_Word_Use_Measure_for_Content_Analysis_in_Automated_Essay_Scoring","262245627_Measuring_the_use_of_factual_information_in_test-taker_essays","260607052_Automated_Scoring_of_Constructed-Response_Science_Items_Prospects_and_Obstacles","257484019_Large-scale_assessment_locally-developed_measures_and_automated_scoring_of_essays_Fishing_for_red_herrings","247276964_Project_essay_grade_PEG","246494802_Intellimetric_From_Here_to_Validity","245566910_Automated_Essay_Scoring_A_Cross-Disciplinary_Perspective","228535655_Exploring_Content_Features_for_Automated_Speech_Scoring","222833344_Writing_evaluation_What_can_analytic_versus_holistic_essay_scoring_tell_us","220875004_Modeling_Local_Coherence_An_Entity-Based_Approach","220817159_Using_Entity-Based_Features_to_Model_Coherence_in_Student_Essays","220812843_Improving_Word_Sense_Disambiguation_in_Lexical_Chaining","220355166_Modeling_Local_Coherence_An_Entity-Based_Approach","200019282_Automatic_Essay_Grading_with_Probabilistic_Latent_Semantic_Analysis","2879178_A_System_To_Assess_The_Semantic_Content_Of_Student_Essays","2647371_The_Measurement_of_Textual_Coherence_with_Latent_Semantic_Analysis","28798528_Automated_Essay_Scoring_With_e-raterR_V2","3454073_Finding_the_WRITE_Stuff_Automatic_Identification_of_Discourse_Structure_in_Student_Essays"]}