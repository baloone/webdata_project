{"id":"333527125_Deep_Neural_Network_Approximation_for_Custom_Hardware_Where_We've_Been_Where_We're_Going","abstract":"Deep neural networks have proven to be particularly effective in visual and audio recognition tasks. Existing models tend to be computationally expensive and memory intensive, however, and so methods for hardware-oriented approximation have become a hot topic. Research has shown that custom hardware-based neural network accelerators can surpass their general-purpose processor equivalents in terms of both throughput and energy efficiency. Application-tailored accelerators, when co-designed with approximation-based network training methods, transform large, dense, and computationally expensive networks into small, sparse, and hardware-efficient alternatives, increasing the feasibility of network deployment. In this article, we provide a comprehensive evaluation of approximation methods for high-performance network inference along with in-depth discussion of their effectiveness for custom hardware implementation. We also include proposals for future research based on a thorough analysis of current trends. This article represents the first survey providing detailed comparisons of custom hardware accelerators featuring approximation for both convolutional and recurrent neural networks, through which we hope to inspire exciting new developments in the field.","authors":["Erwei Wang","James J. Davis","Ruizhe Zhao","Ho-Cheung Ng"],"meta":["May 2019ACM Computing Surveys 52(2):1-39","DOI:10.1145/3309551"],"references":["329481891_CascadeCNN_Pushing_the_Performance_Limits_of_Quantisation_in_Convolutional_Neural_Networks","329473376_Embracing_Diversity_Enhanced_DSP_Blocks_for_Low-Precision_Deep_Learning_on_FPGAs","327810635_ReBNet_Residual_Binarized_Neural_Network","327198532_A_domain-specific_architecture_for_deep_neural_networks","325634095_Structured_Weight_Matrices-Based_Hardware_Accelerators_in_Deep_Neural_Networks_FPGAs_and_ASICs","324435700_NetAdapt_Platform-Aware_Neural_Network_Adaptation_for_Mobile_Applications","324275373_Approximate_FPGA-Based_LSTMs_Under_Computation_Time_Constraints","323846238_C-LSTM_Enabling_Efficient_LSTM_using_Structured_Compression_Techniques_on_FPGAs","323375482_DeltaRNN_A_Power-efficient_Recurrent_Neural_Network_Accelerator","323373772_C-LSTM_Enabling_Efficient_LSTM_using_Structured_Compression_Techniques_on_FPGAs","323373090_Towards_a_Uniform_Template-based_Architecture_for_Accelerating_2D_and_3D_CNNs_on_FPGA","322328789_Approximate_FPGA-based_LSTMs_under_Computation_Time_Constraints","322075975_A_Survey_of_FPGA_Based_Neural_Network_Accelerator","322059721_Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks","322057654_Learning_Efficient_Convolutional_Networks_through_Network_Slimming","321417623_Towards_Accurate_Binary_Convolutional_Neural_Network","320867264_ResBinNet_Residual_Binary_Neural_Network","320252886_Latency-driven_design_for_FPGA-based_convolutional_neural_networks","338506754_Binary_Ensemble_Neural_Network_More_Bits_per_Network_or_More_Networks_per_Bit","332068898_DL_A_Survey_of_FPGA-based_Neural_Network_Inference_Accelerators","329740169_Quantization_and_Training_of_Neural_Networks_for_Efficient_Integer-Arithmetic-Only_Inference","329477860_In-Package_Domain-Specific_ASICs_for_IntelR_StratixR_10_FPGAs_A_Case_Study_of_Accelerating_Deep_Learning_Using_TensorTile_ASIC","328378376_Caffeine_Toward_Uniformed_Representation_and_Acceleration_for_Deep_Convolutional_Neural_Networks","328112952_NetAdapt_Platform-Aware_Neural_Network_Adaptation_for_Mobile_Applications_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Part_X","327811551_A_PYNQ-Based_Framework_for_Rapid_CNN_Prototyping","327806262_PQ-CNN_Accelerating_Product_Quantized_Convolutional_Neural_Network_on_FPGA","327804038_Exploration_of_Low_Numeric_Precision_Deep_Learning_Inference_Using_IntelR_FPGAs","327785222_Loom_Exploiting_Weight_and_Activation_Precisions_to_Accelerate_Convolutional_Neural_Networks","326566660_Bit_Fusion_Bit-Level_Dynamically_Composable_Architecture_for_Accelerating_Deep_Neural_Network","325860786_Loom_Exploiting_Weight_and_Activation_Precisions_to_Accelerate_Convolutional_Neural_Networks","325447324_Binarized_LSTM_Language_Model","324767922_Throughput_Optimizations_for_FPGA-based_Deep_Neural_Network_Inference","324274798_Redundancy-Reduced_MobileNet_Acceleration_on_Reconfigurable_Logic_for_ImageNet_Classification","324164613_Recent_advances_in_efficient_computation_of_deep_convolutional_neural_networks","324137820_Optimizing_FPGA-based_CNN_accelerator_for_energy_efficiency_with_an_extended_Rooine_model","323561648_Flexpoint_An_Adaptive_Numerical_Format_for_Efficient_Training_of_Deep_Neural_Networks","323375503_A_Customizable_Matrix_Multiplication_Framework_for_the_Intel_HARPv2_XeonFPGA_Platform_A_Deep_Learning_Case_Study","323374899_In-Package_Domain-Specific_ASICs_for_IntelR_StratixR_10_FPGAs_A_Case_Study_of_Accelerating_Deep_Learning_Using_TensorTile_ASICAbstract_Only","323373646_Exploration_of_Low_Numeric_Precision_Deep_Learning_Inference_Using_IntelR_FPGAs_Abstract_Only","323373587_FPGA_Fastfood_-_A_High_Speed_Systolic_Implementation_of_a_Large_Scale_Online_Kernel_Method","323349661_Running_sparse_and_low-precision_neural_network_When_algorithm_meets_hardware","323165247_Training_and_Inference_with_Integers_in_Deep_Neural_Networks","322376264_Model_Compression_and_Acceleration_for_Deep_Neural_Networks_The_Principles_Progress_and_Challenges","321816568_Learning_to_fly_by_crashing","321173495_Bit-pragmatic_deep_neural_network_computing","321065052_CaffePresso_Accelerating_Convolutional_Networks_on_Embedded_SoCs","320971375_Deep_Learning_with_Low_Precision_by_Half-Wave_Gaussian_Quantization","320968331_Designing_Energy-Efficient_Convolutional_Neural_Networks_Using_Energy-Aware_Pruning","320920375_Flexpoint_An_Adaptive_Numerical_Format_for_Efficient_Training_of_Deep_Neural_Networks","320497894_FP-BNN_Binarized_neural_network_on_FPGA","320251759_Scalable_high-performance_architecture_for_convolutional_ternary_neural_networks_on_FPGA","320250008_High-performance_video_content_recognition_with_long-term_recurrent_convolutional_network_for_FPGA","319856813_In-Datacenter_Performance_Analysis_of_a_Tensor_Processing_Unit","320091463_Hardware_accelerators_for_recurrent_neural_networks_on_FPGA","319770367_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation"]}