{"id":"337345997_Learning_dexterous_in-hand_manipulation","abstract":"We use reinforcement learning (RL) to learn dexterous in-hand manipulation policies that can perform vision-based object reorientation on a physical Shadow Dexterous Hand. The training is performed in a simulated environment in which we randomize many of the physical properties of the system such as friction coefficients and an object’s appearance. Our policies transfer to the physical robot despite being trained entirely in simulation. Our method does not rely on any human demonstrations, but many behaviors found in human manipulation emerge naturally, including finger gaiting, multi-finger coordination, and the controlled use of gravity. Our results were obtained using the same distributed RL system that was used to train OpenAI Five. We also include a video of our results: https://youtu.be/jwSbzNHGflM .","authors":["OpenAI: Marcin Andrychowicz","Bowen Baker","Maciek Chociej","Rafal Józefowicz"],"meta":["November 2019The International Journal of Robotics Research 39(1):027836491988744","DOI:10.1177/0278364919887447"],"references":["326741033_Sim-to-Real_Learning_Agile_Locomotion_For_Quadruped_Robots","326738260_Reinforcement_and_Imitation_Learning_for_Diverse_Visuomotor_Skills","324745048_Distributed_Distributional_Deterministic_Policy_Gradients","322765921_On_Policy_Learning_Robust_to_Irreversible_Events_An_Application_to_Robotic_In-Hand_Manipulation","339776797_Rotary_objectdexterous_manipulation_in_hand_a_feedback-based_method","326740129_Asymmetric_Actor_Critic_for_Image-Based_Robot_Learning","322277018_Tensorflow_Large-scale_machine_learning_on_heterogeneous_distributed_systems","321810915_Domain_randomization_for_transferring_deep_neural_networks_from_simulation_to_the_real_world","320486930_Asymmetric_Actor_Critic_for_Image-Based_Robot_Learning","320486736_Sim-to-Real_Transfer_of_Robotic_Control_with_Dynamics_Randomization"]}