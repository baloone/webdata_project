{"id":"313346066_A_Hybrid_Parallelization_Scheme_for_Standard_Simplex_Method_based_on_CPUGPU_Collaboration","abstract":"The simplex method has been successfully used in solving linear programming problems for many years. Parallel approaches have also extensively been studied due to the intensive computations required, especially for the solution of large problems. The rapid proliferation of multicore CPU architectures as well as the computational power provided by the massive parallelism of modern GPUs have turned OpenMP and CUDA programming models increasingly into focus over the last years. However, the efficient CPU/GPU collaboration through the combined use of the above programming models still remains a major research challenge. In this paper we present a highly efficient parallel implementation of the standard simplex method, which can exploit concurrently the full power of the provided resources, on a multicore platform with a CUDA-enabled GPU. Specifically, we present three suitable parallel schemes, (a) a multi-threading one based on OpenMP, (b) a GPU-offloading scheme based on CUDA, and (c) a hybrid multi-threading/GPU offloading scheme. The experimental results show that the performance of our GPU-based implementation is comparable to other relevant works in the literature, and superior to our OpenMP-based implementation. The most important, the performance of our hybrid multi-threading/GPU offloading scheme is clearly superior to the GPU-based only implementation in almost all cases, which validates the worth of using both resources concurrently.","authors":["Basilis Mamalis","Marios Perlitis"],"meta":["November 2016","DOI:10.1145/3003733.3003757","Conference: the 20th Pan-Hellenic Conference"],"references":["317000661_Simultaneous_Solving_of_Linear_Programming_Problems_in_GPU","290430548_Simultaneous_Solving_of_Linear_Programming_Problems_in_GPU","280254541_A_multi-GPU_implementation_and_performance_model_for_the_standard_simplex_method","274383561_Some_Computational_Results_on_MPI_Parallel_Implementation_of_Dense_Simplex_Method","268693691_Efficient_GPU-based_implementations_of_simplex_type_algorithms","261235254_Recent_Advances_on_GPU_Computing_in_Operations_Research","257719607_Dynamic_Distribution_of_Workload_between_CPU_and_GPU_for_a_Parallel_Conjugate_Gradient_Method_in_an_Adaptive_FEM","257549123_Parallel_distributed-memory_simplex_for_large-scale_stochastic_LP_problems","235257619_Some_Computational_Results_on_MPI_Parallel_Implementation_of_Derived_Subgraph_Algorithm","225568277_Towards_a_practical_parallelisation_of_the_simplex_method","220951550_Efficient_Implementation_of_the_Simplex_Method_on_a_CPU-GPU_System","220949325_Linear_optimization_on_modern_GPUs","220939027_Accelerating_Linpack_with_CUDA_on_heterogenous_clusters","2539139_An_Efficient_Steepest-Edge_Simplex_Algorithm_for_SIMD_Computers","301388765_Hybrid_Parallelization_of_Standard_Full_Tableau_Simplex_Method_with_MPI_and_OpenMP","300257197_Advances_in_the_Parallelization_of_the_Simplex_Method","270989597_Highly_scalable_parallelization_of_standard_simplex_method_on_a_myrinet-connected_cluster_platform","261463424_Transparent_CPU-GPU_collaboration_for_data-parallel_kernels_on_heterogeneous_systems","224140961_An_efficient_GPU_implementation_of_the_revised_simplex_method","223190602_Hybrid_CUDA_OpenMP_and_MPI_parallel_programming_on_multicore_GPU_clusters","221149010_Multi_GPU_Implementation_of_the_Simplex_Algorithm","220952935_DAGuE_A_generic_distributed_DAG_engine_for_High_Performance_Computing","220717679_Harmony_An_execution_model_and_runtime_for_heterogeneous_many_core_systems","220359168_A_distributed_scaleable_simplex_method"]}