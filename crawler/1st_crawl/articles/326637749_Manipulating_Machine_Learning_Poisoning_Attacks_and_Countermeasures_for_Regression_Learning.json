{"id":"326637749_Manipulating_Machine_Learning_Poisoning_Attacks_and_Countermeasures_for_Regression_Learning","authors":["Matthew Jagielski","Alina Oprea","Battista Biggio","Chang Liu"],"meta":["May 2018","DOI:10.1109/SP.2018.00057","Conference: 2018 IEEE Symposium on Security and Privacy (SP)","Project: Adversarial Machine Learning"],"references":["320835811_Robust_Linear_Regression_Against_Training_Data_Poisoning","319235406_BadNets_Identifying_Vulnerabilities_in_the_Machine_Learning_Model_Supply_Chain","317002535_Membership_Inference_Attacks_Against_Machine_Learning_Models","307303246_Data_Poisoning_Attacks_on_Factorization-Based_Collaborative_Filtering","306304648_Distillation_as_a_Defense_to_Adversarial_Perturbations_Against_Deep_Neural_Networks","284788388_The_Limitations_of_Deep_Learning_in_Adversarial_Settings","284097112_Distillation_as_a_Defense_to_Adversarial_Perturbations_against_Deep_Neural_Networks","281376985_Man_vs_Machine_Practical_Adversarial_Detection_of_Malicious_Crowdsourcing_Workers","269935591_Explaining_and_Harnessing_Adversarial_Examples","225734295_The_Elements_of_Statistical_Learning_Data_Mining_Inference_and_Prediction","221654486_Adversarial_learning","220832101_Exploiting_Machine_Learning_to_Subvert_Your_Spam_Filter","220713708_Casting_out_Demons_Sanitizing_Training_Data_for_Anomaly_Sensors","45903465_Security_Analysis_of_Online_Centroid_Anomaly_Detection","4238319_Misleading_worm_signature_generators_using_deliberate_noise_injection","328326898_Wild_Patterns_Ten_Years_After_the_Rise_of_Adversarial_Machine_Learning","324717611_Is_feature_selection_secure_against_training_data_poisoning","321718936_Wild_Patterns_Ten_Years_After_the_Rise_of_Adversarial_Machine_Learning","319770378_Explaining_and_harnessing_adversarial_examples","317919653_Towards_Evaluating_the_Robustness_of_Neural_Networks","310824049_PREDATOR_Proactive_Recognition_and_Elimination_of_Domain_Abuse_at_Time-Of-Registration","306226844_Towards_Evaluating_the_Robustness_of_Neural_Networks","301534715_Privacy_in_Pharmacogenetics_An_End-to-End_Case_Study_of_Personalized_Warfarin_Dosing","301419711_Model_Inversion_Attacks_that_Exploit_Confidence_Information_and_Basic_Countermeasures","301135714_Applications_of_Artificial_Intelligence","289578622_On_the_Practicality_of_Integrity_Attacks_on_Document-Level_Sentiment_Analysis","289095306_Robust_sparse_regression_under_adversarial_corruption","288410669_Robust_logistic_regression_and_classification","286370353_Practical_Evasion_of_a_Learning-Based_Classifier_A_Case_Study","265978139_Information_geometry_and_alternating_minimization_procedures","264503005_Systematic_Poisoning_Attacks_on_and_Defenses_for_Machine_Learning_in_Healthcare","262173234_Adversarial_machine_learning","256600830_Evasion_Attacks_against_Machine_Learning_at_Test_Time","240383291_Security_Evaluation_of_Pattern_Classifiers_Under_Attack","238879940_Robust_Statistics_Theory_and_Methods","234113819_Robust_High_Dimensional_Sparse_Regression_and_Matching_Pursuit","228095591_Poisoning_Attacks_against_Support_Vector_Machines","225112116_Paragraph_Thwarting_Signature_Learning_by_Training_Maliciously","224145832_Robust_Regression_and_Lasso","221932989_Robust_Statistics","221678220_Robust_Estimation_of_a_Location_Parameter","221655408_Limits_of_Learning-based_Signature_Generation_with_Adversaries","221611962_ANTIDOTE_understanding_and_defending_against_poisoning_of_anomaly_detectors","221609372_Can_machine_learning_be_secure","215458581_Random_Sample_Consensus_A_Paradigm_for_Model_Fitting_with_Applications_To_Image_Analysis_and_Automated_Cartography","45890930_Robust_Principal_Component_Analysis","2925496_Learning_in_the_Presence_of_Malicious_Errors","2886081_Adversarial_Classification"]}