{"id":"318679033_SparseConnect_Regularizing_CNNs_on_Fully-Connected_Layers","abstract":"Deep convolutional neural networks (CNNs) have achieved unprecedented success in many domains. The numerous parameters allow CNNs to learn complex features, but also tend to hinder generalisation by over-fitting training data. Despite many previously proposed regularisation methods, over-fitting is one of many problems in training a robust CNN. Among many factors that may lead to over-fitting, the numerous parameters of fully connected layers (FCLs) of a typical CNN are a contributor to the over-fitting problem. The authors propose SparseConnect, which alleviates over-fitting by sparsifying connections to FCLs. Experimental results on three benchmark datasets MNIST and CIFAR10 show SparseConnect outperforms several stateof- the-art regularisation methods.","authors":["Qi Xu","Gang Pan"],"meta":["July 2017Electronics Letters 53(18)","DOI:10.1049/el.2017.2621"],"references":["322277018_Tensorflow_Large-scale_machine_learning_on_heterogeneous_distributed_systems","319770347_Memory_Bounded_Deep_Convolutional_Networks","319770252_TensorFlow_Large-Scale_Machine_Learning_on_Heterogeneous_Distributed_Systems","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","311610153_DisturbLabel_Regularizing_CNN_on_the_Loss_Layer","306218037_Learning_multiple_layers_of_features_from_tiny_images","304824205_Regression_Shrinkage_and_Selection_via_the_LASSO","301841689_Convolutional_Neural_Networks_using_Logarithmic_Data_Representation","286794765_Dropout_A_Simple_Way_to_Prevent_Neural_Networks_from_Overfitting","269116397_Memory_Bounded_Deep_Convolutional_Networks"]}