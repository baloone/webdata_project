{"id":"316848481_Flipper_A_Systematic_Approach_to_Debugging_Training_Sets","abstract":"As machine learning methods gain popularity across different fields, acquiring labeled training datasets has become the primary bottleneck in the machine learning pipeline. Recently generative models have been used to create and label large amounts of training data, albeit noisily. The output of these generative models is then used to train a discriminative model of choice, such as logistic regression or a complex neural network. However, any errors in the generative model can propagate to the subsequent model being trained. Unfortunately, these generative models are not easily interpretable and are therefore difficult to debug for users. To address this, we present our vision for Flipper, a framework that presents users with high-level information about why their training set is inaccurate and informs their decisions as they improve their generative model manually. We present potential tools within the Flipper framework, inspired by observing biomedical experts working with generative models, which allow users to analyze the errors in their training data in a systematic fashion. Finally, we discuss a prototype of Flipper and report results of a user study where users create a training set for a classification task and improve the discriminative model's accuracy by 2.4 points in less than an hour with feedback from Flipper.","authors":["Paroma Varma","Dan Iter","Christopher De Sa","Christopher RÃ©"],"meta":["May 2017","DOI:10.1145/3077257.3077263","Conference: the 2nd Workshop"],"references":["307747289_Show_and_tell_A_neural_image_caption_generator","304054981_Data_programming_with_DDLite_putting_humans_in_a_different_part_of_the_loop","288971322_Overview_of_the_BioCreative_V_chemical_disease_relation_CDR_task","272194766_Show_Attend_and_Tell_Neural_Image_Caption_Generation_with_Visual_Attention","221603805_Building_Explainable_Artificial_Intelligence_Systems","221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database","200045222_An_Introduction_to_Latent_Semantic_Analysis","13853244_Long_Short-term_Memory","319770355_Generative_Adversarial_Nets","319770247_Why_Should_I_Trust_You_Explaining_the_Predictions_of_Any_Classifier","310752533_Visualizing_and_understanding_convolutional_networks","308850035_Learning_from_massive_noisy_labeled_data_for_image_classification","308813785_Deep_visual-semantic_alignments_for_generating_image_descriptions","305999024_Why_Should_I_Trust_You_Explaining_the_Predictions_of_Any_Classifier","305342147_Why_Should_I_Trust_You_Explaining_the_Predictions_of_Any_Classifier","303521103_Data_Programming_Creating_Large_Training_Sets_Quickly","269339562_Deep_Visual-Semantic_Alignments_for_Generating_Image_Descriptions","267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks","261880160_One_weird_trick_for_parallelizing_convolutional_neural_networks","258424423_Visualizing_and_Understanding_Convolutional_Neural_Networks","247931959_The_mnist_database_of_handwritten_digits"]}