{"id":"332001876_Reasoning_with_smart_objects'_affordance_for_personalized_behavior_monitoring_in_pervasive_information_systems","abstract":"The miniaturization of sensors and their integration in everyday appliances have opened the way for ecologically monitoring people’s behavior based on their interaction with smart objects. Thanks to behavior monitoring, mobile, and ubiquitous information systems in the areas of e-health, home automation, and smart cities are becoming more and more “smart,” being able to dynamically adapt themselves to the current users’ context and situation. However, human behavior is characterized by large variability due to individual habits, physical disabilities or cognitive impairment. This aspect makes behavior monitoring a challenging task. On the one side, execution variability makes it hard to acquire sufficiently large activity datasets needed by supervised learning methods. On the other side, being based on a strict definition of activities in terms of constituting simpler actions, existing knowledge-based frameworks fall short in adapting to the specific characteristics of the subject. Hence, the variability of activity execution by different subjects calls for personalized methods to capture human activities and interaction in smart spaces at a fine-grained level. In this paper, we address this challenge by proposing a novel hybrid reasoning framework to capture fine-grained interaction with smart objects considering the specific features of individuals. Our model has its roots in the well-founded psychological theory of affordances, i.e., those features of an object that naturally explain its possible uses and how it should be used. The core of the framework is the ontological model of smart objects affordance, expressed through the OWL 2 Web Ontology Language. Through a use case in pervasive healthcare, we show how our framework can be applied to personalized recognition of abnormal behaviors. In particular, we tackle a particularly challenging issue: how to recognize early behavioral symptoms of mild cognitive impairment in subjects with physical disabilities. Moreover, an extensive experimental evaluation with real-world datasets acquired from 24 subjects shows the effectiveness of our framework in recognizing human activities and fine-grained manipulative gestures in different pervasive computing environments.","authors":["Assunta Matassa","Daniele Riboni"],"meta":["April 2020Knowledge and Information Systems 62(1)","DOI:10.1007/s10115-019-01357-y"],"references":["296684500_Deep_Dynamic_Neural_Networks_for_Multimodal_Gesture_Segmentation_and_Recognition","324352933_The_Ecological_Approach_to_Visual_Perception","324308514_Plans_and_Situated_Actions_The_Problem_of_Human-Machine_Communication","319395635_The_Description_Logic_Handbook_Theory_Implementation_and_Applications","319394983_Artificial_Intelligence_A_Modern_Approach","319394978_Artificial_Intelligence_---_A_Modern_Approach","308007064_Unsupervised_recognition_of_interleaved_activities_of_daily_living_through_ontological_and_probabilistic_reasoning","301583577_From_smart_to_deep_Robust_activity_recognition_on_smartwatches_using_deep_learning","300351026_Motion_Sequence_Recognition_with_Multi-sensors_Using_Deep_Convolutional_Neural_Network","283925025_Maintaining_Knowledge_about_Temporal_Intervals","282507401_A_New_Multi-channels_Sequence_Recognition_Framework_Using_Deep_Convolutional_Neural_Network","273574762_Handling_smart_environment_devices_data_and_services_at_the_semantic_level_with_the_FI-WARE_core_platform","272399955_The_UniversAAL_Platform_for_AAL_Ambient_Assisted_Living","270790857_Sensor-Based_Activity_Recognition","266654315_A_probabilistic_ontological_framework_for_the_recognition_of_multilevel_human_activities"]}