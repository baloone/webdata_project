{"id":"273187563_Automatic_Speech_Recognition_for_Mixed_Dialect_Utterances_by_Mixing_Dialect_Language_Models","abstract":"This paper presents an automatic speech recognition (ASR) system that accepts a mixture of various kinds of dialects. The system recognizes dialect utterances on the basis of the statistical simulation of vocabulary transformation and combinations of several dialect models. Previous dialect ASR systems were based on handcrafted dictionaries for several dialects, which involved costly processes. The proposed system statistically trains transformation rules between a common language and dialects, and simulates a dialect corpus for ASR on the basis of a machine translation technique. The rules are trained with small sets of parallel corpora to make up for the lack of linguistic resources on dialects. The proposed system also accepts mixed dialect utterances that contain a variety of vocabularies. In fact, spoken language is not a single dialect but a mixed dialect that is affected by the circumstances of speakersâ€™ backgrounds (e.g., native dialects of their parents or where they live). We addressed two methods to combine several dialects appropriately for each speaker. The first was recognition with language models of mixed dialects with automatically estimated weights that maximized the recognition likelihood. This method performed the best, but calculation was very expensive because it conducted grid searches of combinations of dialect mixing proportions that maximized the recognition likelihood. The second was integration of results of recognition from each single dialect language model. The improvements with this model were slightly smaller than those with the first method. Its calculation cost was, however, inexpensive and it worked in real-time on general workstations. Both methods achieved higher recognition accuracies for all speakers than those with the single dialect models and the common language model, and we could choose a suitable model for use in ASR that took into consideration the computational costs and recognition accuracies.","authors":["Naoki Hirayama","Koichiro Yoshino","Katsutoshi Itoyama","Shinsuke Mori"],"meta":["February 2015IEEE/ACM Transactions on Audio, Speech, and Language Processing 23(2):1-1","DOI:10.1109/TASLP.2014.2387414"],"references":["275475207_JNAS_Japanese_speech_corpus_for_large_vocabulary_continuous_speech_recognition_research","268378907_Design_of_a_Balanced_Corpus_of_Contemporary_Written_Japanese","228584595_Corpus_of_Spontaneous_Japanese_Its_design_and_evaluation","228463525_Speech-Based_Real-Time_Subtitling_Services","224641111_Speech_Recognition_on_Code-Switching_Among_the_Chinese_Dialects","221490493_Julius-An_open_source_real-time_large_vocabulary_recognition_engine","221481727_A_bootstrapping_approach_for_developing_language_model_of_new_spoken_dialogue_systems_by_selecting_web_texts","221480746_Automatic_transcription_system_for_meetings_of_the_Japanese_National_Congress","221419995_Speech_Recognition_for_Mobile_Devices_at_Google","333032182_Rural_Southern_white_accents","283602280_Automatic_estimation_of_dialect_mixing_ratio_for_dialect_speech_recognition","270877880_Sentence_Level_Dialect_Identification_in_Arabic","270877702_Statistical_Method_of_Building_Dialect_Language_Models_for_ASR_Systems","238000480_How_innovative_is_Apple's_new_voice_assistant_Siri","228944761_Multidialectal_Acoustic_Modeling_a_Comparative_Study","224668281_From_phonology_and_acoustic_properties_to_automatic_recognition_of_Cantonese","220874554_Dialect_Classification_for_Online_Podcasts_Fusing_Acoustic_and_Language_Based_Structural_and_Semantic_Information","3734420_A_post-processing_system_to_yield_reduced_word_error_rates_Recognizer_Output_Voting_Error_Reduction_ROVER","3703832_Statistical_dialect_classification_based_on_mean_phonetic_features","3618313_Improved_Backing-off_for_N-gram_Language_Modeling","2602251_Srilm_---_An_Extensible_Language_Modeling_Toolkit"]}