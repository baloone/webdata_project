{"id":"327874829_Statistical_quality_of_experience_analysis_On_planning_the_sample_size_and_statistical_significance_testing","abstract":"This paper analyzes how an experimenter can balance errors in subjective video quality tests between\nthe statistical power of finding an effect if it is there and not claiming that an effect is there if the effect is not there,\ni.e., balancing Type I and Type II errors. The risk of committing Type I errors increases with the number of\ncomparisons that are performed in statistical tests. We will show that when controlling for this and at the\nsame time keeping the power of the experiment at a reasonably high level, it is unlikely that the number of\ntest subjects that are normally used and recommended by the International Telecommunication Union (ITU),\ni.e., 15 is sufficient but the number used by the Video Quality Experts Group (VQEG), i.e., 24 is more likely\nto be sufficient. Examples will also be given for the influence of Type I error on the statistical significance of\ncomparing objective metrics by correlation. We also present a comparison between parametric and nonparametric\nstatistics. The comparison targets the question whether we would reach different conclusions on the statistical\ndifference between the video quality ratings of different video clips in a subjective test, based on the\ncomparison between the student T-test and the Mann–Whitney U-test. We found that there was hardly a difference\nwhen few comparisons are compensated for, i.e., then almost the same conclusions are reached. When\nthe number of comparisons is increased, then larger and larger differences between the two methods are\nrevealed. In these cases, the parametric T-test gives clearly more significant cases, than the nonparametric\ntest, which makes it more important to investigate whether the assumptions are met for performing a certain\ntest.","authors":["Kjell Brunnström","Marcus Barkowsky"],"meta":["September 2018Journal of Electronic Imaging 27(05):1","DOI:10.1117/1.JEI.27.5.053013"],"references":["299467953_Performance_measure_of_image_and_video_quality_assessment_algorithms_Subjective_root-mean-square_error","273900406_Evaluation_of_Statistical_Inference_Tests_Applied_to_Subjective_Audio_Quality_Data_With_Small_Sample_Size","221995234_Controlling_The_False_Discovery_Rate_-_A_Practical_And_Powerful_Approach_To_Multiple_Testing","318393712_R_A_Language_and_Environment_for_Statistical_Computing","313459531_The_Bayesian_New_Statistics_Hypothesis_testing_estimation_meta-analysis_and_power_analysis_from_a_Bayesian_perspective","289638001_'pwr'_Basic_functions_for_power_analysis","275946347_Quality_of_Experience_of_Adaptive_Video_Streaming_Investigation_in_Service_Parameters_and_Subjective_Quality_Assessment_Methodology","260660604_Continuous_assessment_of_time-varying_image_quality","258305139_R_in_Action_Data_Analysis_and_Graphics_with_R","246340725_Graphic_Scaling_and_Validity_of_Japanese_Descriptive_Terms_Used_in_Subjective-Evaluation_Tests","243783742_Designing_Experiments_and_Analyzing_Data_A_Model_Comparison_Perspective","243713879_The_Validity_of_CCIR_Quality_Indicators_along_a_Graphical_Scale","238416987_Retrospective_Power_Analysis","224194967_Study_of_Rating_Scales_for_Subjective_Quality_Assessment_of_High-Definition_Video","221678016_Psychophysical_Analysis","216300794_A_Simple_Sequentially_Rejective_Multiple_Test_Procedure","51999250_The_Control_of_The_False_Discovery_Rate_in_Multiple_Testing_Under_Dependency","6720907_A_Statistical_Evaluation_of_Recent_Full_Reference_Image_Quality_Assessment_Algorithms","5437123_Consultants'_forum_Should_post_hoc_sample_size_calculations_be_done"]}