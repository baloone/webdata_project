{"id":"328180820_Attention-Mechanism-Containing_Neural_Networks_for_High-Resolution_Remote_Sensing_Image_Classification","abstract":"A deep neural network is suitable for remote sensing image pixel-wise classification because it effectively extracts features from the raw data. However, remote sensing images with higher spatial resolution exhibit smaller inter-class differences and greater intra-class differences; thus, feature extraction becomes more difficult. The attention mechanism, as a method that simulates the manner in which humans comprehend and perceive images, is useful for the quick and accurate acquisition of key features. In this study, we propose a novel neural network that incorporates two kinds of attention mechanisms in its mask and trunk branches; i.e., control gate (soft) and feedback attention mechanisms, respectively, based on the branchesâ€™ primary roles. Thus, a deep neural network can be equipped with an attention mechanism to perform pixel-wise classification for very high-resolution remote sensing (VHRRS) images. The control gate attention mechanism in the mask branch is utilized to build pixel-wise masks for feature maps, to assign different priorities to different locations on different channels for feature extraction recalibration, to apply stress to the effective features, and to weaken the influence of other profitless features. The feedback attention mechanism in the trunk branch allows for the retrieval of high-level semantic features. Hence, additional aids are provided for lower layers to re-weight the focus and to re-update higher-level feature extraction in a target-oriented manner. These two attention mechanisms are fused to form a neural network module. By stacking various modules with different-scale mask branches, the network utilizes different attention-aware features under different local spatial structures. The proposed method is tested on the VHRRS images from the BJ-02, GF-02, Geoeye, and Quickbird satellites, and the influence of the network structure and the rationality of the network design are discussed. Compared with other state-of-the-art methods, our proposed method achieves competitive accuracy, thereby proving its effectiveness.","authors":["Rudong Xu","Tao Yiting","Zhongyuan Lu","Yanfei Zhong"],"meta":["October 2018Remote Sensing 10(10):1602","DOI:10.3390/rs10101602"],"references":["325266390_DenseNet-Based_Depth-Width_Double_Reinforced_Deep_Learning_Neural_Network_for_High-Resolution_Remote_Sensing_Image_Per-Pixel_Classification","323156250_Remote_Sensing_Scene_Classification_Based_on_Convolutional_Neural_Networks_Pre-Trained_Using_Attention-Guided_Sparse_Filters","338512016_Dual_Attention_Network_for_Scene_Segmentation","329743809_Convolutional_Neural_Networks_with_Alternately_Updated_Clique","327003493_Attention_CoupleNet_Fully_Convolutional_Attention_Coupling_Network_for_Object_Detection","322994662_Hyperspectral_Image_Classification_With_Deep_Feature_Fusion_Network","321789494_An_Unsupervised_Convolutional_Feature_Fusion_Network_for_Deep_Representation_of_Remote_Sensing_Images","321630230_A_new_deep_convolutional_neural_network_for_fast_hyperspectral_image_classification","321092808_Object-Part_Attention_Model_for_Fine-Grained_Image_Classification","319770395_An_Analysis_of_Single-Layer_Networks_in_Unsupervised_Feature_Learning"]}