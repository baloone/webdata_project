{"id":"315454825_Cooperating_with_Machines","abstract":"Since Alan Turing envisioned Artificial Intelligence (AI) [1], a major driving force behind technical progress has been competition with human cognition. Historical milestones have been frequently associated with computers matching or outperforming humans in difficult cognitive tasks (e.g. face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.g. Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]). In contrast, less attention has been given to developing autonomous machines that establish mutually cooperative relationships with people who may not share the machine's preferences. A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts. Here, we combine a state-of-the-art machine-learning algorithm with novel mechanisms for generating and acting on signals to produce a new learning algorithm that cooperates with people and other machines at levels that rival human cooperation in a variety of two-player repeated stochastic games. This is the first general-purpose algorithm that is capable, given a description of a previously unseen game environment, of learning to cooperate with people within short timescales in scenarios previously unanticipated by algorithm designers. This is achieved without complex opponent modeling or higher-order theories of mind, thus showing that flexible, fast, and general human-machine cooperation is computationally achievable using a non-trivial, but ultimately simple, set of algorithmic mechanisms.","authors":["Jacob Crandall","Mayada Oudah","Tennom","Fatimah Ishowo-Oloko"],"meta":["January 2018Nature Communications 9(1)","DOI:10.1038/s41467-017-02597-8"],"references":["344472261_Theory_of_Moves","338039379_XAI-Explainable_artificial_intelligence","331456158_Incorporating_Fairness_into_Game_Theory_and_Economics","320640959_Heads-up_limit_Hold'em_Poker_is_solved","318494451_Computing_Machinery_and_Intelligence","318201010_I'm_just_a_soul_whose_intentions_are_good_The_role_of_communication_in_noisy_repeated_games","313650896_Multi-agent_Reinforcement_Learning_in_Sequential_Social_Dilemmas","313642261_Multi-agent_Reinforcement_Learning_in_Sequential_Social_Dilemmas","313362582_A_Polynomial-time_Nash_Equilibrium_Algorithm_for_Repeated_Stochastic_Games","312157307_DeepStack_Expert-Level_Artificial_Intelligence_in_No-Limit_Poker","292074166_Mastering_the_game_of_Go_with_deep_neural_networks_and_tree_search","304645915_behavioural_game_theory","303904981_Group_Norms_for_Multi-Agent_Organisations","300905632_Efficient_Model_Learning_from_Joint-Action_Demonstrations_for_Human-Robot_Collaborative_Tasks","296112844_A_little_artificial_intelligence"]}