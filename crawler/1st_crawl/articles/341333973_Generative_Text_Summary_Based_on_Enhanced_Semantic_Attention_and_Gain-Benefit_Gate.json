{"id":"341333973_Generative_Text_Summary_Based_on_Enhanced_Semantic_Attention_and_Gain-Benefit_Gate","abstract":"Generative text summary is an important branch of natural language processing. Aiming at the problems of insufficient use of semantic information, insufficient summary precision and the problem of semantics-loss in the current generated text summary method, an enhanced semantic model is proposed based on dual-encoder, which can provide richer semantic information for sequence-to-sequence architecture through dual-encoder. The enhanced attention architecture with dual-channel semantics is optimized, and the empirical distribution and Gain-Benefit gate are built for decoding. In addition, the position embedding and word embedding are merged into the word embedding technology, and the TF-IDF(term frequency-inverse document frequency), part of speech, key score are added to word’s feature. Meanwhile, the optimal dimension of word embedding is optimized. This paper aims to optimize the traditional sequence mapping and word feature representation, enhance the model’s semantic understanding, and improve the quality of the summary. The LCSTS and SOGOU datasets are used to validate proposed method. The experimental results show that the proposed method can improve the performance of the ROUGE evaluation system by 10–13 percentage points compared with other listed algorithms. We can observe that the semantic understanding of the text summaries is more accurate and the generation effect is better, which has a better application prospect.","authors":["Jianli Ding","Yang Li","Huiyu Ni","Zhengquan Yang"],"meta":["May 2020IEEE Access 8:1-1","DOI:10.1109/ACCESS.2020.2994092"],"references":["335877676_MS-Pointer_Network_Abstractive_Text_Summary_Based_on_Multi-Head_Self-Attention","335764474_Massively_Multilingual_Sentence_Embeddings_for_Zero-Shot_Cross-Lingual_Transfer_and_Beyond","332450689_Synchronous_Bidirectional_Neural_Machine_Translation","331749874_Generative_Adversarial_Network_with_Policy_Gradient_for_Text_Summarization","336998273_Pretraining-Based_Natural_Language_Generation_for_Text_Summarization","327268836_A_Reading_Comprehension_Style_Question_Answering_Model_Based_On_Attention_Mechanism","325913845_Chinese_Short_Text_Summary_Generation_Model_Integrating_Multi-Level_Semantic_Information","321571322_Deep_Semantic_Role_Labeling_with_Self-Attention","321057098_A_Neural_Approach_to_Source_Dependency-Based_Context_Model_for_Statistical_Machine_Translation","318740838_Get_To_The_Point_Summarization_with_Pointer-Generator_Networks"]}