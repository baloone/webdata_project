{"id":"5596000_Reinforcement_Learning_An_Introduction","abstract":"Of several responses made to the same situation, those which are accompanied or closely followed by satisfaction to the animal will, other things being equal, be more firmly connected with the situation, so that, when it recurs, they will be more likely to recur; those which are accompanied or closely followed by discomfort to the animal will, other things being equal, have their connections with that situation weakened, so that, when it recurs, they will be less likely to occur. The greater the satisfaction or discomfort, the greater the strengthening or weakening of the bond. (Thorndike, 1911) The idea of learning to make appropriate responses based on reinforcing events has its roots in early psychological theories such as Thorndike's \"law of effect\" (quoted above). Although several important contributions were made in the 1950s, 1960s and 1970s by illustrious luminaries such as Bellman, Minsky, Klopf and others (Farley and Clark, 1954; Bellman, 1957; Minsky, 1961; Samuel, 1963; Michie and Chambers, 1968; Grossberg, 1975; Klopf, 1982), the last two decades have wit- nessed perhaps the strongest advances in the mathematical foundations of reinforcement learning, in addition to several impressive demonstrations of the performance of reinforcement learning algo- rithms in real world tasks. The introductory book by Sutton and Barto, two of the most influential and recognized leaders in the field, is therefore both timely and welcome. The book is divided into three parts. In the first part, the authors introduce and elaborate on the es- sential characteristics of the reinforcement learning problem, namely, the problem of learning \"poli- cies\" or mappings from environmental states to actions so as to maximize the amount of \"reward\"","authors":["Richard Sutton","Andrew G. Barto"],"meta":["February 1998IEEE Transactions on Neural Networks 9(5):1054","DOI:10.1109/TNN.1998.712192","SourcePubMed"],"references":["14429274_A_Framework_for_Mesencephalic_Dopamine_Systems_Based_on_Predictive_Hebbian_Learning","226853334_A_Survey_of_Algorithmic_Methods_for_Partially_Observed_Markov_Decision_Processes","223650531_A_Theory_of_Cerebellar_Function","222460895_A_time-delay_neural_network_architecture_for_isolated_word_recognition","221605762_A_Unified_Theory_of_Heuristic_Evaluation_Functions_and_its_Application_to_Learning","201976486_Some_Aspects_of_the_Sequential_Design_of_Experiments","2799903_Markov_Games_as_a_Framework_for_Multi-Agent_Reinforcement_Learning"]}