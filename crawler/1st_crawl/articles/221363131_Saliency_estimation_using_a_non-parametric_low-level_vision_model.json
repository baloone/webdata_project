{"id":"221363131_Saliency_estimation_using_a_non-parametric_low-level_vision_model","abstract":"Many successful models for predicting attention in a scene involve three main steps: convolution with a set of filters, a center-surround mechanism and spatial pooling to construct a saliency map. However, integrating spatial information and justifying the choice of various parameter values remain open problems. In this paper we show that an efficient model of color appearance in human vision, which contains a principled selection of parameters as well as an innate spatial pooling mechanism, can be generalized to obtain a saliency model that outperforms state-of-the-art models. Scale integration is achieved by an inverse wavelet transform over the set of scale-weighted center-surround responses. The scale-weighting function (termed ECSF) has been optimized to better replicate psychophysical data on color appearance, and the appropriate sizes of the center-surround inhibition windows have been determined by training a Gaussian Mixture Model on eye-fixation data, thus avoiding ad-hoc parameter selection. Additionally, we conclude that the extension of a color appearance model to saliency estimation adds to the evidence for a common low-level visual front-end for different visual tasks.","authors":["Naila Murray","Maria Vanrell","Xavier Otazu","C. Alejandro PÃ¡rraga"],"meta":["June 2011Proceedings / CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE Computer Society Conference on Computer Vision and Pattern Recognition","DOI:10.1109/CVPR.2011.5995506","SourceDBLP","Conference: The 24th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2011, Colorado Springs, CO, USA, 20-25 June 2011"],"references":["224301400_Level_set_hyperspectral_image_segmentation_using_spectral_information_divergence-based_best_band_selection","221619044_Saliency_Based_on_Information_Maximization","221618431_A_Nonparametric_Approach_to_Bottom-Up_Visual_Saliency","47675540_Toward_a_unified_chromatic_induction_model","23790320_SUN_A_Bayesian_framework_for_saliency_using_nature_statistics","312116089_Bottom-up_saliency_is_a_discriminant_process","275439442_The_spatial_tuning_of_chromatic_adaptation","232628093_Nonparametric_bottom-Up_saliency_detection_by_self-resemblance","221109992_Learning_to_Predict_Where_Humans_Look","40869094_Static_and_Space-time_Visual_Saliency_Detection_by_Self-Resemblance","23790302_On_the_plausibility_of_the_discriminant_center-surround_hypothesis_for_visual_saliency","19162987_The_contrast_sensitivity_of_human_color_vision_to_red-green_and_blue-yellow_chromatic_gratings","19324926_Shifts_in_Selective_Visual_Attention_Towards_the_Underlying_Neural_Circuitry","17363995_On_the_Existence_of_Neurons_in_the_Human_Visual_System_Selectively_Sensitive_to_the_Orientation_and_Size_of_Retinal_Images","13815618_Similar_mechanisms_underlie_simultaneous_brightness_contrast_and_grating_induction"]}