{"id":"291437015_Model-Coupled_Autoencoder_for_Time_Series_Visualisation","abstract":"We present an approach for the visualisation of a set of time series that\ncombines an echo state network with an autoencoder. For each time series in the\ndataset we train an echo state network, using a common and fixed reservoir of\nhidden neurons, and use the optimised readout weights as the new\nrepresentation. Dimensionality reduction is then performed via an autoencoder\non the readout weight representations. The crux of the work is to equip the\nautoencoder with a loss function that correctly interprets the reconstructed\nreadout weights by associating them with a reconstruction error measured in the\ndata space of sequences. This essentially amounts to measuring the predictive\nperformance that the reconstructed readout weights exhibit on their\ncorresponding sequences when plugged back into the echo state network with the\nsame fixed reservoir. We demonstrate that the proposed visualisation framework\ncan deal both with real valued sequences as well as binary sequences. We derive\nmagnification factors in order to analyse distance preservations and\ndistortions in the visualisation space. The versatility and advantages of the\nproposed method are demonstrated on datasets of time series that originate from\ndiverse domains.","authors":["Nikolaos Gianniotis","Sven D. KÃ¼gler","Peter Tino","Kai Lars Polsterer"],"meta":["January 2016Neurocomputing 192","DOI:10.1016/j.neucom.2016.01.086","SourcearXiv","Project: Dimensionality reduction"],"references":["284514502_Minimum_complexity_echo_state_network","275974870_Autoencoding_Time_Series_for_Visualisation","260021565_Model-based_Kernel_for_Efficient_Time_Series_Analysis","251566872_Time-Series_Classification_Through_Histograms_of_Symbolic_Polynomials","236029704_Learning_in_the_Model_Space_for_Fault_Diagnosis","228339739_Viualizing_data_using_t-SNE","224881746_Magnification_Factors_for_the_GTM_Algorithm","220320479_Probability_Product_Kernels","47791151_Minimum_complexity_echo_state_network_IEEE_Trans_Neural_Netw","1786923_A_model-independent_analysis_of_the_variability_of_GRS_1915105","261343067_Comparative_study_of_visualisation_methods_for_temporal_data","248512106_Pattern_Recognition_and_Machine_Learning_Errata","227660503_Nonlinear_Principal_Component_Analysis_Using_Auto-Associative_Neural_Networks","222526235_Jaeger_H_Reservoir_computing_approaches_to_recurrent_neural_network_training_Computer_Science_Review_3_127-149","220320714_Probabilistic_Non-linear_Principal_Component_Analysis_with_Gaussian_Process_Latent_Variable_Models","51534966_Echo_State_Gaussian_Process","50336131_Information_Theory_And_Statistics","44360813_Information_theory_and_statistics_Solomon_Kullback","2845238_Stochastic_Models_That_Separate_Fractal_Dimension_and_Hurst_Effect","2463681_Exploiting_Generative_Models_in_Discriminative_Classifiers","2166741_Stochastic_Models_That_Separate_Fractal_Dimension_and_the_Hurst_Effect"]}