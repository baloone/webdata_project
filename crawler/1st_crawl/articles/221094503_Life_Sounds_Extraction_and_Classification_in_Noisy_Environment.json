{"id":"221094503_Life_Sounds_Extraction_and_Classification_in_Noisy_Environment","abstract":"This paper deals with the sound event detection in a noisy environment and presents a first classification approach. Detection is the first step of our sound analysis system and is necessary to extract the significant sounds before ini- tiating the classification step. We present three original event detection algorithms. Among these algorithms, one is based on the wavelet and gives the best performances. We evaluate and compare their performance in a noisy en- vironment with the state of the art algorithms in the field. Then, we present a statistical study to obtain the acous- tical parameters necessary for the training and, the sound classification results. The detection algorithms and sound classification are applied to medical telemonitoring. We re- place video camera by microphones surveying life sounds in order to preserve patient's privacy. In this paper, we present a system of everyday life sound classification. In order to reduce the calculation time nec- essary for a multi-channel real time system, our sound ex- traction process is divided in two steps: detection and clas- sification. The sound event detection is a complex task be- cause the audio signals occur in a noisy environment. In detection step, we compare the performances of the state of the art algorithms and of the three new proposed detec- tion algorithms in the real noisy conditions. The best per- formances resulted from our proposed algorithm based on the wavelet analysis of sound that allows us to eliminate the noise influence on the detection results. In recognition step using a statistical study applied to acoustical parame- ters, we can choose the appropriate parameters that give the best classification results with a GMM system.","authors":["Michel Vacher","Dan Istrate","Laurent Besacier","Jean-Fran√ßois Serignat"],"meta":["July 2003","SourceDBLP","Conference: Signal and Image Processing (SIP 2003), Proceedings of the IASTED International Conference, August 13-15, 2003, Honolulu, HI, USA"],"references":["29460559_Analysis_of_Speech_Recognition_Techniques_for_use_in_a_Non-Speech_Sound_Recognition_System","8537683_A_system_for_automatic_measurement_of_circadian_activity_deviations_in_telemedicine","2565289_Smart_Audio_Sensor_for_Telemedicine","285976647_Comparison_of_Parametric_Representations_for_Monosyllabic_Word_Recognition_in_Continuously_Spoken_Sentences","245897528_Detection_and_recognition_of_impulsive_sou_nds_signals","245099594_A_system_for_automatic_measurement_of_circadian_activity_in_telemedicine","223836611_Speaker_identification_and_verification_using_Gaussian_Mixture_Speaker_Models","3914192_Ultrasonic_detection_using_wideband_discrete_wavelet_transform","2558566_Overview_Of_The_2000-2001_Elisa_Consortium_Research_Activities"]}