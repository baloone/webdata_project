{"id":"335788783_Wireless_Network_Intelligence_at_the_Edge","abstract":"Fueled by the availability of more data and computing power, recent breakthroughs in cloud-based machine learning (ML) have transformed every aspect of our lives from face recognition and medical diagnosis to natural language processing. However, classical ML exerts severe demands in terms of energy, memory and computing resources, limiting their adoption for resource constrained edge devices. The new breed of intelligent devices and high-stake applications (drones, augmented/virtual reality, autonomous systems, etc.), requires a novel paradigm change calling for distributed, low-latency and reliable ML at the wireless network edge (referred to as edge ML). In edge ML, training data is unevenly distributed over a large number of edge nodes, which have access to a tiny fraction of the data. Moreover training and inference are carried out collectively over wireless links, where edge devices communicate and exchange their learned models (not their private data). In a first of its kind, this article explores key building blocks of edge ML, different neural network architectural splits and their inherent tradeoffs, as well as theoretical and technical enablers stemming from a wide range of mathematical disciplines. Finally, several case studies pertaining to various high-stake applications are presented demonstrating the effectiveness of edge ML in unlocking the full potential of 5G and beyond.","authors":["Jihong Park","Sumudu Samarakoon","Mehdi Bennis","m√©rouane Debbah"],"meta":["September 2019Proceedings of the IEEE 107(11)","DOI:10.1109/JPROC.2019.2941458"],"references":["337618049_Distributed_Federated_Learning_for_Ultra-Reliable_Low-Latency_Vehicular_Communications","335602129_GADMM_Fast_and_Communication_Efficient_Framework_for_Distributed_Machine_Learning","345478455_Supporting_Very_Large_Models_using_Automatic_Dataflow_Graph_Partitioning","345474529_A_Statistical_Learning_Approach_to_Ultra-Reliable_Low_Latency_Communication","341248487_Communication_Efficient_Framework_for_Decentralized_Machine_Learning","341094192_Federated_Learning_Challenges_Methods_and_Future_Directions","339837493_Geometry_of_Energy_Landscapes_and_the_Optimizability_of_Deep_Neural_Networks","339562699_Massive_Autonomous_UAV_Path_Planning_A_Neural_Network_Based_Mean-Field_Game_Theoretic_Approach","336228851_Risk-averse_Distributional_Reinforcement_Learning_A_CVaR_Optimization_Approach","335572682_MD-GAN_Multi-Discriminator_Generative_Adversarial_Networks_for_Distributed_Datasets","334520749_Federated_Reinforcement_Distillation_with_Proxy_Experience_Memory","334520330_Multi-hop_Federated_Private_Data_Augmentation_with_Sample_Compression","334482229_Client_Selection_for_Federated_Learning_with_Heterogeneous_Resources_in_Mobile_Edge","333719659_Blockchained_On-Device_Federated_Learning","334667710_In-Edge_AI_Intelligentizing_Mobile_Edge_Computing_Caching_and_Communication_by_Federated_Learning"]}