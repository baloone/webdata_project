{"id":"331569180_Explanations_by_Arbitrated_Argumentative_Dispute","abstract":"Explaining outputs determined algorithmically by machines is one of the most pressing and studied problems in Artificial Intelligence (AI) nowadays, but the equally pressing problem of using AI to explain outputs determined by humans is less studied. In this paper we advance a novel methodology integrating case-based reasoning and computational argumentation from AI to explain outcomes, determined by humans or by machines, indifferently, for cases characterised by discrete (static) features and/or (dynamic) stages. At the heart of our methodology lies the concept of arbitrated argumentative disputesbetween two fictitious disputants arguing, respectively, for or against a case's output in need of explanation, and where this case acts as an arbiter. Specifically, in explaining the outcome of a case in question, the disputants put forward as arguments relevant cases favouring their respective positions, with arguments/cases conflicting due to their features, stages and outcomes, and the applicability of arguments/cases arbitrated by the features and stages of the case in question. We in addition use arbitrated dispute trees to identify the excess features that help the winning disputant to win the dispute and thus complement the explanation. We evaluate our novel methodology theoretically, proving desirable properties thereof, and empirically, in the context of primary legislation in the United Kingdom (UK), concerning the passage of Bills that may or may not become laws. High-level factors underpinning a Bill's passage are its content-agnostic features such as type, number of sponsors, ballot order, as well as the UK Parliament's rules of conduct. Given high numbers of proposed legislation (hundreds of Bills a year), it is hard even for legal experts to explain on a large scale why certain Bills pass or not. We show how our methodology can address this problem by automatically providing high-level explanations of why Bills pass or not, based on the given Bills and their content-agnostic features.","authors":["Kristijonas Cyras","David Birch","Yike Guo","Francesca Toni"],"meta":["March 2019Expert Systems with Applications 127(1)","DOI:10.1016/j.eswa.2019.03.012"],"references":["346303432_Context-based_and_Explainable_Decision_Making_with_Argumentation","327837762_Explanatory_Predictions_with_Artificial_Neural_Networks_and_Argumentation","320163544_Explainable_Planning","317821828_Explanation_in_Artificial_Intelligence_Insights_from_the_Social_Sciences","303865053_A_method_for_explaining_Bayesian_networks_for_legal_evidence_with_scenarios","299582880_A_methodology_for_designing_systems_to_reason_with_legal_cases_using_Abstract_Dialectical_Frameworks","257520620_A_Carneades_reconstruction_of_Popov_v_Hayashi","220660596_Agents_that_argue_and_explain_classifications","220637908_Explanation_and_Argumentation_CapabilitiesTowards_the_Creation_of_More_Persuasive_Agents","220637584_Explanation_in_Case-Based_Reasoning-Perspectives_and_Goals","338039379_XAI-Explainable_artificial_intelligence","335697695_Argumentation_for_Explainable_Scheduling","329384965_From_Fine-Grained_Properties_to_Broad_Principles_for_Gradual_Argumentation_a_Principled_Spectrum","327837582_Explanation_for_Case-Based_Reasoning_via_Abstract_Argumentation","327837566_Abstract_Argumentation_for_Case-Based_Reasoning","327813567_An_Explainable_Multi-Attribute_Decision_Model_based_on_Argumentation","326922498_Handbook_of_Legal_Reasoning_and_Argumentation","326208362_Model-free_Model-based_and_General_Intelligence","326202439_A_Symbolic_Approach_to_Explaining_Bayesian_Network_Classifiers","326202262_Argumentation-Based_Recommendations_Fantastic_Explanations_and_How_to_Find_Them","326201500_Conversational_Explanations_of_Machine_Learning_Predictions_Through_Class-contrastive_Counterfactual_Statements","322929400_Visual_Interpretability_for_Deep_Learning_a_Survey","313555181_On_Explanations_for_Non-Acceptable_Arguments","311550931_Providing_Arguments_in_Discussions_on_the_Basis_of_the_Prediction_of_Human_Argumentative_Behavior","308130845_A_two-phase_method_for_extracting_explanatory_arguments_from_Bayesian_networks","288771302_On_computing_explanations_in_abstract_argumentation","288146967_Formal_arguments_preferences_and_natural_language_interfaces_to_humans_An_empirical_evaluation","262677460_Argument-based_mixed_recommenders_and_their_application_to_movie_suggestion","257404849_Formalizing_dialectical_explanation_support_for_argument-based_reasoning_in_knowledge-based_systems","226561196_Semantics_of_Abstract_Argument_Systems","226525581_Proof_Theories_and_Algorithms_for_Abstract_Argumentation_Frameworks","225570395_An_Efficient_Implementation_of_Sugiyama's_Algorithm_for_Layered_Graph_Drawing","223206895_Computing_ideal_sceptical_argumentation","222823033_Dialectic_proof_procedures_for_assumption-based_admissible_argumentation","222464284_On_the_acceptability_of_arguments_and_its_fundamental_role_in_nonmonotonic_reasoning_logic_programming_and_n-person_games_1","222428444_Using_Arguments_for_Making_and_Explaining_Decisions","221621736_Case-Based_Reasoning"]}