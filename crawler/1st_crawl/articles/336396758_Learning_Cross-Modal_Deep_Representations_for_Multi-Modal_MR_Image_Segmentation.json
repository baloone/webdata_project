{"id":"336396758_Learning_Cross-Modal_Deep_Representations_for_Multi-Modal_MR_Image_Segmentation","abstract":"Multi-modal magnetic resonance imaging (MRI) is essential in clinics for comprehensive diagnosis and surgical planning. Nevertheless, the segmentation of multi-modal MR images tends to be time-consuming and challenging. Convolutional neural network (CNN)-based multi-modal MR image analysis commonly proceeds with multiple down-sampling streams fused at one or several layers. Although inspiring performance has been achieved, the feature fusion is usually conducted through simple summation or concatenation without optimization. In this work, we propose a supervised image fusion method to selectively fuse the useful information from different modalities and suppress the respective noise signals. Specifically, an attention block is introduced as guidance for the information selection. From the different modalities, one modality that contributes most to the results is selected as the master modality, which supervises the information selection of the other assistant modalities. The effectiveness of the proposed method is confirmed through breast mass segmentation in MR images of two modalities and better segmentation results are achieved compared to the state-of-the-art methods.","authors":["Cheng Li","Hui Sun","Zaiyi Liu","Meiyun Wang"],"meta":["October 2019","DOI:10.1007/978-3-030-32245-8_7","In book: Medical Image Computing and Computer Assisted Intervention â€“ MICCAI 2019 (pp.57-65)"],"references":["324354680_HyperDense-Net_A_Hyper-Densely_Connected_CNN_for_Multi-Modal_Image_Segmentation","313857891_A_Survey_on_Deep_Learning_in_Medical_Image_Analysis","308311897_FuseNet_Incorporating_Depth_into_Semantic_Segmentation_via_Fusion-Based_CNN_Architecture","329741351_Progressively_Complementarity-Aware_Fusion_Network_for_RGB-D_Salient_Object_Detection","327629769_One-Pass_Multi-task_Convolutional_Neural_Networks_for_Efficient_Brain_Tumor_Segmentation_21st_International_Conference_Granada_Spain_September_16-20_2018_Proceedings_Part_III","327629270_Enhancing_Clinical_MRI_Perfusion_Maps_with_Data-Driven_Maps_of_Complementary_Nature_for_Lesion_Outcome_Prediction_21st_International_Conference_Granada_Spain_September_16-20_2018_Proceedings_Part_III","311612099_Paying_More_Attention_to_Attention_Improving_the_Performance_of_Convolutional_Neural_Networks_via_Attention_Transfer","305193694_U-Net_Convolutional_Networks_for_Biomedical_Image_Segmentation","304665638_Fully_convolutional_networks_for_multi-modality_isointense_infant_brain_image_segmentation","301921832_Fully_convolutional_networks_for_semantic_segmentation","273387909_Distilling_the_Knowledge_in_a_Neural_Network","270662540_Deep_Convolutional_Neural_Networks_for_Multi-Modality_Isointense_Infant_Brain_Image_Segmentation","260370153_Using_T2-Weighted_Sequences_to_More_Accurately_Characterize_Breast_Masses_Seen_on_MRI","258374356_Rich_Feature_Hierarchies_for_Accurate_Object_Detection_and_Semantic_Segmentation","14120089_Heywang-Kobrunner_SH_Viehweg_P_Heinig_A_Kuchler_CContrast-enhanced_MRI_of_the_breast_accuracy_value_controversies_solutions_Eur_J_Radiol_24_94-108"]}