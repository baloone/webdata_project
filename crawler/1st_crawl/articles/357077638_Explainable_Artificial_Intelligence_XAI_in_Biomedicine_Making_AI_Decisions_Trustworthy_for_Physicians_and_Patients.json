{"id":"357077638_Explainable_Artificial_Intelligence_XAI_in_Biomedicine_Making_AI_Decisions_Trustworthy_for_Physicians_and_Patients","abstract":"The use of artificial intelligence (AI) systems in biomedical and clinical settings can disrupt the traditional doctor-patient relationship, which is based on trust and transparency in medical advice and therapeutic decisions. When the diagnosis or selection of a therapy is no longer made solely by the physician, but to a significant extent by a machine using algorithms, decisions become untransparent. Skill learning is the most common application of machine learning algorithms in clinical decision making. These are a class of very general algorithms (artificial neural networks, classifiers, etc.) which are tuned based on examples to optimize the classification of new, unseen cases. It is pointless to ask for an explanation for a decision. A detailed understanding of the mathematical details of an AI algorithm may be possible for experts in statistics or computer science. But when it comes to the fate of human beings, this \"developer's explanation\" is not sufficient. The concept of explainable AI (XAI) as a solution to this problem is attracting increasing scientific and regulatory interest. This review focuses on the requirement that XAIs must be able to explain in detail the decisions made by the AI to the experts in the field.","authors":["Jörn Lötsch","Dario Kringel","Alfred Ultsch"],"meta":["December 2021","DOI:10.3390/biomedinformatics2010001","Project: Biomedinformatics - A new peer-reviewed open access journal published by MDPI"],"references":["353807239_Visually_guided_preprocessing_of_bioanalytical_laboratory_data_using_an_interactive_R_notebook_pguIMP","353464157_Optimal_distribution-preserving_downsampling_of_large_biomedical_data_sets_opdisDownsampling","353045633_Machine_learning_liver-injuring_drug_interactions_with_non-steroidal_anti-inflammatory_drugs_NSAIDs_from_a_retrospective_electronic_health_record_EHR_cohort","351791386_Checklist_for_responsible_deep_learning_modeling_of_medical_images_based_on_COVID-19_detection_studies","350285459_Artificial_intelligence_Deep_learning_in_oncological_radiomics_and_challenges_of_interpretability_and_data_harmonization","348706544_Explainable_AI_and_Multi-Modal_Causability_in_Medicine","348032815_Explainable_AI_A_Review_of_Machine_Learning_Interpretability_Methods","347238741_Emergenz_Von_der_Unvorhersagbarkeit_zur_Selbstorganisation_4_Auflage","346679179_Robustness_and_Explainability_of_Artificial_Intelligence_from_technical_to_policy_solutions","345629230_Black_Box_to_Conversational_Machine_Learning_Ondansetron_Reduces_Risk_of_Hospital-Acquired_Venous_Thromboembolism"]}