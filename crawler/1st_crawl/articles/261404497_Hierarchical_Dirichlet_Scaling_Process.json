{"id":"261404497_Hierarchical_Dirichlet_Scaling_Process","abstract":"We present the hierarchical Dirichlet scaling process (HDSP), a Bayesian\nnonparametric mixed membership model for multi-labeled data. We construct the\nHDSP based on the gamma representation of the hierarchical Dirichlet process\n(HDP) which allows scaling the mixture components. With such construction, HDSP\nallocates a latent location to each label and mixture component in a metric\nspace, and uses the distance between them to guide membership probabilities. We\ndevelop a variational Bayes algorithm for the approximate posterior inference\nof the HDSP. Through experiments on synthetic datasets as well as datasets of\nnewswire, medical journal articles, and Wikipedia, we show that the HDSP\nresults in better predictive performance than HDP, labeled LDA and partially\nlabeled LDA.","authors":["Dongwoo Kim","Alice Oh"],"meta":["March 2017Machine Learning 3(3)","DOI:10.1007/s10994-016-5621-5","SourcearXiv"],"references":["329650090_Gaussian_Processes_for_Machine_Learning","319770229_Auto-Encoding_Variational_Bayes","289303642_Distributed_stochastic_gradient_MCMC","284477399_Variational_Inference_for_Dirichlet_Process_Mixtures","284476307_Variational_Gaussian_Process","271454998_Labeled_LDA","269996418_Gaussian_Processes_for_Machine_Learning_Adaptive_Computation_and_Machine_Learning","265943277_The_Doubly_Correlated_Nonparametric_Topic_Model","262157385_Latent_Dirichlet_Allocation","259528495_Black_Box_Variational_Inference"]}