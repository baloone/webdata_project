{"id":"271513141_Support_Vector_Networks","abstract":"The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data. High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.","authors":["Corinna Cortes","VN Vapnik"],"meta":["September 1995Machine Learning 20(3):273-297","DOI:10.1023/A:1022627411411"],"references":["246929280_Neural-network_and_K-nearest-neighbor_Classifiers","260869480_The_Use_of_Multiple_Measurements_in_Taxonomic_Problems","248857140_Theoretical_Foundations_of_the_potential_function_method_in_pattern_recognition","243743707_Learning_Internal_Representations_by_Error_Propagation","239059398_Leaning_internal_representations_by_back-propagating_errors","236736807_Estimation_of_Dependences_Based_on_Empirical_Data","38366305_Classification_into_two_Multivariate_Normal_Distributions_with_Different_Covariance_Matrices","2439558_Handwritten_Digit_Recognition_with_a_Back-Propagation_Network"]}