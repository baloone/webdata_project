{"id":"301257976_A_Nonlinear_Label_Compression_and_Transformation_Method_for_Multi-label_Classification_Using_Autoencoders","abstract":"Multi-label classification targets the prediction of multiple interdependent and non-exclusive binary target variables. Transformation-based algorithms transform the data set such that regular single-label algorithms can be applied to the problem. A special type of transformation-based classifiers are label compression methods, which compress the labels and then mostly use single label classifiers to predict the compressed labels. So far, there are no compression-based algorithms that follow a problem transformation approach and address non-linear dependencies in the labels. In this paper, we propose a new algorithm, called Maniac (Multi-lAbel classificatioN usIng AutoenCoders), which extracts the non-linear dependencies by compressing the labels using autoencoders. We adapt the training process of autoencoders in a way to make them more suitable for a parameter optimization in the context of this algorithm. The method is evaluated on eight standard multi-label data sets. Experiments show that despite not producing a good ranking, Maniac generates a particularly good bipartition of the labels into positives and negatives. This is caused by rather strong predictions with either really high or low probability. Additionally, the algorithm seems to perform better given more labels and a higher label cardinality in the data set.","authors":["JÃ¶rg Wicker","Andrey Tyukin","Stefan Kramer"],"meta":["April 2016","DOI:10.1007/978-3-319-31753-3_27","Conference: Pacific-Asia Conference on Knowledge Discovery and Data Mining"],"references":["313656130_Correlation-based_pruning_of_stacked_binary_relevance_models_for_multi-label_learning","262323962_A_Genetic_Algorithm_for_Optimizing_the_Label_Ordering_in_Multi-label_Classifier_Chains","259367487_Large-Scale_Multi-label_Text_Classification_-_Revisiting_Neural_Networks","234800756_A_Shared_Task_Involving_Multi-label_Classification_of_Clinical_Free_Text","233780193_Multi-Label_Classification_Methods_for_Multi-Target_Regression","228386519_Effective_and_efficient_multilabel_classification_in_domains_with_large_number_of_labels","227049463_Inference_for_the_Generalization_Error","226649250_Random_k-Labelsets_An_Ensemble_Method_for_Multilabel_Classification","225986997_Mining_Multi-label_Data","221565489_Protein_Classification_with_Multiple_Algorithms","220723464_Multi-label_classification_of_music_into_emotions","316682495_Conditional_Restricted_Boltzmann_Machines_for_Multi-label_Learning_with_Incomplete_Labels","312735676_A_Deep_Interpretation_of_Classifier_Chains","300140821_Bi-directional_Representation_Learning_for_Multi-label_Classification","254006363_Multi-label_classification_using_boolean_matrix_decomposition","232628841_An_extensive_experimental_comparison_of_methods_for_multi-label_learning","224976748_Multilabel_Classification_with_Principal_Label_Space_Transformation","222709440_ML-KNN_A_lazy_learning_approach_to_multi-label_leaming","222430151_Learning_multi-label_scene_classification","221619768_A_Kernel_Method_for_Multi-Labelled_Classification","221112118_The_Enron_Corpus_A_New_Dataset_for_Email_Classification_Research","6912170_Reducing_the_Dimensionality_of_Data_with_Neural_Networks","3458009_Semantic_Annotation_and_Retrieval_of_Music_and_Sound_Effects","2543302_Knowledge_Discovery_in_Multi-Label_Phenotype_Data"]}