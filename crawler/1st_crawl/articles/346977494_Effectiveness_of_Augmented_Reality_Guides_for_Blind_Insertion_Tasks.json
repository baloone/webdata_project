{"id":"346977494_Effectiveness_of_Augmented_Reality_Guides_for_Blind_Insertion_Tasks","abstract":"Although many augmented reality (AR)-based assembly support systems have been proposed in academic research and industry, the effectiveness of AR to resolve the occlusion issue in the context of a blind assembly process remains an unexplored topic. Therefore, the present work investigates how AR can assist operators during the execution of blind manual assembly tasks. Specifically, an AR research set-up was designed to provide assistance in occlusion situations during a peg-in-hole task. The set-up featured a see-through device (HoloLens), which provides operators with two modes of visual augmentations that directly overlay on the assembly objects. The first mode referred to as the “wireframe overlay” displays the inner part of the objects, providing an inside view of the occluded parts, and the second one referred to as the “axes overlay,” displays the axes of the objects and their slots, indicating how to align the different parts during the assembly. The effectiveness of these AR visualizations was compared to a baseline augmentation-free situation in a controlled experiment. Thus, following a within-subject design, 30 participants performed a two-stages blind insertion task. Their performances represented by task completion time, insertion errors, and smoothness of the insertions were recorded. In addition, a post-questionnaire reported their subjective perception of task difficulty during the task and their preferences. Results indicated a strong acceptance of participants for AR visualizations that they rated as allowing them to perform the task more easily. However, no statistically significant differences in terms of objective performance measures were found. Yet, it was found that axes overlay produced smoother trajectories compared to the wireframe overlay, highlighting the potential effect of more abstract visualization aids.","authors":["Nawel Khenak","Jeanne Vézien","Patrick Bourdot"],"meta":["November 2020","DOI:10.3389/frvir.2020.588217"],"references":["338758602_Projection-Based_Augmented_Reality_Assistance_for_Manual_Electronic_Component_Assembly_Processes","330450961_Haptic_Augmented_Reality_HapticAR_for_assembly_guidance","310822551_Haptic_Auditory_or_Visual_Towards_Optimal_Error_Feedback_at_Manual_Assembly_Workplaces","310820161_Interactive_worker_assistance_comparing_the_effects_of_in-situ_projection_head-mounted_displays_tablet_and_paper_instructions","308416722_A_benchmark_for_interactive_augmented_reality_instructions_for_assembly_tasks","308416533_Interactive_Worker_Assistance_Comparing_the_Effects_of_In-Situ_Projection_Head-Mounted_Displays_Tablet_and_Paper_Instructions","345157949_Evaluating_the_Microsoft_HoloLens_through_an_augmented_reality_assembly_application","318373723_A_systematic_review_of_augmented_reality_applications_in_maintenance","317868752_Comparing_Conventional_and_Augmented_Reality_Instructions_for_Manual_Assembly_Tasks","316483388_Force_control_for_a_rigid_dual_peg-in-hole_assembly"]}