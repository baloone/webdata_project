{"id":"328129716_LQ-Nets_Learned_Quantization_for_Highly_Accurate_and_Compact_Deep_Neural_Networks_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Part_VIII","abstract":"Although weight and activation quantization is an effective approach for Deep Neural Network (DNN) compression and has a lot of potentials to increase inference speed leveraging bit-operations, there is still a noticeable gap in terms of prediction accuracy between the quantized model and the full-precision model. To address this gap, we propose to jointly train a quantized, bit-operation-compatible DNN and its associated quantizers, as opposed to using fixed, handcrafted quantization schemes such as uniform or logarithmic quantization. Our method for learning the quantizers applies to both network weights and activations with arbitrary-bit precision, and our quantizers are easy to train. The comprehensive experiments on CIFAR-10 and ImageNet datasets show that our method works consistently well for various network structures such as AlexNet, VGG-Net, GoogLeNet, ResNet, and DenseNet, surpassing previous quantization methods in terms of accuracy by an appreciable margin. Code available at https://github.com/Microsoft/LQ-Nets.","authors":["Dongqing Zhang","Jiaolong Yang","Dongqiangzi Ye","Gang Hua"],"meta":["September 2018","DOI:10.1007/978-3-030-01237-3_23","In book: Computer Vision â€“ ECCV 2018 (pp.373-390)"],"references":["332816448_Learning_Accurate_Low-Bit_Deep_Neural_Networks_with_Stochastic_Quantization","323392310_Loss-aware_Weight_Quantization_of_Deep_Networks","322059721_Channel_Pruning_for_Accelerating_Very_Deep_Neural_Networks","321417623_Towards_Accurate_Binary_Convolutional_Neural_Network","320796791_Towards_Effective_Low-bitwidth_Convolutional_Neural_Networks","319350438_Performance_Guaranteed_Network_Acceleration_via_High-Order_Residual_Quantization","318899430_Learning_Accurate_Low-Bit_Deep_Neural_Networks_with_Stochastic_Quantization","316184205_MobileNets_Efficient_Convolutional_Neural_Networks_for_Mobile_Vision_Applications","313645102_Incremental_Network_Quantization_Towards_Lossless_CNNs_with_Low-Precision_Weights","306885833_Densely_Connected_Convolutional_Networks","305196650_Going_deeper_with_convolutions","303270485_Ternary_Weight_Networks","301878495_SqueezeNet_AlexNet-level_accuracy_with_50x_fewer_parameters_and_05MB_model_size","301839500_TensorFlow_Large-Scale_Machine_Learning_on_Heterogeneous_Distributed_Systems","287853408_Quantized_Convolutional_Neural_Networks_for_Mobile_Devices","284476540_Fixed_Point_Quantization_of_Deep_Convolutional_Networks","282844341_Neural_Networks_with_Few_Multiplications","282181995_Tensorizing_Neural_Networks","275279789_Compressing_Neural_Networks_with_the_Hashing_Trick","272195143_Deep_Learning_with_Limited_Numerical_Precision","329744984_Towards_Effective_Low-Bitwidth_Convolutional_Neural_Networks","329740172_ShuffleNet_An_Extremely_Efficient_Convolutional_Neural_Network_for_Mobile_Devices","322060302_Performance_Guaranteed_Network_Acceleration_via_High-Order_Residual_Quantization","322058064_ThiNet_A_Filter_Level_Pruning_Method_for_Deep_Neural_Network_Compression","320971540_Aggregated_Residual_Transformations_for_Deep_Neural_Networks","320971375_Deep_Learning_with_Low_Precision_by_Half-Wave_Gaussian_Quantization","320968591_On_Compressing_Deep_Models_by_Low_Rank_and_Sparse_Decomposition","320968382_Xception_Deep_Learning_with_Depthwise_Separable_Convolutions","319770367_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation","319770342_Compressing_Deep_Convolutional_Networks_using_Vector_Quantization","319770334_Deep_Compression_Compressing_Deep_Neural_Networks_with_Pruning_Trained_Quantization_and_Huffman_Coding","319770272_Delving_Deep_into_Rectifiers_Surpassing_Human-Level_Performance_on_ImageNet_Classification","319770252_TensorFlow_Large-Scale_Machine_Learning_on_Heterogeneous_Distributed_Systems","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","318584216_ThiNet_A_Filter_Level_Pruning_Method_for_Deep_Neural_Network_Compression","318205093_ShuffleNet_An_Extremely_Efficient_Convolutional_Neural_Network_for_Mobile_Devices","311610246_Fast_ConvNets_Using_Group-Wise_Brain_Damage","311609205_Quantized_Convolutional_Neural_Networks_for_Mobile_Devices","311609041_Deep_Residual_Learning_for_Image_Recognition","311430286_Trained_Ternary_Quantization","310441005_Aggregated_Residual_Transformations_for_Deep_Neural_Networks","308277201_Identity_Mappings_in_Deep_Residual_Networks","308277088_XNOR-Net_ImageNet_Classification_Using_Binary_Convolutional_Neural_Networks","306218037_Learning_multiple_layers_of_features_from_tiny_images","306187229_Learning_Structured_Sparsity_in_Deep_Neural_Networks","303750082_A_Survey_on_Learning_to_Hash","301847911_Binarized_Neural_Networks","283471201_BinaryConnect_Training_Deep_Neural_Networks_with_binary_weights_during_propagations","277959043_Learning_both_Weights_and_Connections_for_Efficient_Neural_Networks","277334635_Accelerating_Very_Deep_Convolutional_Networks_for_Classification_and_Detection","269935399_Speeding-up_Convolutional_Neural_Networks_Using_Fine-tuned_CP-Decomposition","265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge","272027131_Delving_Deep_into_Rectifiers_Surpassing_Human-Level_Performance_on_ImageNet_Classification","265385906_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition","262380602_Speeding_up_Convolutional_Neural_Networks_with_Low_Rank_Expansions"]}