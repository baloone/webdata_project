{"id":"324055230_Long_short-term_memory_and_Learning-to-learn_in_networks_of_spiking_neurons","abstract":"Networks of spiking neurons (SNNs) are frequently studied as models for networks of neurons in the brain, but also as paradigm for novel energy efficient computing hardware. In principle they are especially suitable for computations in the temporal domain, such as speech processing, because their computations are carried out via events in time and space. But so far they have been lacking the capability to preserve information for longer time spans during a computation, until it is updated or needed - like a register of a digital computer. This function is provided to artificial neural networks through Long Short-Term Memory (LSTM) units. We show here that SNNs attain similar capabilities if one includes adapting neurons in the network. Adaptation denotes an increase of the firing threshold of a neuron after preceding firing. A substantial fraction of neurons in the neocortex of rodents and humans has been found to be adapting. It turns out that if adapting neurons are integrated in a suitable manner into the architecture of SNNs, the performance of these enhanced SNNs, which we call LSNNs, for computation in the temporal domain approaches that of artificial neural networks with LSTM-units. In addition, the computing and learning capabilities of LSNNs can be substantially enhanced through learning-to-learn (L2L) methods from machine learning, that have so far been applied primarily to LSTM networks and apparently never to SSNs. This preliminary report on arXiv will be replaced by a more detailed version in about a month.","authors":["Guillaume Bellec","Darjan Salaj","Anand Subramoney","Robert Legenstein"],"meta":["March 2018"],"references":["323266253_Generalized_leaky_integrate-and-fire_models_classify_multiple_neuron_types","323266087_Systematic_generation_of_biophysically_detailed_models_for_diverse_cortical_neuron_types","322548911_Loihi_A_Neuromorphic_Manycore_Processor_with_On-Chip_Learning","316163230_Reward-based_stochastic_self-configuration_of_neural_circuits","301837424_Convolutional_Networks_for_Fast_Energy-Efficient_Neuromorphic_Computing","278792695_Automated_High-Throughput_Characterization_of_Single_Neurons_by_Means_of_Simplified_Spiking_Models","277894249_'Activity-silent'_working_memory_in_prefrontal_cortex_A_dynamic_coding_framework","276158066_A_Re-configurable_On-line_Learning_Spiking_Neuromorphic_Processor_comprising_256_neurons_and_128K_synapses","275279965_Network_Plasticity_as_Bayesian_Inference","260585643_Overview_of_the_SpiNNaker_System_Architecture","225182080_Learning_To_Learn_Using_Gradient_Descent","50597038_Questions_About_STDP_as_a_General_Model_of_Synaptic_Plasticity","50597017_Temporal_Modulation_of_Spike-Timing-Dependent_Plasticity","13853244_Long_Short-term_Memory","323302753_Meta-Reinforcement_Learning_of_Structured_Exploration_Strategies","318222321_Toward_a_Neurocentric_View_of_Learning","291208484_Neuronal_dynamics_From_single_neurons_to_networks_and_models_of_cognition","269935079_Adam_A_Method_for_Stochastic_Optimization","224163545_AWafer-Scale_Neuromorphic_Hardware_System_for_Large-Scale_Neural_Modeling","11034746_Real-Time_Computing_Without_Stable_States_A_New_Framework_for_Neural_Computation_Based_on_Perturbations","6404553_The_Medial_Temporal_Lobe_and_Recognition_Memory"]}