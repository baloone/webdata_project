{"id":"350391904_On_the_Use_of_Self-Supervised_Pre-Trained_Acoustic_and_Linguistic_Features_for_Continuous_Speech_Emotion_Recognition","authors":["Manon Macary","Marie Tahon","Yannick Est√®ve","Anthony Rousseau"],"meta":["January 2021","DOI:10.1109/SLT48900.2021.9383456","Conference: 2021 IEEE Spoken Language Technology Workshop (SLT)"],"references":["341084410_Mockingjay_Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders","338331839_Asynchronous_pipelines_for_processing_huge_corpora_on_medium_to_low_resource_infrastructures","336792910_AVEC_2019_Workshop_and_Challenge_State-of-Mind_Detecting_Depression_with_AI_and_Cross-Cultural_Affect_Recognition","336202590_SEWA_DB_A_Rich_Database_for_Audio-Visual_Emotion_and_Sentiment_Research_in_the_Wild","335829316_wav2vec_Unsupervised_Pre-Training_for_Speech_Recognition","334115085_A_Helping_Hand_Transfer_Learning_for_Deep_Sentiment_Analysis","333950088_A_Sensitivity_and_Performance_Analysis_of_Word2Vec_Applied_to_Emotion_State_Classification_Using_a_Deep_Neural_Architecture","328376918_AVEC_2018_Workshop_and_Challenge_Bipolar_Disorder_and_Cross-Cultural_Affect_Recognition","317340604_Handcrafted_vs_Non-Handcrafted_Features_for_computer_vision_classification","313242937_The_interspeech_2013_computational_paralinguistics_challenge_Social_signals_conflict_emotion_autism","311469575_Introducing_the_recola_multimodal_corpus_of_remote_collaborative_and_affective_interactions","261121552_Introducing_the_RECOLA_multimodal_corpus_of_remote_collaborative_and_affective_interactions","257882504_Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality","255820377_Software_Framework_for_Topic_Modelling_with_Large_Corpora","224929655_openSMILE_--_The_Munich_Versatile_and_Fast_Open-Source_Audio_Feature_Extractor","221488147_Real-life_emotions_detection_with_lexical_and_paralinguistic_cues_on_human-human_call_center_dialogs","345307315_Multi-corpus_Experiment_on_Continuous_Speech_Emotion_Recognition_Convolution_or_Recurrence","343296728_CamemBERT_a_Tasty_French_Language_Model","341083201_Libri-Light_A_Benchmark_for_ASR_with_Limited_or_No_Supervision","335829552_Continuous_Emotion_Recognition_in_Speech_-_Do_We_Need_Recurrence","335783773_Multi-Task_Deep_Neural_Networks_for_Natural_Language_Understanding","335778994_ERNIE_Enhanced_Language_Representation_with_Informative_Entities","327206519_TED-LIUM_3_Twice_as_Much_Data_and_Corpus_Repartition_for_Experiments_on_Speaker_Adaptation_20th_International_Conference_SPECOM_2018_Leipzig_Germany_September_18-22_2018_Proceedings","326747187_Recent_Trends_in_Deep_Learning_Based_Natural_Language_Processing_Review_Article","320745374_Prominence_features_Effective_emotional_features_for_speech_emotion_recognition","308871877_Librispeech_An_ASR_corpus_based_on_public_domain_audio_books","308808804_A_comprehensive_survey_on_features_and_methods_for_speech_emotion_detection","284793178_What_are_emotions_And_how_can_they_be_measured","282540984_The_Geneva_Minimalistic_Acoustic_Parameter_Set_GeMAPS_for_Voice_Research_and_Affective_Computing","229060094_Scherer_KR_What_are_emotions_And_how_can_they_be_measured_Soc_Sci_Inf_44_695-729","20436291_A_Concordance_Correlation-Coefficient_To_Evaluate_Reproducibility"]}