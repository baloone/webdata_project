{"id":"333493043_Human-level_performance_in_3D_multiplayer_games_with_population-based_reinforcement_learning","abstract":"Reinforcement learning (RL) has shown great success in increasingly complex single-agent environments and two-player turn-based games. However, the real world contains multiple agents, each learning and acting independently to cooperate and compete with other agents. We used a tournament-style evaluation to demonstrate that an agent can achieve human-level performance in a three-dimensional multiplayer first-person video game, Quake III Arena in Capture the Flag mode, using only pixels and game points scored as input. We used a two-tier optimization process in which a population of independent RL agents are trained concurrently from thousands of parallel matches on randomly generated environments. Each agent learns its own internal reward signal and rich representation of the world. These results indicate the great potential of multiagent reinforcement learning for artificial intelligence research.","authors":["Max Jaderberg","Wojciech Marian Czarnecki","Iain Dunning","Luke Marris"],"meta":["May 2019Science 364(6443):859-865","DOI:10.1126/science.aau6249"],"references":["320821388_A_Unified_Game-Theoretic_Approach_to_Multiagent_Reinforcement_Learning","320473480_Mastering_the_game_of_Go_without_human_knowledge","319700738_Learning_with_Opponent-Learning_Awareness","314237738_FeUdal_Networks_for_Hierarchical_Reinforcement_Learning","310440792_Reinforcement_Learning_with_Unsupervised_Auxiliary_Tasks","308321225_Playing_FPS_Games_with_Deep_Reinforcement_Learning","308262673_The_Option-Critic_Architecture","303496415_Sequential_Neural_Models_with_Stochastic_Layers","303448501_Learning_to_Communicate_with_Deep_Multi-Agent_Reinforcement_Learning","292074166_Mastering_the_game_of_Go_with_deep_neural_networks_and_tree_search","281670459_Continuous_control_with_deep_reinforcement_learning","258344055_Variational_Policy_Search_via_Trajectory_Optimization","247117649_Action_video_games_and_informal_education_Effects_on_strategies_for_dividing_visual_attention","231890516_Independent_reinforcement_learners_in_cooperative_Markov_games_A_survey_regarding_coordination_problems","226118208_Multiobjective_evolutionary_algorithms_to_identify_highly_autocorrelated_areas_The_case_of_spatial_distribution_in_financially_compromised_farms","224603682_Hierarchical_controller_learning_in_a_First-Person_Shooter","224141166_Intrinsically_Motivated_Reinforcement_Learning_An_Evolutionary_Perspective","221605178_Ad_Hoc_Autonomous_Agent_Teams_Collaboration_without_Pre-Coordination","221054857_On_the_Limits_of_the_Human_Motor_Control_Precision_The_Search_for_a_Device's_Human_Resolution","331477508_A_Unified_Game-Theoretic_Approach_to_Multiagent_Reinforcement_Learning","322950202_IMPALA_Scalable_Distributed_Deep-RL_with_Importance_Weighted_Actor-Learner_Architectures","320322134_Emergent_Complexity_via_Multi-Agent_Competition","319769993_A_Recurrent_Latent_Variable_Model_for_Sequential_Data","317399486_Multi-Agent_Actor-Critic_for_Mixed_Cooperative-Competitive_Environments","315096415_Emergence_of_Grounded_Compositional_Language_in_Multi-Agent_Populations","314285928_Shoot_at_first_sight_First_person_shooter_players_display_reduced_reaction_time_and_compromised_inhibitory_control_in_comparison_to_other_video_game_players","313493106_Neuroscience_Needs_Behavior_Correcting_a_Reductionist_Bias","312157307_DeepStack_Expert-Level_Artificial_Intelligence_in_No-Limit_Poker","309091100_Hybrid_computing_using_a_neural_network_with_dynamic_external_memory","307861335_Hierarchical_Multiscale_Recurrent_Neural_Networks","306093856_Generating_Sentences_from_a_Continuous_Space","303521190_Learning_Multiagent_Communication_with_Backpropagation","291011391_Mapping_Sub-Second_Structure_in_Mouse_Behavior","288753202_The_complexity_of_decentralized_control_of_MDPs","284219020_Generating_Sentences_from_a_Continuous_Space","283659848_Processing_Timescales_as_an_Organizing_Principle_for_Primate_Cortex","280329735_Deep_Recurrent_Q-Learning_for_Partially_Observable_MDPs","277959228_A_Recurrent_Latent_Variable_Model_for_Sequential_Data","276075842_Action_video_game_training_for_cognitive_enhancement","272837232_Human-level_control_through_deep_reinforcement_learning","268304999_Hierarchical_Reinforcement_Learning_with_the_MAXQ_Value_Function_Decomposition","259399927_Deep_Inside_Convolutional_Networks_Visualising_Image_Classification_Models_and_Saliency_Maps","259084898_Teaching_and_leading_an_ad_hoc_teammate_Collaboration_without_pre-coordination","246928154_Neue_Begrndung_der_Theorie_quadratischer_Formen_von_unendlichvielen_Vernderlichen","243653793_Iterative_solution_of_games_by_fictitious_play","242406308_Three_States_and_a_Plan_The_AI_of_FEAR","228114707_Concept_cells_the_building_blocks_of_declarative_memory_functions","225632674_Layered_Learning","221603615_Know_Thine_Enemy_A_Champion_RoboCup_Coach_Agent","221404193_The_Complexity_of_Decentralized_Control_of_Markov_Decision_Processes","200744585_Learning_model-free_robot_control_by_a_Monte_Carlo_EM_algorithm","200744428_Where_Do_Rewards_Come_From","44614174_Increasing_Speed_of_Processing_With_Action_Video_Games","220500234_Learning_Complex_Extended_Sequences_Using_the_Principle_of_History_Compression","220423062_Temporal_Difference_Learning_and_TD-Gammon"]}