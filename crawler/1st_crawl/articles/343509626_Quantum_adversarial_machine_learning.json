{"id":"343509626_Quantum_adversarial_machine_learning","abstract":"Adversarial machine learning is an emerging field that focuses on studying vulnerabilities of machine learning approaches in adversarial settings and developing techniques accordingly to make learning robust to adversarial manipulations. It plays a vital role in various machine learning applications and recently has attracted tremendous attention across different communities. In this paper, we explore different adversarial scenarios in the context of quantum machine learning. We find that, similar to traditional classifiers based on classical neural networks, quantum learning systems are likewise vulnerable to crafted adversarial examples, independent of whether the input data is classical or quantum. In particular, we find that a quantum classifier that achieves nearly the state-of-the-art accuracy can be conclusively deceived by adversarial examples obtained via adding imperceptible perturbations to the original legitimate samples. This is explicitly demonstrated with quantum adversarial learning in different scenarios, including classifying real-life images (e.g., handwritten digit images in the dataset MNIST), learning phases of matter (such as ferromagnetic/paramagnetic orders and symmetry protected topological phases), and classifying quantum data. Furthermore, we show that based on the information of the adversarial examples at hand, practical defense strategies can be designed to fight against a number of different attacks. Our results uncover the notable vulnerability of quantum machine learning systems to adversarial perturbations, which not only reveals another perspective in bridging machine learning and quantum physics in theory but also provides valuable guidance for practical applications of quantum classifiers based on both near-term and future quantum technologies.","authors":["Sirui Lu","Lu-Ming Duan","Dong-Ling Deng"],"meta":["August 2020Physical Review Research 2(3)","DOI:10.1103/PhysRevResearch.2.033212"],"references":["345324085_A_quantum_active_learning_algorithm_for_sampling_against_adversarial_attacks","344005111_Stochastic_gradient_descent_for_hybrid_quantum-classical_optimization","342963763_Machine_learning_phase_transitions_with_a_quantum_processor","341630860_Quantum_Natural_Gradient","341403483_Quantum_classifier_with_tailored_quantum_kernel","350713174_Low-Depth_Gradient_Measurements_Can_Improve_Convergence_in_Variational_Hybrid_Quantum-Classical_Algorithms","350299431_A_survey_on_adversarial_attacks_and_defences","346172124_Yaojl_Extensible_Efficient_Framework_for_Quantum_Algorithm_Design","342388185_Vulnerability_of_quantum_classification_to_adversarial_perturbations","339523157_Adversarial_Learning_Targeting_Deep_Neural_Network_Classification_A_Comprehensive_Review_of_Defenses_Against_Attacks_This_article_provides_a_contemporary_survey_of_adversarial_learning_AL_focused_part"]}