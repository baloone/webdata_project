{"id":"320102864_Incremental_On-line_Learning_A_Review_and_Comparison_of_State_of_the_Art_Algorithms","abstract":"Recently, incremental and on-line learning gained more attention especially in the context of big data and learning from data streams, conflicting with the traditional assumption of complete data availability. Even though a variety of different methods are available, it often remains unclear which of them is suitable for a specific task and how they perform in comparison to each other. We analyze the key properties of eight popular incremental methods representing different algorithm classes. Thereby, we evaluate them with regards to their on-line classification error as well as to their behavior in the limit. Further, we discuss the often neglected issue of hyperparameter optimization specifically for each method and test how robustly it can be done based on a small set of examples. Our extensive evaluation on data sets with different characteristics gives an overview of the performance with respect to accuracy, convergence speed as well as model complexity, facilitating the choice of the best method for a given application.","authors":["Viktor Losing","Barbara Hammer","Heiko Wersing"],"meta":["September 2017Neurocomputing 275","DOI:10.1016/j.neucom.2017.06.084"],"references":["311759998_KNN_Classifier_with_Self_Adjusting_Memory_for_Heterogeneous_Concept_Drift","308869266_Interactive_online_learning_for_obstacle_classification_on_a_mobile_robot","340771713_Learning_in_the_Presence_of_Concept_Drift_and_Hidden_Contexts","313501588_Accelerating_stochastic_gradient_descent_using_predictive_variance_reduction","313060232_Learning_Internal_Representations_by_Error_Propagation","312538118_Support-vector_networks","312532410_Incremental_and_decremental_support_vector_machine_learning","309563249_The_supervised_learning_no-free-lunch_theorems","307881957_LIBSVM_A_library_for_support_vector_machines","304781977_Algorithms_for_hyper-parameter_optimization"]}