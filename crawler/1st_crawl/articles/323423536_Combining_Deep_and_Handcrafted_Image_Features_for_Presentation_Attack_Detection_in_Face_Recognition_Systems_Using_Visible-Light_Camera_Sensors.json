{"id":"323423536_Combining_Deep_and_Handcrafted_Image_Features_for_Presentation_Attack_Detection_in_Face_Recognition_Systems_Using_Visible-Light_Camera_Sensors","abstract":"Although face recognition systems have wide application, they are vulnerable to presentation attack samples (fake samples). Therefore, a presentation attack detection (PAD) method is required to enhance the security level of face recognition systems. Most of the previously proposed PAD methods for face recognition systems have focused on using handcrafted image features, which are designed by expert knowledge of designers, such as Gabor filter, local binary pattern (LBP), local ternary pattern (LTP), and histogram of oriented gradients (HOG). As a result, the extracted features reflect limited aspects of the problem, yielding a detection accuracy that is low and varies with the characteristics of presentation attack face images. The deep learning method has been developed in the computer vision research community, which is proven to be suitable for automatically training a feature extractor that can be used to enhance the ability of handcrafted features. To overcome the limitations of previously proposed PAD methods, we propose a new PAD method that uses a combination of deep and handcrafted features extracted from the images by visible-light camera sensor. Our proposed method uses the convolutional neural network (CNN) method to extract deep image features and the multi-level local binary pattern (MLBP) method to extract skin detail features from face images to discriminate the real and presentation attack face images. By combining the two types of image features, we form a new type of image features, called hybrid features, which has stronger discrimination ability than single image features. Finally, we use the support vector machine (SVM) method to classify the image features into real or presentation attack class. Our experimental results indicate that our proposed method outperforms previous PAD methods by yielding the smallest error rates on the same image databases.","authors":["Dat Tien Nguyen","Tuyen Danh Pham","Na Rae Baek","Kang Ryoung Park"],"meta":["February 2018Sensors 18(3):699","DOI:10.3390/s18030699"],"references":["320177028_Spoof_Detection_for_Finger-Vein_Recognition_System_Using_NIR_Camera","317340604_Handcrafted_vs_Non-Handcrafted_Features_for_computer_vision_classification","315470211_Gender_Recognition_from_Human-Body_Images_Using_Visible-Light_and_Thermal_Camera_Videos_Based_on_a_Convolutional_Neural_Network_for_Image_Feature_Extraction","320373850_Deep_Texture_Features_for_Robust_Face_Spoofing_Detection","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","318920058_A_Survey_of_Local_Feature_Methods_for_3D_Face_Recognition","317229764_Long_Range_Iris_Recognition_A_Survey","312338954_Multimodal_Biometric_Recognition_using_Human_Ear_and_Palmprint","311757141_DeepLanes_End-To-End_Lane_Position_Estimation_Using_Deep_Neural_Networks","311611259_Joint_Training_of_Cascaded_CNN_for_Face_Detection"]}