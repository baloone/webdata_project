{"id":"277411157_Deep_Learning","abstract":"Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.","authors":["Yann LeCun","Y. Bengio","Geoffrey Hinton"],"meta":["May 2015Nature 521(7553):436-44","DOI:10.1038/nature14539","SourcePubMed"],"references":["319770160_Show_and_Tell_A_Neural_Image_Caption_Generator","339506576_Learning_Deep_Architectures_for_AI","329650509_Semantic_Cognition_A_Parallel_Distributed_Processing_Approach","319770465_Sequence_to_Sequence_Learning_with_Neural_Networks","319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation","319770268_Joint_Training_of_a_Convolutional_Network_and_a_Graphical_Model_for_Human_Pose_Estimation","319770184_Speech_Recognition_With_Deep_Recurrent_Neural_Networks","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","318494453_Metaphors_We_Live_By","312973075_The_tradeoffs_of_large_scale_learning"]}