{"id":"330710636_Fighting_misinformation_on_social_media_using_crowdsourced_judgments_of_news_source_quality","abstract":"Reducing the spread of misinformation, especially on social media, is a major challenge. We investigate one potential approach: having social media platform algorithms preferentially display content from news sources that users rate as trustworthy. To do so, we ask whether crowdsourced trust ratings can effectively differentiate more versus less reliable sources. We ran two preregistered experiments ( n = 1,010 from Mechanical Turk and n = 970 from Lucid) where individuals rated familiarity with, and trust in, 60 news sources from three categories: ( i ) mainstream media outlets, ( ii ) hyperpartisan websites, and ( iii ) websites that produce blatantly false content (“fake news”). Despite substantial partisan differences, we find that laypeople across the political spectrum rated mainstream sources as far more trustworthy than either hyperpartisan or fake news sources. Although this difference was larger for Democrats than Republicans—mostly due to distrust of mainstream sources by Republicans—every mainstream source (with one exception) was rated as more trustworthy than every hyperpartisan or fake news source across both studies when equally weighting ratings of Democrats and Republicans. Furthermore, politically balanced layperson ratings were strongly correlated ( r = 0.90) with ratings provided by professional fact-checkers. We also found that, particularly among liberals, individuals higher in cognitive reflection were better able to discern between low- and high-quality sources. Finally, we found that excluding ratings from participants who were not familiar with a given news source dramatically reduced the effectiveness of the crowd. Our findings indicate that having algorithms up-rank content from trusted media outlets may be a promising approach for fighting the spread of misinformation on social media.","authors":["Gordon Pennycook","David G. Rand"],"meta":["January 2019Proceedings of the National Academy of Sciences 116(7):201806781","DOI:10.1073/pnas.1806781116"],"references":["332109523_Who_falls_for_fake_news_The_roles_of_bullshit_receptivity_overclaiming_familiarity_and_analytic_thinking","330696594_Validating_the_demographic_political_psychological_and_experimental_results_obtained_from_a_new_source_of_online_survey_respondents","328507769_Belief_in_Fake_News_is_Associated_with_Delusionality_Dogmatism_Religious_Fundamentalism_and_Reduced_Analytic_Thinking","327866113_Prior_Exposure_Increases_Perceived_Accuracy_of_Fake_News","326280050_Cognitive_Reflection_and_the_2016_US_Presidential_Election","325494600_At_Least_Bias_Is_Bipartisan_A_Meta-Analytic_Comparison_of_Partisan_Bias_in_Liberals_and_Conservatives","331555047_False_Equivalence_Are_Liberals_and_Conservatives_in_the_United_States_Equally_Biased","330626092_Fake_news_on_Twitter_during_the_2016_US_presidential_election","325900992_Lazy_not_biased_Susceptibility_to_partisan_fake_news_is_better_explained_by_lack_of_reasoning_than_by_motivated_reasoning","324042216_Generalizing_from_Survey_Experiments_Conducted_on_Mechanical_Turk_A_Replication_Approach"]}