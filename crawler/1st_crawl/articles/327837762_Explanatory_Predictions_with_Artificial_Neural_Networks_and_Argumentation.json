{"id":"327837762_Explanatory_Predictions_with_Artificial_Neural_Networks_and_Argumentation","abstract":"Data-centric AI has proven successful in several domains, but its outputs are often hard to explain. We present an architecture combining Artificial Neural Networks (ANNs) for feature selection and an instance of Abstract Argumentation (AA) for reasoning to provide effective predictions, explainable both dialectically and logically. In particular, we train an autoencoder to rank features in input examples, and select highest-ranked features to generate an AA framework that can be used for making and explaining predictions as well as mapped onto logical rules, which can equivalently be used for making predictions and for explaining. We show empirically that our method significantly outperforms ANNs and a decision-tree-based method from which logical rules can also be extracted.","authors":["Kristijonas Cyras","Oana Cocarascu","Francesca Toni"],"meta":["July 2018","Conference: IJCAI/ECAI Workshop on Explainable Artificial Intelligence (XAI 2018)At: Stockholm"],"references":["220388060_Value-based_Argumentation_Frameworks_as_Neural-symbolic_Learning_Systems","327837582_Explanation_for_Case-Based_Reasoning_via_Abstract_Argumentation","318830176_Deep_Forest_Towards_An_Alternative_to_Deep_Neural_Networks"]}