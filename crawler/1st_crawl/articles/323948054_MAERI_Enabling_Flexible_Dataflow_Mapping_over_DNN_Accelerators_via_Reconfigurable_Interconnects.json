{"id":"323948054_MAERI_Enabling_Flexible_Dataflow_Mapping_over_DNN_Accelerators_via_Reconfigurable_Interconnects","abstract":"Deep neural networks (DNN) have demonstrated highly promising results across computer vision and speech recognition, and are becoming foundational for ubiquitous AI. The computational complexity of these algorithms and a need for high energy-efficiency has led to a surge in research on hardware accelerators. % for this paradigm. To reduce the latency and energy costs of accessing DRAM, most DNN accelerators are spatial in nature, with hundreds of processing elements (PE) operating in parallel and communicating with each other directly. DNNs are evolving at a rapid rate, and it is common to have convolution, recurrent, pooling, and fully-connected layers with varying input and filter sizes in the most recent topologies.They may be dense or sparse. They can also be partitioned in myriad ways (within and across layers) to exploit data reuse (weights and intermediate outputs). All of the above can lead to different dataflow patterns within the accelerator substrate. Unfortunately, most DNN accelerators support only fixed dataflow patterns internally as they perform a careful co-design of the PEs and the network-on-chip (NoC). In fact, the majority of them are only optimized for traffic within a convolutional layer. This makes it challenging to map arbitrary dataflows on the fabric efficiently, and can lead to underutilization of the available compute resources. DNN accelerators need to be programmable to enable mass deployment. For them to be programmable, they need to be configurable internally to support the various dataflow patterns that could be mapped over them. To address this need, we present MAERI, which is a DNN accelerator built with a set of modular and configurable building blocks that can easily support myriad DNN partitions and mappings by appropriately configuring tiny switches. MAERI provides 8-459% better utilization across multiple dataflow mappings over baselines with rigid NoC fabrics.","authors":["Hyoukjun Kwon","Ananda Samajdar","Tushar Krishna"],"meta":["March 2018","DOI:10.1145/3173162.3173176","Conference: the Twenty-Third International Conference"],"references":["317613363_In-Datacenter_Performance_Analysis_of_a_Tensor_Processing_Unit","316077428_Deep_Convolutional_Neural_Network_Architecture_With_Reconfigurable_Computation_Patterns","314092301_Deep_Voice_Real-time_Neural_Text-to-Speech","313263619_ESE_Efficient_Speech_Recognition_Engine_with_Sparse_LSTM_on_FPGA","311754552_Fused-layer_CNN_accelerators","308831880_FPGA-Based_Low-Power_Speech_Recognition_with_Recurrent_Neural_Networks","306082505_NEUTRAMS_Neural_Network_Transformation_and_Co-design_under_Neuromorphic_Hardware_Constraints","305727225_Dynamic_Approximation_with_Feedback_Control_for_Energy-Efficient_Recurrent_Neural_Network_Hardware","305196650_Going_deeper_with_convolutions","304163527_CNNLab_a_Novel_Parallel_Framework_for_Neural_Networks_using_GPU_and_FPGA-a_Practical_Study_with_Trade-off_Analysis","302569301_Theano_A_Python_framework_for_fast_computation_of_mathematical_expressions","301839500_TensorFlow_Large-Scale_Machine_Learning_on_Heterogeneous_Distributed_Systems","282351169_Jupiter_Rising","265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge","264979485_Caffe_Convolutional_Architecture_for_Fast_Feature_Embedding","346345558_DianNao_a_small-footprint_high-throughput_accelerator_for_ubiquitous_machine-learning","345573355_Maximizing_CNN_Accelerator_Efficiency_Through_Resource_Partitioning","319948267_Rethinking_NoCs_for_Spatial_Neural_Network_Accelerators","319770411_Torch7_A_Matlab-like_Environment_for_Machine_Learning","319770323_EIE_Efficient_Inference_Engine_on_Compressed_Deep_Neural_Network","319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","319135260_SCNN_An_Accelerator_for_Compressed-sparse_Convolutional_Neural_Networks","317631934_Eyeriss_A_Spatial_Architecture_for_Energy-Efficient_Dataflow_for_Convolutional_Neural_Networks","317613527_SCNN_An_Accelerator_for_Compressed-sparse_Convolutional_Neural_Networks","316902593_FlexFlow_A_Flexible_Dataflow_Accelerator_Architecture_for_Convolutional_Neural_Networks","314296599_142_DNPU_An_81TOPSW_reconfigurable_CNN-RNN_processor_for_general-purpose_deep_neural_networks","313870190_FPGA-based_accelerator_for_long_short-term_memory_recurrent_neural_networks","313264817_Optimizing_Loop_Operation_and_Dataflow_in_FPGA_Acceleration_of_Deep_Convolutional_Neural_Networks","312448985_DaDianNao_A_machine-learning_supercomputer","311755562_Cambricon-X_An_accelerator_for_sparse_neural_networks","311609108_FPGA-Based_Low-Power_Speech_Recognition_with_Recurrent_Neural_Networks","311609041_Deep_Residual_Learning_for_Image_Recognition","309143107_Cnvlutin_Ineffectual-Neuron-Free_Deep_Neural_Network_Computing","307091545_Jupiter_rising_A_decade_of_Clos_topologies_and_centralized_control_in_google's_datacenter_network","304758513_Maximizing_CNN_Accelerator_Efficiency_Through_Resource_Partitioning","304340893_Shifting_Vision_Processing_Closer_to_the_Sensor_for_High_Efficiency","301891800_Eyeriss_A_Spatial_Architecture_for_Energy-Efficient_Dataflow_for_Convolutional_Neural_Networks","301819356_EIE_Efficient_Inference_Engine_on_Compressed_Deep_Neural_Network","301367952_Optimizing_FPGA-based_Accelerator_Design_for_Deep_Convolutional_Neural_Networks","301227588_C-BrainA_deep_learning_accelerator_that_tames_the_diversity_of_CNNs_through_adaptive_data-level_parallelization","292215395_Neural_networks_and_physical_systems_with_emergent_collective_computational_abilities","290224579_Minimizing_Computation_in_Convolutional_Neural_Networks","288592468_Transforming_the_LSTM_training_algorithm_for_efficient_FPGA-based_adaptive_control_of_nonlinear_dynamic_systems","286512696_Deep_Residual_Learning_for_Image_Recognition","283770349_FPGA_Acceleration_of_Recurrent_Neural_Network_Based_Language_Model","283024298_DaDianNao_A_Machine-Learning_Supercomputer","280082402_ShiDianNao_shifting_vision_processing_closer_to_the_sensor","271455545_Aladdin_A_pre-RTL_power-performance_accelerator_simulator_enabling_large_design_space_exploration_of_customized_architectures","265385906_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition","262174473_Convolution_Engine_Balancing_Efficiency_and_Flexibility_in_Specialized_Computing","261845797_DianNao_A_Small-Footprint_High-Throughput_Accelerator_for_Ubiquitous_Machine-Learning","261108357_Network-on-Chip_Architectures_for_Neural_Networks","243786282_Serial_order_A_parallel_distributed_processing_approach","222449846_Finding_Structure_in_Time"]}