{"id":"301840264_Multi-fidelity_Gaussian_Process_Bandit_Optimisation","abstract":"In many scientific and engineering applications, we are tasked with the optimisation of an expensive to evaluate black box function $f$. Traditional methods for this problem assume just the availability of this single function. However, in many cases, cheap approximations to $f$ may be obtainable. For example, the expensive real world behaviour of a robot can be approximated by a cheap computer simulation. We can use these approximations to eliminate low function value regions and use the expensive evaluations to $f$ in a small promising region and speedily identify the optimum. We formalise this task as a \\emph{multi-fidelity} bandit problem where the target function and its approximations are sampled from a Gaussian process. We develop a method based on upper confidence bound techniques and prove that it exhibits precisely the above behaviour, hence achieving better regret than strategies which ignore multi-fidelity information. Our method outperforms such naive strategies on several synthetic and real experiments.","authors":["Kirthevasan Kandasamy","Gautam Dasarathy","Junier B. Oliva","Jeff Schneider"],"meta":["March 2016Journal of Artificial Intelligence Research 66","DOI:10.1613/jair.1.11288"],"references":[]}