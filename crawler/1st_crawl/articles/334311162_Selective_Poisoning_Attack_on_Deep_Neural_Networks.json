{"id":"334311162_Selective_Poisoning_Attack_on_Deep_Neural_Networks","abstract":"Studies related to pattern recognition and visualization using computer technology have been introduced. In particular, deep neural networks (DNNs) provide good performance for image, speech, and pattern recognition. However, a poisoning attack is a serious threat to a DNNâ€™s security. A poisoning attack reduces the accuracy of a DNN by adding malicious training data during the training process. In some situations, it may be necessary to drop a specifically chosen class of accuracy from the model. For example, if an attacker specifically disallows nuclear facilities to be selectively recognized, it may be necessary to intentionally prevent unmanned aerial vehicles from correctly recognizing nuclear-related facilities. In this paper, we propose a selective poisoning attack that reduces the accuracy of only the chosen class in the model. The proposed method achieves this by training malicious data corresponding to only the chosen class while maintaining the accuracy of the remaining classes. For the experiment, we used tensorflow as the machine-learning library as well as MNIST, Fashion-MNIST, and CIFAR10 as the datasets. Experimental results show that the proposed method can reduce the accuracy of the chosen class by 43.2%, 41.7%, and 55.3% in MNIST, Fashion-MNIST, and CIFAR10, respectively, while maintaining the accuracy of the remaining classes.","authors":["Hyun Kwon","Hyunsoo Yoon","Ki-Woong Park"],"meta":["July 2019Symmetry 11(7):892","DOI:10.3390/sym11070892"],"references":["331663768_Traffic_Signs_Identification_by_Deep_Learning_for_Autonomous_Driving","328147881_Artificial_bee_colony_algorithm_for_enhancing_image_edge_detection","319312259_Fashion-MNIST_a_Novel_Image_Dataset_for_Benchmarking_Machine_Learning_Algorithms","340822460_Automatically_Designing_CNN_Architectures_Using_the_Genetic_Algorithm_for_Image_Classification","335072144_Selective_Poisoning_Attack_on_Deep_Neural_Network_to_Induce_Fine-Grained_Recognition_Error","332790210_APE-GAN_Adversarial_Perturbation_Elimination_with_GAN","329745708_Learning_Transferable_Architectures_for_Scalable_Image_Recognition","326854294_Audio_Adversarial_Examples_Targeted_Attacks_on_Speech-to-Text","320968636_Universal_Adversarial_Perturbations","320671312_MagNet_A_Two-Pronged_Defense_against_Adversarial_Examples"]}