{"id":"313790788_What_to_expect_from_your_remote_eye-tracker_when_participants_are_unrestrained","abstract":"The marketing materials of remote eye-trackers suggest that data quality is invariant to the position and orientation of the participant as long as the eyes of the participant are within the eye-trackerâ€™s headbox, the area where tracking is possible. As such, remote eye-trackers are marketed as allowing the reliable recording of gaze from participant groups that cannot be restrained, such as infants, schoolchildren and patients with muscular or brain disorders. Practical experience and previous research, however, tells us that eye-tracking data quality, e.g. the accuracy of the recorded gaze position and the amount of data loss, deteriorates (compared to well-trained participants in chinrests) when the participant is unrestrained and assumes a non-optimal pose in front of the eye-tracker. How then can researchers working with unrestrained participants choose an eye-tracker? Here we investigated the performance of five popular remote eye-trackers from EyeTribe, SMI, SR Research, and Tobii in a series of tasks where participants took on non-optimal poses. We report that the tested systems varied in the amount of data loss and systematic offsets observed during our tasks. The EyeLink and EyeTribe in particular had large problems. Furthermore, the Tobii eye-trackers reported data for two eyes when only one eye was visible to the eye-tracker. This study provides practical insight into how popular remote eye-trackers perform when recording from unrestrained participants. It furthermore provides a testing method for evaluating whether a tracker is suitable for studying a certain target population, and that manufacturers can use during the development of new eye-trackers.","authors":["Diederick C. Niehorster","Tim Cornelissen","Kenneth Holmqvist","Ignace Hooge"],"meta":["February 2017Behavior Research Methods 50(1)","DOI:10.3758/s13428-017-0863-0","Project: Data quality"],"references":["309596786_Noise-robust_fixation_detection_in_eye_movement_data_Identification_by_two-means_clustering_I2MC","283776047_The_area-of-interest_problem_in_eyetracking_research_A_noise-robust_solution_for_face_and_sparse_stimuli","259628335_Scan_path_entropy_and_Arrow_plots_Capturing_scanning_behavior_of_multiple_observers","258095028_PyGaze_An_open-source_cross-platform_toolbox_for_minimal-effort_programming_of_eyetracking_experiments","254913339_Eye_Tracking_A_Comprehensive_Guide_To_Methods_And_Measures","254007815_Eye_tracker_data_quality_What_it_is_and_how_to_measure_it","303833233_Do_infants_have_the_horizontal_bias","280874399_Consequences_of_Eye_Color_Positioning_and_Head_Movement_for_Eye-Tracking_Data_Quality_in_Infant_Research","264056926_Qualitative_tests_of_remote_eyetracker_recovery_and_performance_during_head_rotation","256448564_Relations_between_18-month-olds'_gaze_pattern_and_target_action_performance_A_deferred_imitation_study_with_eye_tracking"]}