{"id":"317768309_Reconciliation_between_factions_focused_on_near-term_and_long-term_artificial_intelligence","abstract":"Artificial intelligence (AI) experts are currently divided into “presentist” and “futurist” factions that call for attention to near-term and long-term AI, respectively. This paper argues that the presentist–futurist dispute is not the best focus of attention. Instead, the paper proposes a reconciliation between the two factions based on a mutual interest in AI. The paper further proposes realignment to two new factions: an “intellectualist” faction that seeks to develop AI for intellectual reasons (as found in the traditional norms of computer science) and a “societalist faction” that seeks to develop AI for the benefit of society. The paper argues in favor of societalism and offers three means of concurrently addressing societal impacts from near-term and long-term AI: (1) advancing societalist social norms, thereby increasing the portion of AI researchers who seek to benefit society; (2) technical research on how to make any AI more beneficial to society; and (3) policy to improve the societal benefits of all AI. In practice, it will often be advantageous to emphasize near-term AI due to the greater interest in near-term AI among AI and policy communities alike. However, presentist and futurist societalists alike can benefit from each others’ advocacy for attention to the societal impacts of AI. The reconciliation between the presentist and futurist factions can improve both near-term and long-term societal impacts of AI.","authors":["Seth D Baum"],"meta":["November 2018AI & SOCIETY 33(1):1-8","DOI:10.1007/s00146-017-0734-3"],"references":["271390398_Artificial_General_Intelligence_Concept_State_of_the_Art_and_Future_Prospects","346815036_The_Age_of_Em_Work_Love_and_Life_when_Robots_Rule_the_EarthWork_Love_and_Life_when_Robots_Rule_the_Earth","346077437_Never_Pure_Historical_Studies_of_Science_as_if_It_Was_Produced_by_People_with_Bodies_Situated_in_Time_Space_Culture_and_Society_and_Struggling_for_Credibility_and_Authority","320182421_Superintelligence_paths_dangers_strategies","304226143_Concrete_Problems_in_AI_Safety","303670149_Speculations_concerning_the_first_ultraintelligent_machine","280117536_Fears_of_an_AI_pioneer","274216175_The_Singularity_Is_Near_When_Humans_Transcend_Biology","273579751_The_Far_Future_Argument_for_Confronting_Catastrophic_Threats_to_Humanity_Practical_Significance_and_Alternatives","272746260_The_quest_for_artificial_intelligence_A_history_of_ideas_and_achievements","253193038_The_Role_of_the_NSF_Broader_Impacts_Criterion_in_Enhancing_Research_Ethics_Pedagogy","249623421_Expectations_and_the_Emergence_of_Nanotechnology","248987739_The_Role_of_the_National_Science_Foundation_Broader_Impacts_Criterion_in_Enhancing_Research_Ethics_Pedagogy","266962798_Proof_for_a_Case_Where_Discounting_Advances_the_Doomsday","256040275_Minimizing_Global_Catastrophic_and_Existential_Risks_from_Emerging_Technologies_Through_International_Law"]}