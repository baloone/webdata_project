{"id":"342400144_FoveaBox_Beyound_Anchor-Based_Object_Detection","abstract":"We present FoveaBox, an accurate, flexible, and completely anchor-free framework for object detection. While almost all state-of-the-art object detectors utilize predefined anchors to enumerate possible locations, scales and aspect ratios for the search of the objects, their performance and generalization ability are also limited to the design of anchors. Instead, FoveaBox directly learns the object existing possibility and the bounding box coordinates without anchor reference. This is achieved by: (a) predicting category-sensitive semantic maps for the object existing possibility, and (b) producing category-agnostic bounding box for each position that potentially contains an object. The scales of target boxes are naturally associated with feature pyramid representations. In FoveaBox, an instance is assigned to adjacent feature levels to make the model more accurate.We demonstrate its effectiveness on standard benchmarks and report extensive experimental analysis. Without bells and whistles, FoveaBox achieves state-of-the-art single model performance on the standard COCO and Pascal VOC object detection benchmark. More importantly, FoveaBox avoids all computation and hyper-parameters related to anchor boxes, which are often sensitive to the final detection performance. We believe the simple and effective approach will serve as a solid baseline and help ease future research for object detection. The code has been made publicly available at \nhttps://github.com/taokong/FoveaBox \n.","authors":["Tao Kong","Fuchun Sun","Huaping Liu","Yuning Jiang"],"meta":["June 2020IEEE Transactions on Image Processing PP(99):1-1","DOI:10.1109/TIP.2020.3002345"],"references":["339561869_FCOS_Fully_Convolutional_One-Stage_Object_Detection","336934637_Deep_Learning_for_Generic_Object_Detection_A_Survey","321180719_Single-Shot_Refinement_Neural_Network_for_Object_Detection","319770123_Densely_Connected_Convolutional_Networks","318258790_RON_Reverse_Connection_with_Objectness_Prior_Networks_for_Object_Detection","312759848_DSSD_Deconvolutional_Single_Shot_Detector","311769895_Beyond_Skip_Connections_Top-Down_Modulation_for_Object_Detection","305857552_UnitBox_An_Advanced_Object_Detection_Network","303657108_TensorFlow_A_system_for_large-scale_machine_learning","347339897_SOLO_Segmenting_Objects_by_Locations","343461365_Hit-Detector_Hierarchical_Trinity_Architecture_Search_for_Object_Detection","343461358_CentripetalNet_Pursuing_High-Quality_Keypoint_Pairs_for_Object_Detection","343456623_EfficientDet_Scalable_and_Efficient_Object_Detection","339562054_RepPoints_Point_Set_Representation_for_Object_Detection","339560816_CenterNet_Keypoint_Triplets_for_Object_Detection","339559417_Scale-Aware_Trident_Networks_for_Object_Detection","339554612_AutoFocus_Efficient_Multi-Scale_Inference","338513352_Bottom-Up_Object_Detection_by_Grouping_Extreme_and_Center_Points","338510048_Region_Proposal_by_Guided_Anchoring","338508710_Deformable_ConvNets_V2_More_Deformable_Better_Results","338506619_Feature_Selective_Anchor-Free_Module_for_Single-Shot_Object_Detection","335007511_P-CNN_Part-Based_Convolutional_Neural_Networks_for_Fine-Grained_Visual_Categorization","333359371_Feature_Pyramid_Reconfiguration_With_Consistent_Loss_for_Object_Detection","329745798_Relation_Networks_for_Object_Detection","328143821_CornerNet_Detecting_Objects_as_Paired_Keypoints_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Part_XIV","328142654_Acquisition_of_Localization_Confidence_for_Accurate_Object_Detection_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Part_XIV","328123781_Deep_Feature_Pyramid_Reconfiguration_for_Object_Detection_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Part_V","326566753_Focal_Loss_for_Dense_Object_Detection","324387691_YOLOv3_An_Incremental_Improvement","322060558_Deformable_Convolutional_Networks","322059652_DSOD_Learning_Deeply_Supervised_Object_Detectors_from_Scratch","322058119_Soft-NMS_-_Improving_Object_Detection_with_One_Line_of_Code","321512547_Cascade_R-CNN_Delving_into_High_Quality_Object_Detection","320968449_EAST_An_Efficient_and_Accurate_Scene_Text_Detector","320967941_YOLO9000_Better_Faster_Stronger","320964885_SpeedAccuracy_Trade-Offs_for_Modern_Convolutional_Object_Detectors","320964510_Feature_Pyramid_Networks_for_Object_Detection","319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","319769911_Faster_R-CNN_Towards_Real-Time_Object_Detection_with_Region_Proposal_Networks","311610815_Multi-oriented_Text_Detection_with_Fully_Convolutional_Networks","311609522_You_Only_Look_Once_Unified_Real-Time_Object_Detection","311609212_HyperNet_Towards_Accurate_Region_Proposal_Generation_and_Joint_Object_Detection","311609097_Training_Region-Based_Object_Detectors_with_Online_Hard_Example_Mining","310440947_Associative_EmbeddingEnd-to-End_Learning_for_Joint_Detection_and_Grouping","307870837_Learning_Rotation-Invariant_Convolutional_Neural_Networks_for_Object_Detection_in_VHR_Optical_Remote_Sensing_Images","305267748_Neuroscience_Exploring_the_brain_Fourth_edition","303027834_Co-Saliency_Detection_via_a_Self-Paced_Multiple-Instance_Learning_Framework","301921832_Fully_convolutional_networks_for_semantic_segmentation","287250848_Inside-Outside_Net_Detecting_Objects_in_Context_with_Skip_Pooling_and_Recurrent_Neural_Networks","286513835_SSD_Single_Shot_MultiBox_Detector","286512696_Deep_Residual_Learning_for_Image_Recognition","281895687_DenseBox_Unifying_Landmark_Localization_with_End_to_End_Object_Detection","281327886_Histograms_of_Oriented_Gradients_for_Human_Detection","275973799_Object_Detection_via_a_Multi-region_and_Semantic_Segmentation-Aware_CNN_Model"]}