{"id":"320954341_Generalization_of_the_de_Bruijn_identity_to_general_PH-entropies_and_PH-Fisher_informations","abstract":"In this paper, we propose generalizations of the de Bruijn identity based on extensions of the Shannon entropy, Fisher information and their associated divergences or relative measures. The foundation of these generalizations are the Φ- entropies and divergences of the Csiszár (or Salicrú) class considered within a multidimensional context, including the one-dimensional case, and for several type of noisy channels characterized by a more general probability distribution beyond the well-known Gaussian noise. We found that the gradient and/or the Hessian of these entropies or divergences with respect to the noise parameters naturally give rise to generalized versions of the Fisher information or divergence, which are named as the Φ-Fisher information (divergence). The obtained identities can be viewed as further extensions of the classical de Bruijn identity. Analogously, it is shown that a similar relation holds between the Φ-divergence and an extended mean-square error, named Φ-mean square error, for the Gaussian channel.","authors":["Irene Valero-Toranzo","Steeve Zozor","Jean-Marc Brossier"],"meta":["November 2017IEEE Transactions on Information Theory PP(99):1-1","DOI:10.1109/TIT.2017.2771209"],"references":["319855267_On_Generalized_Stam_Inequalities_and_Fisher-Renyi_Complexity_Measures","315651923_Information-Estimation_Relationship_in_Mismatched_Gaussian_Channels","226805234_Possible_generalization_of_Boltzmann-Gibbs_statistics","226179755_Entropy_and_Complexity_Analyses_of_D-dimensional_Quantum_Systems","224679036_The_Monotonicity_of_Information_in_the_Central_Limit_Theorem_and_Entropy_Power_Inequalities","224621480_Additive_non-Gaussian_noise_channels_mutual_information_and_conditional_mean_estimation","224578537_Relative_Entropy_and_Score_Function_New_Information-Estimation_Relationships_through_Arbitrary_Additive_Perturbation","220482938_On_the_Equivalence_Between_Stein_and_De_Bruijn_Identities","284329441_Mesure_d'ordre_a_de_l'information_au_sens_de_Fisher","281572611_Moment-entropy_inequalities","275967437_Matrix_Analysis_and_Applied_Linear_Algebra","275967213_Matrix_Analysis_and_Applied_Linear_Algebra_Book_and_Solutions_Manual","266939410_ch_a_-divergence_and_generalized_Fisher's_information","266840726_An_extension_of_the_Fisher_information_measure","266239647_Information_Theory_and_the_Central_Limit_Theorem","265352289_Information-Type_Measures_of_Difference_of_Probability_Distributions_and_Indirect_Observations","261122620_New_perspectives_extensions_and_applications_of_de_Bruijn_identity","257199245_The_Heat_Equation_and_Stein's_Identity_Connections_Applications","256994073_Divergence_measures_for_statistical_data_processing-An_annotated_bibliography","246449821_The_Fokker-Planck-Equation_Methods_of_Solution_and_Applications","242324520_Stable_Non-Gaussian_Random_Processes_Stochastic_Models_With_Infinite_Variance","241297248_Science_From_Fisher_Information_A_Unification","239294983_Multifractals_Theory_and_Applications","238973858_A_General_Class_of_Coefficients_of_Divergence_of_One_Distribution_from_Another","236878895_Some_properties_of_generalized_Fisher_information_in_the_context_of_nonextensive_thermostatistics","235409843_Methods_of_Information_Geometry","233387693_On_multidimensional_generalized_Cram'er-Rao_inequalities_uncertaintyrelations_and_characterizations_of_generalized_q-Gaussian_distributions","232128602_Quantification_method_of_classification_processes_Concept_of_structural_a_-entropy","227992567_Elements_of_Information_Theory","225098574_On_generalized_Cramer-Rao_inequalities_generalized_Fisher_information_and_characterizations_of_generalized_q-Gaussian_distributions","223752514_Distance_measures_for_signal_processing_and_pattern_recognition","223360213_Tsallis-like_information_measures_and_the_analysis_of_complex_signals","223063538_Generalized_entropy_as_a_measure_of_quantum_uncertainty","222986049_A_coding_theorem_and_Renyi's_entropy","222574140_A_symmetric_information_divergence_measure_of_the_Csiszar's_f-divergence_class_and_its_bounds","222544664_Non_Linear_Kinetics_underlying_Generalized_Statistics","222523412_Entropy_as_a_tool_for_analyzing_statistical_dependences_in_financial_time_series","222511980_Some_inequalities_satisfied_by_the_quantities_of_information_of_Fisher_and_Shannon","222422115_The_world_according_to_Renyi_Thermodynamics_of_multifractal_systems","222421010_Analysis_of_signals_in_the_Fisher-Shannon_information_plane","222401241_Source_Coding_with_Escort_Distributions_and_Renyi_Entropy_Bounds","221671582_On_a_b_q-generalized_Fisher_information_and_inequalities_involving_q-Gaussian_distributions","220685212_Moment-Entropy_Inequalities_for_a_Random_Vector","220681174_Gradient_of_mutual_information_in_linear_vector_Gaussian_channels","220679826_Extensions_of_Fisher_Information_and_Stam's_Inequality","220679088_Mismatched_Estimation_and_Relative_Entropy","220248802_Generalized_Information_Functions","200524441_On_measures_of_entropy_and_information","200034021_Elements_of_Information_Theory","51993442_A_Mathematical_Theory_of_Communication","48173370_Jensen_divergence_based_on_Fisher's_information","38361413_Entropy_and_the_Central_Limit_Theorem","26365871_Nonextensive_Statistics_Theoretical_Experimental_and_Computational_Evidences_and_Connections","39082569_Funciones_de_entropia_asociadas_a_medidas_de_Csiszar","13988269_The_Mathematical_Theory_of_Communication"]}