{"id":"305185995_Direct_Sparse_Odometry","abstract":"We propose a novel direct sparse visual odometry formulation. It combines a fully direct probabilistic model (minimizing a photometric error) with consistent, joint optimization of all model parameters, including geometry -- represented as inverse depth in a reference frame -- and camera motion. This is achieved in real time by omitting the smoothness prior used in other direct methods and instead sampling pixels evenly throughout the images. Since our method does not depend on keypoint detectors or descriptors, it can naturally sample pixels from across all image regions that have intensity gradient, including edges or smooth intensity variations on mostly white walls. The proposed model integrates a full photometric calibration, accounting for exposure time, lens vignetting, and non-linear response functions. We thoroughly evaluate our method on three different datasets comprising several hours of video. The experiments show that the presented approach significantly outperforms state-of-the-art direct and indirect methods in a variety of real-world settings, both in terms of tracking accuracy and robustness.","authors":["Jakob Engel","Vladlen Koltun","Daniel Cremers"],"meta":["July 2016IEEE Transactions on Pattern Analysis and Machine Intelligence PP(99)","DOI:10.1109/TPAMI.2017.2658577"],"references":["291954561_The_EuRoC_micro_aerial_vehicle_datasets","271823237_ORB-SLAM_a_versatile_and_accurate_monocular_SLAM_system","265683241_Keyframe-Based_Visual-Inertial_Odometry_Using_Nonlinear_Optimization","262378171_REMODE_Probabilistic_Monocular_Dense_Reconstruction_in_Real_Time","262378002_SVO_Fast_Semi-Direct_Monocular_Visual_Odometry","261496377_Real-time_motion_tracking_on_a_cellphone_using_inertial_sensing_and_a_rolling-shutter_camera","254098771_iSAM2_Incremental_Smoothing_and_Mapping_Using_the_Bayes_Tree","224332456_Inverse_Depth_Parametrization_for_Monocular_SLAM","221113828_Real-Time_Dense_Geometry_from_a_Handheld_Camera","220659629_Dense_versus_Sparse_Approaches_for_Estimating_the_Fundamental_Matrix","6397818_MonoSLAM_real-time_single_camera_SLAM","319770169_LSD-SLAM_large-scale_direct_monocular_SLAM","308855101_Large-scale_direct_SLAM_with_stereo_cameras","308821220_Large-scale_direct_SLAM_for_omnidirectional_cameras","305186921_A_Photometrically_Calibrated_Benchmark_For_Monocular_Visual_Odometry","303123869_Parallel_tracking_and_mapping_for_small_AR_workspaces","302305301_Dense_Monocular_Depth_Estimation_in_Complex_Dynamic_Scenes","300412679_Dense_Continuous-Time_Tracking_and_Mapping_with_Rolling_Shutter_RGB-D_Cameras","286680449_A_benchmark_for_RGB-D_visual_odometry_3D_reconstruction_and_SLAM","285250506_Semi-dense_visual_odometry_for_AR_on_a_smartphone","261290739_Scale-aware_navigation_of_a_low-cost_quadrocopter_with_a_monocular_camera","225168176_A_First-Estimates_Jacobian_EKF_for_Improving_SLAM_Consistency","221111724_DTAM_Dense_tracking_and_mapping_in_real-time","221110313_Double_window_optimisation_for_constant_time_visual_SLAM","4334429_Parallel_Tracking_and_Mapping_for_Small_AR_Workspaces"]}