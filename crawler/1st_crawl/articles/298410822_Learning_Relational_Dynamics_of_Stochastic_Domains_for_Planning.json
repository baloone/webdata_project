{"id":"298410822_Learning_Relational_Dynamics_of_Stochastic_Domains_for_Planning","abstract":"Probabilistic planners are very flexible tools that can provide good solutions for difficult tasks. However, they rely on a model of the domain, which may be costly to either hand code or automatically learn for complex tasks. We propose a new learning approach that (a) requires only a set of state transitions to learn the model; (b) can cope with uncertainty in the effects; (c) uses a relational representation to generalize over different objects ; and (d) in addition to action effects, it can also learn exogenous effects that are not related to any action , e.g., moving objects, endogenous growth and natural development. The proposed learning approach combines a multi-valued variant of inductive logic programming for the generation of candidate models, with an optimization method to select the best set of planning operators to model a problem. Finally, experimental validation is provided that shows improvements over previous work.","authors":["David Martínez","Guillem Alenyà","Carme Torras","Tony Ribeiro"],"meta":["June 2016","Conference: International Conference on Automated Planning and SchedulingAt: London"],"references":["283764594_Learning_probabilistic_action_models_from_interpretation_transitions","257618580_Learning_from_interpretation_transition","257311157_Active_Learning_for_Teaching_a_Robot_Grounded_Relational_Symbols","290772849_Reverse_iterative_deepening_for_finite-horizon_MDPs_with_large_branching_factors","269725515_Planning_robot_manipulation_to_clean_planar_surfaces","268040816_Efficient_learning_of_relational_models_for_sequential_decision_making","261598780_Scalable_Approximate_Policies_for_Markov_Decision_Process_Models_of_Hospital_Elective_Admissions","261104605_Action-model_acquisition_for_planning_via_transfer_learning","261039132_Learning_revised_models_for_planning_in_adaptive_systems","253603006_From_Non-Deterministic_to_Probabilistic_Planning_with_the_help_of_Statistical_Relational_Learning"]}