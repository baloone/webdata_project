{"id":"273425837_Comparability_of_Test_Results_of_Computer_based_Tests_CBT_and_Paper_and_Pencil_Tests_PPT_among_English_Language_Learners_in_Iran","abstract":"This study aims at examining the score comparability of institutional multiple-choice reading comprehension tests in two testing methods, i.e. paper-based and computer-based tests taken by Iranian first-year English students in Azad University of Tehran, Iran. In order to find the results, the researcher required examining the impact of computer-based testing (henceforth CBT) on the test score results, and exploring the relationship between particular test takers’ characteristics such as prior computer familiarity and computer attitudes as well as test performancewith their test scores. Two equivalent tests were administered to participants on two different occasions. Utilizing matched t-test to compare the means of two test modes, the results of the study show the priority of PPT over CBT with .01 degree of difference at p<05. Using ANOVA, the findings revealed that computer familiarity and attitude towards computer had no significant influence on the students’ performance in computerized test. Additionally, participants showed more preference on test features presented on the computer test.","authors":["Monirosadat Hosseini","Mohamad Z. A. Jafre","Mostafa Baghdarnia"],"meta":["May 2014Procedia - Social and Behavioral Sciences 98:659-667","DOI:10.1016/j.sbspro.2014.03.465","Project: The Relationship Between Technological Research Skills and Research Self-Efficacy of Higher Education Students"],"references":["274713232_Evaluating_comparability_of_paper-and-pencil_and_computer-based_assessment_in_a_K-12_setting_1","298934457_An_Examination_of_the_Equivalence_between_Non-Adaptive_Computer-Based_and_Traditional_Testing","285740962_The_art_of_writing_a_scientific_article","285304583_FIELD_TEST_OF_A_COMPUTER-BASED_GRE_GENERAL_TEST","285304574_ANALYSIS_OF_DISCOURSE_FEATURES_AND_VERIFICATION_OF_SCORING_LEVELS_FOR_INDEPENDENT_AND_INTEGRATED_PROTOTYPE_WRITTEN_TASKS_FOR_THE_NEW_TOEFLR","284665951_The_construction_of_a_Turkish_computer_attitude_scale","279566648_Classroom_minute_by_assessment_minute_day_by_day","271698989_Comparability_of_Computer_and_Paper-and-Pencil_Scores_for_Two_CLEPR_General_Examinations","265705438_Classroom_assessment_Minute_by_minute_day_by_day","265525245_An_Investigation_of_the_Impact_of_Composition_Medium_on_the_Quality_of_TOEFL_Writing_Scores","249870144_Modern_language_testing_at_the_turn_of_the_century_Assuring_that_what_we_count_counts","242580253_Administration_Mode_Comparability_Study_for_Stanford_Diagnostic_Reading_and_Mathematics_Tests","250144827_The_Score_Comparability_of_Computerized_and_Paper-and-Pencil_Formats_for_K-3_Reading_Tests","248941029_Comparability_of_Computer_and_Paper-Administered_Multiple-Choice_Tests_for_K-12_Populations_A_Synthesis","240278395_Reliability_and_Factorial_Validity_of_Computer_Attitude_Scales"]}