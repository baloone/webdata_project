{"id":"286594344_Multiple_Granularity_Analysis_for_Fine-Grained_Action_Detection","abstract":"We propose to decompose the fine-grained human activ- ity analysis problem into two sequential tasks with increas- ing granularity. Firstly, we infer the coarse interaction sta- tus, i.e., which object is being manipulated and where it is. Knowing that the major challenge is frequent mutual oc- clusions during manipulation, we propose an 'interaction tracking' framework in which hand/object position and in- teraction status are jointly tracked by explicitly modeling the contextual information between mutual occlusion and interaction status. Secondly, the inferred hand/object posi- tion and interaction status are utilized to provide 1) more compact feature pooling by effectively pruning large num- ber of motion features from irrelevant spatio-temporal po- sitions and 2) discriminative action detection by a granu- larity fusion strategy. Comprehensive experiments on two challenging fine-grained activity datasets (i.e., cooking ac- tion) show that the proposed framework achieves high ac- curacy/robustness in tracking multiple mutually occluded hands/objects during manipulation as well as significant performance improvement on fine-grained action detection over state-of-the-art methods.","authors":["Bingbing Ni","Vignesh Paramathayalan","Pierre Moulin"],"meta":["June 2014","DOI:10.1109/CVPR.2014.102","Conference: 2014 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"],"references":["262237442_Fine-grained_kitchen_activity_recognition_using_RGB-D","231609161_Learning_Human_Activities_and_Object_Affordances_from_RGB-D_Videos","224323322_Model-Based_Hand_Tracking_with_Texture_Shading_and_Self-occlusions","221303719_Simultaneous_Visual_Recognition_of_Manipulation_Actions_and_Manipulated_Objects","221260163_Unsupervised_Learning_of_Human_Action_Categories_Using_Spatial-Temporal_Words","221110356_Fast_Multiple_Object_Tracking_via_a_Hierarchical_Particle_Filter","49853604_Discriminative_Video_Pattern_Search_for_Efficient_Action_Detection","49799896_Multiple_Object_Tracking_Using_K-Shortest_Paths_Optimization","4082162_An_algorithm_for_multiple_object_trajectory_tracking","4038396_Space-time_interest_points","3940787_Multi-Object_Tracking_Using_Dynamical_Graph_Matching","3816578_Exploiting_human_actions_and_object_context_for_recognition_tasks","3816561_A_Probabilistic_Exclusion_Principle_for_Tracking_Multiple_Objects","319770820_Histograms_of_Oriented_Gradients_for_Human_Detection","261334190_Hand_tracking_by_binary_quadratic_programming_and_its_application_to_retail_activity_recognition","261283554_A_Database_for_Fine_Grained_Activity_Detection_of_Cooking_Activities","261276849_Pixel-Level_Hand_Detection_in_Ego-centric_Videos","261115901_A_combined_pose_object_and_feature_model_for_action_understanding","229078422_Loopy_Belief_Propagation_for_Approximate_Inference_-_an_Empirical_Study","228518860_Classifying_actions_and_measuring_action_similarity_by_modeling_the_mutual_context_of_objects_and_human_poses","224164394_P-N_Learning_Bootstrapping_Binary_Classifiers_by_Structural_Constraints","224136049_Spatio-Temporal_Relationship_Match_Video_Structure_Comparison_for_Recognition_of_Complex_Human_Activities","221363763_Multiple_Object_Tracking_with_Kernel_Particle_Filter","220343422_Cutting-Plane_Training_of_Structural_SVMs","51025101_Action_Recognition_by_Dense_Trajectories","49661958_Hidden_Part_Models_for_Human_Action_Recognition_Probabilistic_vs_Max-Margin","4301708_A_Scalable_Approach_to_Activity_Recognition_based_on_Object_Use","4082291_Tracking_multiple_humans_in_crowded_environment","3277975_Multiple_Hypothesis_Tracking_for_Multiple_Target_Tracking"]}