{"id":"336819471_Towards_Interpretability_of_Segmentation_Networks_by_Analyzing_DeepDreams","abstract":"Interpretability of a neural network can be expressed as the identification of patterns or features to which the network can be either sensitive or indifferent. To this aim, a method inspired by DeepDream is proposed, where the activation of a neuron is maximized by performing gradient ascent on an input image. The method outputs curves that show the evolution of features during the maximization. A controlled experiment shows how it enables to assess the robustness to a given feature, or by contrast its sensitivity. The method is illustrated on the task of segmenting tumors in liver CT images.","authors":["Vincent Couteaux","Olivier Nempont","Guillaume Pizaine","Isabelle Bloch"],"meta":["October 2019","DOI:10.1007/978-3-030-33850-3_7","In book: Interpretability of Machine Intelligence in Medical Image Computing and Multimodal Learning for Clinical Decision Support, Second International Workshop, iMIMIC 2019, and 9th International Workshop, ML-CDS 2019, Held in Conjunction with MICCAI 2019, Shenzhen, China, October 17, 2019, Proceedings (pp.56-63)"],"references":["327709435_Peeking_Inside_the_Black-Box_A_Survey_on_Explainable_Artificial_Intelligence_XAI","313857497_Automatic_Liver_and_Tumor_Segmentation_of_CT_and_MRI_Volumes_using_Cascaded_Fully_Convolutional_Neural_Networks","286385791_Explaining_NonLinear_Classification_Decisions_with_Deep_Taylor_Decomposition","286301796_Visualizing_Deep_Convolutional_Neural_Networks_Using_Natural_Pre-Images","284170872_Radiomics_Images_Are_More_than_Pictures_They_Are_Data","277248670_On_Pixel-Wise_Explanations_for_Non-Linear_Classifier_Decisions_by_Layer-Wise_Relevance_Propagation","262817448_Decoding_tumour_phenotype_by_noninvasive_imaging_using_a_quantitative_radiomics_approach","332048309_Kindey_Cortex_Segmentation_in_2D_CT_with_U-Nets_Ensemble_Aggregation","317391256_Beyond_imaging_The_promise_of_radiomics","305999024_Why_Should_I_Trust_You_Explaining_the_Predictions_of_Any_Classifier","305342147_Why_Should_I_Trust_You_Explaining_the_Predictions_of_Any_Classifier","263002356_Microsoft_COCO_Common_Objects_in_Context","258424423_Visualizing_and_Understanding_Convolutional_Neural_Networks"]}