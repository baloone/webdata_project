{"id":"325492539_Using_Deep_Learning_for_Title-Based_Semantic_Subject_Indexing_to_Reach_Competitive_Performance_to_Full-Text","abstract":"For (semi-)automated subject indexing systems in digital libraries, it is often more practical to use metadata such as the title of a publication instead of the full-text or the abstract. Therefore, it is desirable to have good text mining and text classification algorithms that operate well already on the title of a publication. So far, the classification performance on titles is not competitive with the performance on the full-texts if the same number of training samples is used for training. However, it is much easier to obtain title data in large quantities and to use it for training than full-text data. In this paper, we investigate the question how models obtained from training on increasing amounts of title training data compare to models from training on a constant number of full-texts. We evaluate this question on a large-scale dataset from the medical domain (PubMed) and from economics (EconBiz). In these datasets, the titles and annotations of millions of publications are available, and they outnumber the available full-texts by a factor of 20 and 15, respectively. To exploit these large amounts of data to their full potential, we develop three strong deep learning classifiers and evaluate their performance on the two datasets. The results are promising. On the EconBiz dataset, all three classifiers outperform their full-text counterparts by a large margin. The best title-based classifier outperforms the best full-text method by 9.4%. On the PubMed dataset, the best title-based method almost reaches the performance of the best full-text classifier, with a difference of only 2.9%.","authors":["Florian Mai","Lukas Galke","Ansgar Scherp"],"meta":["May 2018","DOI:10.1145/3197026.3197039","Conference: the 18th ACM/IEEE","Project: Extreme Multi-Label Classification"],"references":["321890892_Using_Titles_vs_Full-text_as_Source_for_Automated_Semantic_Document_Annotation","319035676_Recent_Trends_in_Deep_Learning_Based_Natural_Language_Processing","316168423_MeSH_Now_Automatic_MeSH_indexing_at_PubMed_scale_via_learning_to_rank","305334401_Hierarchical_Attention_Networks_for_Document_Classification","284576917_Glove_Global_Vectors_for_Word_Representation","283080770_A_Comparison_of_Different_Strategies_for_Automated_Semantic_Document_Annotation","281607724_Character-level_Convolutional_Networks_for_Text_Classification","279310231_Amplifying_the_Impact_of_Open_Access_Wikipedia_and_the_Diffusion_of_Science","278331931_MeSHLabeler_improving_the_accuracy_of_large-scale_MeSH_indexing_by_integrating_diverse_evidence","277411157_Deep_Learning","275639796_An_overview_of_the_BIOASQ_large-scale_biomedical_semantic_indexing_and_question_answering_competition","273640320_LSTM_A_search_space_odyssey","273067823_Improved_Semantic_Representations_From_Tree-Structured_Long_Short-Term_Memory_Networks","259367487_Large-Scale_Multi-label_Text_Classification_-_Revisiting_Neural_Networks","220924337_A_source_independent_framework_for_research_paper_recommendation","51951266_Statistical_Topic_Models_for_Multi-Label_Document_Classification","51166278_Recommending_MeSH_terms_for_annotating_biomedical_articles","13853244_Long_Short-term_Memory","3297607_Multilabel_Neural_Networks_with_Applications_to_Functional_Genomics_and_Text_Categorization","319769994_A_Theoretically_Grounded_Application_of_Dropout_in_Recurrent_Neural_Networks","318764077_Deep_Learning_for_Extreme_Multi-label_Text_Classification","318742463_Very_Deep_Convolutional_Networks_for_Text_Classification","318741395_Bag_of_Tricks_for_Efficient_Text_Classification","318527982_On_the_State_of_the_Art_of_Evaluation_in_Neural_Language_Models","318418622_Do_Convolutional_Networks_need_to_be_Deep_for_Text_Classification","311609041_Deep_Residual_Learning_for_Image_Recognition","305334589_Dependency_Sensitive_Convolutional_Neural_Networks_for_Modeling_Sentences_and_Documents","303901942_Profiling_vs_Time_vs_Content_What_does_Matter_for_Top-k_Publication_Recommendation_based_on_Twitter_Profiles","301857163_Efficient_Character-level_Document_Classification_by_Combining_Convolution_and_Recurrent_Layers","301839505_Multichannel_Variable-Size_Convolution_for_Sentence_Classification","286794765_Dropout_A_Simple_Way_to_Prevent_Neural_Networks_from_Overfitting","286512696_Deep_Residual_Learning_for_Image_Recognition","272194743_Batch_Normalization_Accelerating_Deep_Network_Training_by_Reducing_Internal_Covariate_Shift","269935079_Adam_A_Method_for_Stochastic_Optimization","265052545_Convolutional_Neural_Networks_for_Sentence_Classification","223117716_Buckley_C_Term-Weighting_Approaches_in_Automatic_Text_Retrieval_Information_Processing_Management_245_513-523","220433356_Comparison_of_full-text_searching_to_metadata_searching_for_genes_in_two_biomedical_literature_cohorts","220228998_Term-Weighting_Approaches_in_Automatic_Text_Retrieval","215721756_Lecture_Notes_in_Computer_Science","2681820_Text_Categorization_with_Support_Vector_Machines_Learning_with_Many_Relevant_Features"]}