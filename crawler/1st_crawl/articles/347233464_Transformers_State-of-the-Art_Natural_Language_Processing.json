{"id":"347233464_Transformers_State-of-the-Art_Natural_Language_Processing","authors":["Thomas Wolf","Lysandre Debut","Victor Sanh","Julien Chaumond"],"meta":["January 2020","DOI:10.18653/v1/2020.emnlp-demos.6","Conference: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations"],"references":["336868525_ALBERT_A_LITE_BERT_FOR_SELF-SUPERVISED_LEARNING_OF_LANGUAGE_REPRESENTATIONS","334116365_Universal_Language_Model_Fine-tuning_for_Text_Classification","343300293_Stanza_A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages","336995622_SciBERT_A_Pretrained_Language_Model_for_Scientific_Text","335788074_Texar_A_Modularized_Versatile_and_Extensible_Toolkit_for_Text_Generation","335783534_COMET_Commonsense_Transformers_for_Automatic_Knowledge_Graph_Construction","335781169_Transformer-XL_Attentive_Language_Models_beyond_a_Fixed-Length_Context","335778883_BERT_Rediscovers_the_Classical_NLP_Pipeline","334600392_fairseq_A_Fast_Extensible_Toolkit_for_Sequence_Modeling","330268857_Model_Cards_for_Model_Reporting"]}