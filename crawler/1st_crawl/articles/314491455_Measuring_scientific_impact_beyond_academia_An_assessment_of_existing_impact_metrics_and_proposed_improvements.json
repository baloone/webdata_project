{"id":"314491455_Measuring_scientific_impact_beyond_academia_An_assessment_of_existing_impact_metrics_and_proposed_improvements","abstract":"How does scientific research affect the world around us? Being able to answer this question is of great importance in order to appropriately channel efforts and resources in science. The impact by scientists in academia is currently measured by citation based metrics such as h-index, i-index and citation counts. These academic metrics aim to represent the dissemination of knowledge among scientists rather than the impact of the research on the wider world. In this work we are interested in measuring scientific impact beyond academia, on the economy, society, health and legislation (comprehensive impact). Indeed scientists are asked to demonstrate evidence of such comprehensive impact by authoring case studies in the context of the Research Excellence Framework (REF). We first investigate the extent to which existing citation based metrics can be indicative of comprehensive impact. We have collected all recent REF impact case studies from 2014 and we have linked these to papers in citation networks that we constructed and derived from CiteSeerX, arXiv and PubMed Central using a number of text processing and information retrieval techniques. We have demonstrated that existing citation-based metrics for impact measurement do not correlate well with REF impact results. We also consider metrics of online attention surrounding scientific works, such as those provided by the Altmetric API. We argue that in order to be able to evaluate wider non-academic impact we need to mine information from a much wider set of resources, including social media posts, press releases, news articles and political debates stemming from academic work. We also provide our data as a free and reusable collection for further analysis, including the PubMed citation network and the correspondence between REF case studies, grant applications and the academic literature.","authors":["James Ravenscroft","Maria Liakata","Amanda Clare","Daniel Duma"],"meta":["March 2017PLoS ONE 12(3):e0173152","DOI:10.1371/journal.pone.0173152"],"references":["311458412_How_many_scientific_papers_are_mentioned_in_policy-related_documents_An_empirical_investigation_using_Web_of_Science_and_Altmetric_data","305980268_To_what_extent_does_the_Leiden_manifesto_also_apply_to_altmetrics_A_discussion_of_the_manifesto_against_the_background_of_research_into_altmetrics","290219000_Predicting_the_impact_of_scientific_concepts_using_full-text_features","275335177_The_Leiden_Manifesto_for_research_metrics","309240917_Enriching_scholarly_content_with_article-level_discussion_and_metrics","309177955_Altmetrics_Value_all_research_products","308571603_Academic_Research_in_the_21st_Century_Maintaining_Scientific_Integrity_in_a_Climate_of_Perverse_Incentives_and_Hypercompetition","289744103_RefSeer_A_citation_recommendation_system","279968736_A_review_of_the_literature_on_citation_impact_indicators","272271907_Altmetric_Enriching_scholarly_content_with_article-leveldiscussion_and_metrics"]}