{"id":"335746852_Insurance_Discrimination_and_Fairness_in_Machine_Learning_An_Ethical_Analysis","abstract":"Here we provide an ethical analysis of discrimination in private insurance to guide the application of non-discriminatory algorithms for risk prediction in the insurance context. This addresses the need for ethical guidance of data-science experts and business managers. The reference to private insurance as a business practice is essential in our approach, because the consequences of discrimination and predictive inaccuracy in underwriting are different from those of using predictive algorithms in other sectors (e.g. medical diagnosis, sentencing). Moreover, the computer science literature has demonstrated the existence of a trade-off in the extent to which one can pursue non- discrimination versus predictive accuracy. Again the moral assessment of this trade-off is related to the context of application.","authors":["Michele Loi","Markus Christen"],"meta":["January 2019SSRN Electronic Journal","DOI:10.2139/ssrn.3438823","Project: Big data in insurance (SNF project NRP 75)"],"references":["327796323_Disagreement_Peerhood_and_Compromise_in_advance","323461333_Ethical_Implications_and_Accountability_of_Algorithms","320297065_On_formalizing_fairness_in_prediction_with_machine_learning","315871857_Fairness_Beyond_Disparate_Treatment_Disparate_Impact_Learning_Classification_without_Disparate_Mistreatment","315667137_Fairness_in_Criminal_Justice_Risk_Assessments_The_State_of_the_Art","313107433_Algorithmic_decision_making_and_the_cost_of_fairness","312453085_We_are_all_different_Statistical_discrimination_and_the_right_to_be_treated_as_an_individual","334006211_Profiles_Probabilities_and_Stereotypes","330265558_A_Moral_Framework_for_Understanding_Fair_ML_through_Economic_Models_of_Equality_of_Opportunity","312620522_Social_organization_stress_and_health"]}