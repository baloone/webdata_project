{"id":"304574380_From_handcrafted_to_learned_representations_for_human_action_recognition_A_survey","abstract":"Human action recognition is an important branch among the studies of both human perception and computer vision systems. Along with the development of artificial intelligence, deep learning techniques have gained remarkable reputation when dealing with image categorization tasks (e.g., object detection and classification). However, since human actions normally present in the form of sequential image frames, analyzing human action data requires significantly increased computational power than still images when deep learning techniques are employed. Such a challenge has been the bottleneck for the migration of learning-based image representation techniques to action sequences, so that the old fashioned handcrafted human action representations are still widely used for human action recognition tasks. On the other hand, since handcrafted representations are usually ad-hoc and overfit to specific data, they are incapable of being generalized to deal with various realistic scenarios. Consequently, resorting to deep learning action representations for human action recognition tasks is eventually a natural option. In this work, we provide a detailed overview of recent advancements in human action representations. As the first survey that covers both handcrafted and learning-based action representations, we explicitly discuss the superiorities and limitations of exiting techniques from both kinds. The ultimate goal of this survey is to provide comprehensive analysis and comparisons between learning-based and handcrafted action representations respectively, so as to inspire action recognition researchers towards the study of both kinds of representation techniques.","authors":["Fan Zhu","Ling Shao","Jin Xie","Yi Fang"],"meta":["June 2016Image and Vision Computing 55","DOI:10.1016/j.imavis.2016.06.007"],"references":["257672334_Dense_Trajectories_and_Motion_Boundary_Descriptors_for_Action_Recognition","257672261_Image_Classification_with_the_Fisher_Vector_Theory_and_Practice","228088864_Ward_RK_Learning_sparse_representations_for_human_action_recognition_IEEE_Trans_PAMI_34_1576-1588","225761164_SURF_Speeded_up_robust_features","225191516_View_Invariance_for_Human_Action_Recognition","222505795_The_Visual_Analysis_of_Human_Movement_A_Survey","222347483_Principal_Component_Analysis","221620711_Lecture_Notes_in_Computer_Science","221364708_Real-Time_Human_Pose_Recognition_in_Parts_from_Single_Depth_Images","221303896_Improving_the_Fisher_Kernel_for_Large-Scale_Image_Classification","220320057_Learning_Precise_Timing_with_LSTM_Recurrent_Networks","24213728_A_Novel_Connectionist_System_for_Unconstrained_Handwriting_Recognition","15736280_Mathematical_description_of_the_response_of_simple_cortical_cells","10598462_Audiovisual_motor_neurons_and_action_recognition","7773326_Brain_Signatures_of_Meaning_Access_in_Action_Word_Recognition","3328006_Toward_automatic_phenotyping_of_developing_embryos_from_videos","3319912_K-SVD_An_Algorithm_for_Designing_Overcomplete_Dictionaries_for_Sparse_Representation","2985446_Gradient-Based_Learning_Applied_to_Document_Recognition","308797129_Distributional_structure","305867060_Hierarchical_recurrent_neural_network_for_skeleton_based_action_recognition","290214563_Action_Recognition_with_Stacked_Fisher_Vectors","286663779_Unsupervised_Spectral_Dual_Assignment_Clustering_of_Human_Actions_in_Context","280055760_The_effects_of_reboxetine_with_modafinil_on_noxious_tail_pinch-induced_sensorimotor_gating_reactivity_in_rats","272623654_Libsvm","263092621_Action_recognition_by_spatio-temporal_oriented_energies","263051114_Feature_Learning_for_Image_Classification_Via_Multiobjective_Genetic_Programming","262808249_Weakly-Supervised_Cross-Domain_Dictionary_Learning_for_Visual_Recognition","262242421_Trajectory-Based_Modeling_of_Human_Actions_with_Motion_Reference_Points","258896444_Free_Viewpoint_Action_Recognition_Using_Motion_History_Volumes","258424423_Visualizing_and_Understanding_Convolutional_Neural_Networks","255177389_Spatio-Temporal_Laplacian_Pyramid_Coding_for_Action_Recognition","239060569_Viewpoint_Dependence_in_Scene_Recognition","226678977_On_Space-Time_Interest_Points","225153976_Human_Action_Recognition_Using_a_Modified_Convolutional_Neural_Network","223255810_The_Laplacian-of-Gaussian_kernel_a_formal_analysis_and_design_procedure_for_fast_accurate_convolution_and_full-frame_output","222440943_Motion-based_recognition_a_survey","222427666_A_survey_of_advances_in_vision-based_human_motion_capture_and_analysis","221346417_3D_Convolutional_Neural_Networks_for_Human_Action_Recognition","221304550_Human_Detection_Using_Oriented_Histograms_of_Flow_and_Appearance","220744741_Constrained_Optimization_for_Human_Pose_Estimation_from_Depth_Sequences","220611909_Poppe_R_A_Survey_on_Vision-based_Human_Action_Recognition_Image_and_Vision_Computing_286_976-990","220566360_Human_Activity_Analysis_A_Review","200038910_Distinctive_Image_Features_from_Scale-Invariant_Keypoints","37853388_A_Weighted_FMM_Neural_Network_and_Its_Application_to_Face_Detection","19719670_An_evaluation_of_the_two-dimensional_Gabor_filter_model_of_simple_receptive_fields_in_cat_striate_cortex","15829465_Neocognitron_A_self-organizing_neural_network_model_for_a_mechanism_of_pattern_recognition_unaffected_by_shift_in_position","11225943_Biology_of_progesterone_action_during_pregnancy_recognition_and_maintenance_of_pregnancy","8632577_Buccino_G_Binkofski_F_and_Riggio_L_The_mirror_neuron_system_and_action_recognition","7017915_A_Fast_Learning_Algorithm_for_Deep_Belief_Nets","3705661_Human_Motion_Analysis_A_Review"]}