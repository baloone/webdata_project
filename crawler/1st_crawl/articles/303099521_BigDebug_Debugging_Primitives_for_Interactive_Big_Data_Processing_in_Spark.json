{"id":"303099521_BigDebug_Debugging_Primitives_for_Interactive_Big_Data_Processing_in_Spark","abstract":"Developers use cloud computing platforms to process a large quantity of data in parallel when developing big data analytics. Debugging the massive parallel computations that run in today's datacenters is time consuming and error-prone. To address this challenge, we design a set of interactive, real-time debugging primitives for big data processing in Apache Spark, the next generation data-intensive scalable cloud computing platform. This requires rethinking the notion of step-through debugging in a traditional debugger such as gdb, because pausing the entire computation across distributed worker nodes causes significant delay and naively inspecting millions of records using a watchpoint is too time consuming for an end user.\nFirst, BigDebug's simulated breakpoints and on-demand watchpoints allow users to selectively examine distributed, intermediate data on the cloud with little overhead. Second, a user can also pinpoint a crash-inducing record and selectively resume relevant sub-computations after a quick fix. Third, a user can determine the root causes of errors (or delays) at the level of individual records through a fine-grained data provenance capability. Our evaluation shows that BigDebug scales to terabytes and its record-level tracing incurs less than 25% overhead on average. It determines crash culprits orders of magnitude more accurately and provides up to 100% time saving compared to the baseline replay debugger. The results show that BigDebug supports debugging at interactive speeds with minimal performance impact.","authors":["Muhammad Ali Gulzar","Matteo Interlandi","Seunghyun Yoo","Sai Deep Tetali"],"meta":["May 2016Proceedings - International Conference on Software Engineering 2016:784-795","DOI:10.1145/2884781.2884813","Conference: the 38th International Conference"],"references":["289356046_Titian_Data_Provenance_Support_in_Spark","316921933_An_Empirical_Study_on_Quality_Issues_of_Production_Big_Data_Platform","312775005_MapReduce_Simplified_data_processing_on_large_clusters","308871838_An_Empirical_Study_on_Quality_Issues_of_Production_Big_Data_Platform","303918385_Graphx_Graph_processing_in_a_distributed_dataflow_framework","303198479_Resilient_distributed_datasets_A_fault-tolerant_abstraction_for_in-memory_cluster_computing","300581460_Graft","292670724_Titian","290471147_Spark_SQL","277334549_MLlib_Machine_Learning_in_Apache_Spark"]}