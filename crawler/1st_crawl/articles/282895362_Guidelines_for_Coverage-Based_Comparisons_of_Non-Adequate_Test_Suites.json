{"id":"282895362_Guidelines_for_Coverage-Based_Comparisons_of_Non-Adequate_Test_Suites","abstract":"A fundamental question in software testing research is how to compare test suites, often as a means for comparing test-generation techniques that produce those test suites. Researchers frequently compare test suites by measuring their coverage. A coverage criterion C provides a set of test requirements and measures how many requirements a given suite satisfies. A suite that satisfies 100&percnt; of the feasible requirements is called C-adequate. Previous rigorous evaluations of coverage criteria mostly focused on such adequate test suites: given two criteria C and C′, are C-adequate suites on average more effective than C′-adequate suites? However, in many realistic cases, producing adequate suites is impractical or even impossible.\nThis article presents the first extensive study that evaluates coverage criteria for the common case of non-adequate test suites: given two criteria C and C′, which one is better to use to compare test suites? Namely, if suites T1, T2,…,Tn have coverage values c1, c2,…,cn for C and c1′, c2′,…,cn′ for C′, is it better to compare suites based on c1, c2,…,cn or based on c1′, c2′,…,cn′? We evaluate a large set of plausible criteria, including basic criteria such as statement and branch coverage, as well as stronger criteria used in recent studies, including criteria based on program paths, equivalence classes of covered statements, and predicate states. The criteria are evaluated on a set of Java and C programs with both manually written and automatically generated test suites. The evaluation uses three correlation measures. Based on these experiments, two criteria perform best: branch coverage and an intraprocedural acyclic path coverage. We provide guidelines for testing researchers aiming to evaluate test suites using coverage criteria as well as for other researchers evaluating coverage criteria for research use.","authors":["Milos Gligoric","Alex Groce","Chaoqiang Zhang","Rohan Sharma"],"meta":["September 2015ACM Transactions on Software Engineering and Methodology 24(4):1-33","DOI:10.1145/2660767"],"references":["266656271_Code_coverage_for_suite_evaluation_by_developers","263949597_Sampling_Program_Inputs_with_Mutation_Analysis_Going_Beyond_Combinatorial_Interaction_Testing","350683302_Ordinal_Methods_for_Behavioral_Data_Analysis","302683031_Incremental_compositional_dynamic_test_generation","271752241_Criteria_For_Measures_of_Association","266711003_Introduction_to_algorithms_3rd_revised_and_extended_ed","266656203_Coverage_is_not_strongly_correlated_with_test_suite_effectiveness","266500619_Predicting_Test_Suite_Effectiveness_for_Java_Programs","265286435_Industrial_validation_of_test_coverage_quality","263452357_Checked_coverage_An_indicator_for_oracle_quality"]}