{"id":"4182394_Restrictive_compression_techniques_to_increase_level_1_cache_capacity","abstract":"Increasing cache latencies limit L1 cache sizes. In this paper we investigate restrictive compression techniques for level 1 data cache, to avoid an increase in the cache access latency. The basic technique - all words narrow (AWN) - compresses a cache block only if all the words in the cache block are of narrow size. We extend the AWN technique to store a few upper half-words (AHS) in a cache block to accommodate a small number of normal-sized words in the cache block. Further, we make the AHS technique adaptive, where the additional half-words space is adaptively allocated to the various cache blocks. We also propose techniques to reduce the increase in the tag space that is inevitable with compression techniques. Overall, the techniques in this paper increase the average L1 data cache capacity (in terms of the average number of valid cache blocks per cycle) by about 50%, compared to the conventional cache, with no or minimal impact on the cache access time. In addition, the techniques have the potential of reducing the average L1 data cache miss rate by about 23%.","authors":["Prateek Pujara","Aneesh Aggarwal"],"meta":["November 2005","DOI:10.1109/ICCD.2005.94","SourceIEEE Xplore","Conference: Computer Design: VLSI in Computers and Processors, 2005. ICCD 2005. Proceedings. 2005 IEEE International Conference on"],"references":["239223609_Low-Energy_Data_Cache_Using_Sign_Compression_and_Cache_Line_Bisection","238750549_CACTI_30_An_Integrated_Cache_Timing_Power_and_Area_Model","234791111_The_SimpleScalar_tool_set_version_20","228816464_Operating_system_support_for_fast_hardware_compression_of_main_memory_contents","37595019_A_Dynamically_Partitionable_Compressed_Cache","4107271_CoolPression_-_a_hybrid_significance_compression_technique_for_reducing_energy_in_caches","4079986_Wire_Delay_is_Not_a_Problem_for_SMT_In_the_Near_Future","3826693_Design_and_evaluation_of_a_selective_compressed_memory_system","2976152_A_2-ns_cycle_38-ns_access_512-kb_CMOS_ECL_SRAM_with_a_fully_pipelined_architecture","311469073_Frequent_value_locality_and_value-centric_data_cache_design","290651737_Adaptive_Methods_to_Minimize_Decompression_Overhead_for_Compressed_On-Chip_Caches","248011398_The_SimpleScalar_Tool_Set_Version_2","245199280_Adaptive_Methods_to_Minimize_Decompression_Overhead_for_Compressed_On-chip_Cache","222836424_An_on-chip_cache_compression_technique_to_reduce_decompression_overhead_and_design_complexity","221207279_Bit-Sliced_Datapath_for_Energy-Efficient_High_Performance_Microprocessors","220938982_Frequent_Value_Locality_and_Value-Centric_Data_Cache_Design","220771041_Adaptive_Cache_Compression_for_High-Performance_Processors","220271073_A_compressed_memory_hierarchy_using_an_indirect_index_cache","4001370_Exploiting_data-width_locality_to_increase_superscalar_execution_bandwidth","3885100_Dynamic_zero_compression_for_cache_energy_reduction","3885091_Frequent_value_compression_in_data_caches","3787943_Dynamically_Exploiting_Narrow_Width_Operands_to_Improve_Processor_Power_and_Performance","3774790_Power_considerations_in_the_design_of_the_Alpha_21264_microprocessor","3758422_Pipeline_gating_speculation_control_for_energy_reduction","3658982_Design_and_performance_of_a_main_memory_hardware_data_compressor","3623821_Parallel_compression_with_cooperative_dictionary_construction","3215067_The_Alpha_21264_microprocessor","3044418_Cache-memory_interfaces_in_compressed_memory_systems","2460581_Frequent_Value_Compression_in_Data_Caches","2432451_Dynamic_Zero_Compression_for_Cache_Energy_Reduction","2430279_Power_Considerations_in_the_Design_of_the_Alpha_21264_Microprocessor"]}