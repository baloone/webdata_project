{"id":"314274183_Small-sample_reinforcement_learning_Improving_policies_using_synthetic_data","abstract":"Reinforcement learning (RL) concerns algorithms tasked with learning optimal control policies by interacting with or observing a system. In computer science and other fields in which RL originated, large sample sizes are the norm, because data can be generated at will from a generative model. Recently, RL methods have been adapted for use in clinical trials, resulting in much smaller sample sizes. Nonparametric methods are common in RL, but are likely to over-generalize when limited data is available. This paper proposes a novel methodology for learning optimal policies by leveraging the researcher's partial knowledge about the probability transition structure into an approximate generative model from which synthetic data can be produced. Our method is applied to a scenario where the researcher must create a medical prescription policy for managing a disease with sporadically appearing symptoms.","authors":["Stephen Carden","James Livsey"],"meta":["February 2017Intelligent Decision Technologies 11(2):1-9","DOI:10.3233/IDT-170285"],"references":["324314435_Abstraction_Selection_in_Model-Based_Reinforcement_Learning","264707121_Convergence_of_a_Q-learning_Variant_for_Continuous_States_and_Actions","264122881_Practical_Kernel-Based_Reinforcement_Learning","221539780_Optimal_Sample_Selection_for_Batch-mode_Reinforcement_Learning","307963128_On_estimating_regression","260406452_Smooth_Regression_Analysis","243772635_On_the_Sample_Complexity_of_Reinforcement_Learning","243099545_On_Estimating_Regression","242503423_Applied_Probability_Models_with_Optimization","230887855_Markov_Decision_Processes_Discrete_Stochastic_Dynamic_Programming"]}