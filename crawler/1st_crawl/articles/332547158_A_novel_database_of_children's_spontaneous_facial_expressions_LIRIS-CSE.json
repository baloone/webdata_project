{"id":"332547158_A_novel_database_of_children's_spontaneous_facial_expressions_LIRIS-CSE","abstract":"Computing environment is moving towards human-centered designs instead of computer centered designs and human's tend to communicate wealth of information through affective states or expressions. Traditional Human Computer Interaction (HCI) based systems ignores bulk of information communicated through those affective states and just caters for user's intentional input. Generally, for evaluating and benchmarking different facial expression analysis algorithms, standardized databases are needed to enable a meaningful comparison. In the absence of comparative tests on such standardized databases it is difficult to find relative strengths and weaknesses of different facial expression recognition algorithms. In this article we present a novel video database for Children's Spontaneous facial Expressions (LIRIS-CSE). Proposed video database contains six basic spontaneous facial expressions shown by 12 ethnically diverse children between the ages of 6 and 12 years with mean age of 7.3 years. To the best of our knowledge, this database is first of its kind as it records and shows spontaneous facial expressions of children. Previously there were few database of children expressions and all of them show posed or exaggerated expressions which are different from spontaneous or natural expressions. Thus, this database will be a milestone for human behavior researchers. This database will be a excellent resource for vision community for benchmarking and comparing results. In this article, we have also proposed framework for automatic expression recognition based on Convolutional Neural Network (CNN) architecture with transfer learning approach. Proposed architecture achieved average classification accuracy of 75% on our proposed database i.e. LIRIS-CSE.","authors":["Rizwan Ahmed Khan","Arthur Crenn","Alexandre Meyer","Saida Bouakaz"],"meta":["March 2019","Project: Recognizing expressions of children in real life scenarios"],"references":["324005705_What_Do_We_Understand_About_Convolutional_Networks","322810419_A_Brief_Review_of_Facial_Emotion_Recognition_Based_on_Visual_Information","305196650_Going_deeper_with_convolutions","323142064_Deep_Meta-Learning_Learning_to_Learn_in_the_Concept_Space","322863727_Softmax_regression_based_deep_sparse_autoencoder_network_for_facial_emotion_recognition_in_human-robot_interaction","320564854_Real-time_Convolutional_Neural_Networks_for_Emotion_and_Gender_Classification","319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition","318200394_Places_A_10_Million_Image_Database_for_Scene_Recognition","316240524_Saliency_Based_Framework_for_Facial_Expression_Recognition","310752533_Visualizing_and_understanding_convolutional_networks"]}