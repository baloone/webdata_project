{"id":"220679924_Lin_JH_Divergence_measures_based_on_the_Shannon_entropy_IEEE_Trans_Inform_Theory_37_145-151","abstract":"A novel class of information-theoretic divergence measures based\non the Shannon entropy is introduced. Unlike the well-known Kullback\ndivergences, the new measures do not require the condition of absolute\ncontinuity to be satisfied by the probability distributions involved.\nMore importantly, their close relationship with the variational distance\nand the probability of misclassification error are established in terms\nof bounds. These bounds are crucial in many applications of divergence\nmeasures. The measures are also well characterized by the properties of\nnonnegativity, finiteness, semiboundedness, and boundedness","authors":["Jianhua Lin"],"meta":["January 1991IEEE Transactions on Information Theory 37(1):145-151","DOI:10.1109/18.61115","SourceDBLP"],"references":["268676512_Approximation_of_discrete_probability_distributions_based_on_a_new_divergence_measure","268636561_The_Information_in_Contingency_Tables","268498022_A_Comparative_Assessment_of_Various_Measures_of_Entropy","266722003_Dimensionality_and_Classification_Performance_with_Independent_Coordinates","266224006_Diversity_Its_measurement_decomposition_apportionment_and_analysis","265352289_Information-Type_Measures_of_Difference_of_Probability_Distributions_and_Indirect_Observations","247022399_On_some_measures_of_information_and_their_application_to_pattern_recognition","243770698_Information_Theory_with_Application","238973858_A_General_Class_of_Coefficients_of_Divergence_of_One_Distribution_from_Another","232843428_Some_normalized_measures_of_directed_divergence","230842138_On_Measures_of_Information_and_Their_Characterization","226515034_On_thef-divergence_and_singularity_of_probability_measures","224839945_On_Information_and_Sufficiency","224730474_Kailath_T_The_divergence_and_Bhattacharyya_distance_measures_in_signal_selection_IEEE_Trans_on_Comm_Tech_151_52-60","224377906_Entropy_and_Distance_of_Random_Graphs_with_Application_to_Structural_Pattern_Recognition","224377502_A_Decision_Theory_Approach_to_the_Approximation_of_Discrete_Probability_Densities","223657743_On_information_and_distance_measures_error_bounds_and_feature_selection","223106857_f-entropies_probability_of_error_and_feature_selection","222770300_Diversity_and_Dissimilarity_Coefficients_A_Unified_Approach_Theoretical_population_biology_21_24-43","220682511_Cross_entropy_dissimilarity_measures_and_characterizations_of_quadratic_entropy","200524258_Information_Theory_and_Reliable_Communication","47583918_An_Invariant_Form_for_the_Prior_Probability_in_Estimation_Problems","3083298_Axiomatic_Characterization_of_the_Directed_Divergences_and_their_Linear_Combinations","3082481_Sharper_Lower_Bounds_for_Discrimination_Information_in_Terms_of_Variation","3081751_Note_on_discrimination_information_and_variation_Corresp","3081680_Probability_of_Error_Equivocation_and_the_Chernoff_Bound","3081307_Liu_C_Approximating_Discrete_Probability_Distributions_with_Dependence_Trees_IEEE_Transactions_on_Information_Theory_143_462-467","3081192_On_the_Best_Finite_Set_of_Linear_Observables_for_Discriminating_Two_Gaussian_Signals","3081179_A_lower_bound_for_discrimination_information_in_terms_of_variation_Corresp"]}