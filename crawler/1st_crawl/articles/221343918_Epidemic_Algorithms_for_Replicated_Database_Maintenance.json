{"id":"221343918_Epidemic_Algorithms_for_Replicated_Database_Maintenance","abstract":"When a database is replicated at many sites, maintaining mutual consistency among the sites in the face of updates is a significant problem. This paper describes several randomized algorithms for distributing updates and driving the replicas toward consistency. The algorithms are very simple and require few guarantees from the underlying communication system, yet they ensure that the effect of every update is eventually reflected in all replicas. The cost and performance of the algorithms are tuned by choosing appropriate distributions in the randomization step. The algorithms are closely analogous to epidemics, and the epidemiology literature aids in understanding their behavior. One of the algorithms has been implemented in the Clearinghouse servers of the Xerox Corporate Internet. solving long-standing problems of high traffic and database inconsistency.","authors":["Alan Demers","Daniel H. Greene","Carl Hauser","Wes Irish"],"meta":["January 1987ACM SIGOPS Operating Systems Review 22(1):1-12","DOI:10.1145/43921.43922","SourceDBLP"],"references":["221344302_Another_Advantage_of_Free_Choice_Completely_Asynchronous_Agreement_Protocols_Extended_Abstract","2389798_Designing_a_Global_Name_Service","249638706_Efficient_and_reliable_broadcast_is_achievable_in_an_eventually_connected_networkExtended_Abstract","238758016_On_Spreading_a_Rumor","221343981_Probabilistic_Solitude_Verification_on_a_Ring","221343931_Fast_Asynchronous_Byzantine_Agreement_Extended_Abstract","220423935_Grapevine_An_Exercise_in_Distributed_Computing","216824955_Distributed_Snapshots_Determining_Global_States_of_Distributed_Systems","3188678_Discarding_Obsolete_Information_in_a_Replicated_Database_System"]}