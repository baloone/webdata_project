{"id":"318082024_Autonomous_Vehicle_Ethics_Stock_or_custom","abstract":"A current challenge in the development of autonomous vehicles is programming the ethics of their behavior. One way to explore ethical issues of safety and agency when an autonomous vehicle is put in a situation where it must choose between two outcomes has been to use the trolley problem, a moral dilemma documented by Prof. J.J. Thompson of the Massachusetts Institute of Technology [1]. In the trolley problem, a moral dilemma is presented: is it preferable to kill one person to save the lives of five others, or to do nothing, even if one knows that five people would die? The trolley problem suggests two scenarios: 1) a person is driving a trolley without functioning brakes that is about to hit five people working on a track and must decide if he will steer the train down another track and just kill one workman, or 2) a person is a bystander, in similar circumstances, and must decide if he will pull a switch to kill one person working on the track, instead of the five people. As it turns out, Thompson declares that \"most people\" believe it is acceptable to divert a train away from killing five people, to kill only one, but in a variation involving pushing someone onto the track to stop the trolley, most people believe that it \"would not be morally permissible for you to proceed, even if this would save five lives.\"","authors":["Sally Applin"],"meta":["July 2017IEEE Consumer Electronics Magazine 6(3):108-110","DOI:10.1109/MCE.2017.2684917"],"references":["303331393_New_Technologies_and_Mixed-Use_Convergence_How_Humans_and_Algorithms_are_Adapting_to_Each_Other","264540541_Cultural_differences_in_responses_to_real-life_and_hypothetical_trolley_problems","274411823_The_Trolley_Problem","252547504_A_Dissociation_Between_Moral_Judgments_and_Justification"]}