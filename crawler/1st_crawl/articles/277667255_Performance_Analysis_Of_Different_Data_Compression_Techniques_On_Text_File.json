{"id":"277667255_Performance_Analysis_Of_Different_Data_Compression_Techniques_On_Text_File","abstract":"Data Compression is the science and art of\nrepresenting information in a compact form.\nCompression is the process of coding that will\neffectively reduce the total number of bits needed to\nrepresent certain information.Data compression\nhas been one of the critical enabling technologies\nfor the ongoing digital multimedia revolution .data\ncompression also called as source coding or bitrate\nreduction. There are different compression\nalgorithms which are available in different formats.\nData compressions are generally lossless and lossy\ndata compression. In this paper, we study different\nmethods of lossless data compression algorithms\nand calculating the entropy on English text files:\nShanon-Fano coding, Huffman Encoding, RunLength\nEncoding (RLE), Lempel-Ziv-Welch (LZW).\nKeywords: lossless data compression, lossy data\ncompression, Entropy, Shannon-Fano coding,\nHuffman encoding, RLE, LZW.","authors":["Yellamma Pachipala"],"meta":["October 2012"],"references":["265661965_A_Comparative_Study_Of_Text_Compression_Algorithms","44261387_Comparative_Study_between_Various_Algorithms_of_Data_Compression_Techniques","334415366_compression_using_huffman_coding","283369216_Double_compression_of_test_data_using_Huffman_code"]}