{"id":"331218270_Dynamic_Bit-width_Reconfiguration_for_Energy-Efficient_Deep_Learning_Hardware","abstract":"Deep learning models have reached state of the art performance in many machine learning tasks. Benefits in terms of energy, bandwidth, latency, etc., can be obtained by evaluating these models directly within Internet of Things end nodes, rather than in the cloud. This calls for implementations of deep learning tasks that can run in resource limited environments with low energy footprints. Research and industry have recently investigated these aspects, coming up with specialized hardware accelerators for low power deep learning. One effective technique adopted in these devices consists in reducing the bit-width of calculations, exploiting the error resilience of deep learning. However, bit-widths are tipically set statically for a given model, regardless of input data. Unless models are retrained, this solution invariably sacrifices accuracy for energy efficiency.\nIn this paper, we propose a new approach for implementing input-dependant dynamic bit-width reconfiguration in deep learning accelerators. Our method is based on a fully automatic characterization phase, and can be applied to popular models without retraining. Using the energy data from a real deep learning accelerator chip, we show that 50% energy reduction can be achieved with respect to a static bit-width selection, with less than 1% accuracy loss.","authors":["Daniele Jahier Pagliari","Enrico Macii","Massimo Poncino"],"meta":["July 2018","DOI:10.1145/3218603.3218611","Conference: the International Symposium"],"references":["316946924_DVAFS_Trading_computational_accuracy_for_energy_through_dynamic-voltage-accuracy-frequency-scaling","314297052_145_Envision_A_026-to-10TOPSW_subword-parallel_dynamic-voltage-accuracy-frequency-scalable_Convolutional_Neural_Network_processor_in_28nm_FDSOI","309145872_Minerva_Enabling_Low-Power_Highly-Accurate_Deep_Neural_Network_Accelerators","321259854_Low-Power_Convolutional_Neural_Network_Processor_for_a_Face-Recognition_System","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","316948743_Energy-quality_scalable_adaptive_VLSI_circuits_and_systems_beyond_approximate_computing","312448985_DaDianNao_A_machine-learning_supercomputer","309444608_Deep_Learning_with_Differential_Privacy","308704215_Biglittle_deep_neural_network_for_ultra_low_power_inference","307953144_YodaNN_An_Ultra-Low_Power_Convolutional_Neural_Network_Accelerator_Based_on_Binary_Weights"]}