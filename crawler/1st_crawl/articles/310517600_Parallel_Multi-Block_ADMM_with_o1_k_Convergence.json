{"id":"310517600_Parallel_Multi-Block_ADMM_with_o1_k_Convergence","abstract":"This paper introduces a parallel and distributed algorithm for solving the following minimization problem with linear constraints: $$\\begin{aligned} \\text {minimize} ~~&f_1(\\mathbf{x}_1) + \\cdots + f_N(\\mathbf{x}_N)\\\\ \\text {subject to}~~&A_1 \\mathbf{x}_1 ~+ \\cdots + A_N\\mathbf{x}_N =c,\\\\&\\mathbf{x}_1\\in {\\mathcal {X}}_1,~\\ldots , ~\\mathbf{x}_N\\in {\\mathcal {X}}_N, \\end{aligned}$$where \\(N \\ge 2\\), \\(f_i\\) are convex functions, \\(A_i\\) are matrices, and \\({\\mathcal {X}}_i\\) are feasible sets for variable \\(\\mathbf{x}_i\\). Our algorithm extends the alternating direction method of multipliers (ADMM) and decomposes the original problem into N smaller subproblems and solves them in parallel at each iteration. This paper shows that the classic ADMM can be extended to the N-block Jacobi fashion and preserve convergence in the following two cases: (i) matrices \\(A_i\\) are mutually near-orthogonal and have full column-rank, or (ii) proximal terms are added to the N subproblems (but without any assumption on matrices \\(A_i\\)). In the latter case, certain proximal terms can let the subproblem be solved in more flexible and efficient ways. We show that \\(\\Vert {\\mathbf {x}}^{k+1} - {\\mathbf {x}}^k\\Vert _M^2\\) converges at a rate of o(1 / k) where M is a symmetric positive semi-definte matrix. Since the parameters used in the convergence analysis are conservative, we introduce a strategy for automatically tuning the parameters to substantially accelerate our algorithm in practice. We implemented our algorithm (for the case ii above) on Amazon EC2 and tested it on basis pursuit problems with >300 GB of distributed data. This is the first time that successfully solving a compressive sensing problem of such a large scale is reported.","authors":["Wei Deng","Ming-Jun Lai","Zhimin Peng","Wotao Yin"],"meta":["May 2017Journal of Scientific Computing 71(2)","DOI:10.1007/s10915-016-0318-2"],"references":["284160173_On_Full_Jacobian_Decomposition_of_the_Augmented_Lagrangian_Method_for_Separable_Convex_Programming","274645139_A_Three-Operator_Splitting_Scheme_and_its_Optimization_Applications","272792309_The_direct_extension_of_ADMM_for_multi-block_convex_minimization_problems_is_not_necessarily_convergent","267570211_A_Convergent_3-Block_Semi-Proximal_ADMM_for_Convex_Minimization_Problems_with_One_Strongly_Convex_Block","321512672_Numerical_Methods_for_Nonlinear_Variational_Problems","313157156_Fast_alternating_direction_optimization_methods","313048431_Generalized_Lagrange_multiplier_method_for_solving_problems_of_optimum_allocation_of_resources","301853907_Latent_variable_graphical_model_selection_via_convex_optimization","277679394_A_Generalized_Proximal_Point_Algorithm_and_Its_Convergence_Rate","269308300_Parallel_and_distributed_sparse_optimization","267385735_On_non-ergodic_convergence_rate_of_Douglas-Rachford_alternating_direction_method_of_multipliers","265360216_On_the_Global_and_Linear_Convergence_of_the_Generalized_Alternating_Direction_Method_of_Multipliers","265180890_Alternating_Direction_Method_with_Gaussian_Back_Substitution_for_Separable_Convex_Programming","267439360_The_multivariate_spline_mehtod_for_scattered_data_fitting_and_numerical_solution_of_partial_differential_equations","265201153_Fast_Alternating_Direction_Optimization_Methods"]}