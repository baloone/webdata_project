{"id":"259335452_Deep_Convolutional_Ranking_for_Multilabel_Image_Annotation","abstract":"Multilabel image annotation is one of the most important challenges in\ncomputer vision with many real-world applications. While existing work usually\nuse conventional visual features for multilabel annotation, the recent deep\nconvolutional feature shows potentials to significantly boost performance. In\nthis work, we propose to leverage the advantage of such features and analyze\nkey components that lead to better performances. Specifically, we show that a\nsignificant performance gain could be obtained by combining convolutional\narchitectures with an approximate top-$k$ ranking objective function, as such\nobjectives naturally fit the multilabel tagging problem. Our experiments on the\npublicly available NUS-WIDE dataset outperforms the conventional visual\nfeatures by about $10\\%$, obtaining the best reported performance in the\nliterature.","authors":["Yunchao Gong","Yangqing Jia","Thomas Leung","Alexander Toshev"],"meta":["December 2013","SourcearXiv"],"references":["266225209_Large_Scale_Distributed_Deep_Networks","228102719_Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors","225741505_Object_Recognition_as_Machine_Translation_Learning_a_Lexicon_for_a_Fixed_Image_Vocabulary","224577638_Evaluating_color_descriptors_for_object_and_scene_recognition_IEEE_Trans_Pattern_Anal_Mach_Intell","224323302_Evaluating_color_descriptors_for_object_and_scene_recognition","224164326_Aggregating_local_descriptors_into_a_compact_image_representation","224135977_TagProp_Discriminative_Metric_Learning_in_Nearest_Neighbor_Models_for_Image_Auto-Annotation","221368756_NUS-WIDE_A_real-world_web_image_database_from_National_University_of_Singapore","221364427_Locality-constrained_Linear_Coding_for_image_classification","221364080_Linear_spatial_pyramid_matching_using_sparse_coding_for_image_classification","221362912_Multimodal_semi-supervised_learning_for_image_classification","221361988_Learning_Visual_Representations_using_Images_with_Captions","221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database","221344904_Convolutional_deep_belief_networks_for_scalable_unsupervised_learning_of_hierarchical_representations","221303908_A_New_Baseline_for_Image_Annotation","220320803_LIBLINEAR_a_library_for_large_linear_classification","6576878_Supervised_Learning_of_Semantic_Classes_for_Image_Annotation_and_Retrieval","3906151_Learning_the_semantics_of_words_and_pictures","3424605_Bridging_the_Gap_Query_by_Semantic_Example","2371608_Learning_the_Semantics_of_Words_and_Pictures","319770357_DeCAF_A_Deep_Convolutional_Activation_Feature_for_Generic_Visual_Recognition","257409887_DeCAF_A_Deep_Convolutional_Activation_Feature_for_Generic_Visual_Recognition","234131103_Stochastic_Pooling_for_Regularization_of_Deep_Convolutional_NeuralNetworks","233937091_A_Multi-View_Embedding_Space_for_Modeling_Internet_Images_Tags_and_Their_Semantics","224716280_Fisher_Kernels_on_Visual_Vocabularies_for_Image_Categorization","221619829_Semi-Supervised_Learning_in_Gigantic_Image_Collections","221363276_Iterative_quantization_A_procrustean_approach_to_learning_binary_codes","221362554_SUN_database_Large-scale_scene_recognition_from_abbey_to_zoo","220815909_WSABIE_Scaling_up_to_large_vocabulary_image_annotation","220660299_Modeling_the_Shape_of_the_Scene_A_Holistic_Representation_of_the_Spatial_Envelope","200038910_Distinctive_Image_Features_from_Scale-Invariant_Keypoints","37433319_PLSA-based_Image_Auto-Annotation_Constraining_the_Latent_Space","4246227_Beyond_Bags_of_Features_Spatial_Pyramid_Matching_for_Recognizing_Natural_Scene_Categories","2556463_Optimizing_Search_Engines_using_Clickthrough_Data","2439558_Handwritten_Digit_Recognition_with_a_Back-Propagation_Network"]}