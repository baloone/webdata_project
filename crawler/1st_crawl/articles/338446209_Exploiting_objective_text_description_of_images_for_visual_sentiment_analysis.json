{"id":"338446209_Exploiting_objective_text_description_of_images_for_visual_sentiment_analysis","abstract":"This paper addresses the problem of Visual Sentiment Analysis focusing on the estimation of the polarity of the sentiment evoked by an image. Starting from an embedding approach which exploits both visual and textual features, we attempt to boost the contribution of each input view. We propose to extract and employ an Objective Text description of images rather than the classic Subjective Text provided by the users (i.e., title, tags and image description) which is extensively exploited in the state of the art to infer the sentiment associated to social images. Objective Text is obtained from the visual content of the images through recent deep learning architectures which are used to classify object, scene and to perform image captioning. Objective Text features are then combined with visual features in an embedding space obtained with Canonical Correlation Analysis. The sentiment polarity is then inferred by a supervised Support Vector Machine. During the evaluation, we compared an extensive number of text and visual features combinations and baselines obtained by considering the state of the art methods. Experiments performed on a representative dataset of 47235 labelled samples demonstrate that the exploitation of Objective Text helps to outperform state-of-the-art for sentiment polarity estimation.","authors":["Alessandro Ortis","Giovanni Maria Farinella","Giovanni Torrisi","Sebastiano Battiato"],"meta":["June 2021Multimedia Tools and Applications 80(2)","DOI:10.1007/s11042-019-08312-7"],"references":["329061386_Visual_Sentiment_Analysis_Based_on_on_Objective_Text_Description_of_Images","324882480_Ensemble_of_Deep_Models_for_Event_Recognition","309193548_Unsupervised_Sentiment_Analysis_for_Social_Media_Images","330428583_Image-text_sentiment_analysis_via_deep_multimodal_attentive_fusion","329513491_Joint_Visual-Textual_Sentiment_Analysis_Based_on_Cross-Modality_Attention_Mechanism_25th_International_Conference_MMM_2019_Thessaloniki_Greece_January_8-11_2019_Proceedings_Part_I","319770249_Deep_Visual-Semantic_Alignments_for_Generating_Image_Descriptions","318327555_General_Knowledge_Embedded_Image_Representation_Learning","313363716_Analyzing_and_Predicting_Sentiment_of_Images_on_the_Social_Web","312714920_Improving_Image-Sentence_Embeddings_Using_Large_Weakly_Annotated_Photo_Collections","309532479_Random_features_for_large_scale_kernel_machines","305196650_Going_deeper_with_convolutions","303770896_Rating_Prediction_Based_on_Social_Sentiment_From_Textual_Reviews","308813785_Deep_visual-semantic_alignments_for_generating_image_descriptions","305658501_Art_of_Color_The_Subjective_Experience_and_Objective_Rationale_of_Color","303924053_Image_sentiment_analysis_using_latent_correlations_among_visual_textual_and_sentiment_views"]}