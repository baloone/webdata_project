{"id":"311488529_Throughput-Optimized_OpenCL-based_FPGA_Accelerator_for_Large-Scale_Convolutional_Neural_Networks","abstract":"Convolutional Neural Networks (CNNs) have gained popularity in many computer vision applications such as image classification, face detection, and video analysis, because of their ability to train and classify with high accuracy. Due to multiple convolution and fully-connected layers that are compute-/memory-intensive, it is difficult to perform real-time classification with low power consumption on today?s computing systems. FPGAs have been widely explored as hardware accelerators for CNNs because of their reconfigurability and energy efficiency, as well as fast turn-around-time, especially with high-level synthesis methodologies. Previous FPGA-based CNN accelerators, however, typically implemented generic accelerators agnostic to the CNN configuration, where the reconfigurable capabilities of FPGAs are not fully leveraged to maximize the overall system throughput. In this work, we present a systematic design space exploration methodology to maximize the throughput of an OpenCL-based FPGA accelerator for a given CNN model, considering the FPGA resource constraints such as on-chip memory, registers, computational resources and external memory bandwidth. The proposed methodology is demonstrated by optimizing two representative large-scale CNNs, AlexNet and VGG, on two Altera Stratix-V FPGA platforms, DE5-Net and P395-D8 boards, which have different hardware resources. We achieve a peak performance of 136.5 GOPS for convolution operation, and 117.8 GOPS for the entire VGG network that performs ImageNet classification on P395-D8 board.","authors":["Naveen Suda","Vikas Chandra","Ganesh Dasika","Abinash Mohanty"],"meta":["February 2016","DOI:10.1145/2847263.2847276","Conference: the 2016 ACM/SIGDA International Symposium"],"references":["305196650_Going_deeper_with_convolutions","302633614_Dynamically_configurable_multi-ported_co-processor_for_convolutional_neural_networks","300355189_A_Multichannel_Convolutional_Neural_Network_for_Hand_Posture_Recognition","265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge","264979485_Caffe_Convolutional_Architecture_for_Fast_Feature_Embedding","228344387_High_Performance_Convolutional_Neural_Networks_for_Document_Processing","221345753_A_Theoretical_Analysis_of_Feature_Pooling_in_Visual_Recognition","216792698_Hardware_Accelerated_Convolutional_Neural_Networks_for_Synthetic_Vision_Systems","4147414_Automatically_Tuned_Linear_Algebra_Software","2572098_Automatically_Tuned_Linear_Algebra_Software","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","312448985_DaDianNao_A_machine-learning_supercomputer","312446405_Optimizing_fpgabased_accelerator_design_for_deep_convolutional_neural_networks","308864105_A_convolutional_neural_network_cascade_for_face_detection","301367952_Optimizing_FPGA-based_Accelerator_Design_for_Deep_Convolutional_Neural_Networks","300915585_Gzip_on_a_chip","286594438_Large-Scale_Video_Classification_with_Convolutional_Neural_Networks","283024298_DaDianNao_A_Machine-Learning_Supercomputer","271496703_Memory-centric_accelerator_design_for_Convolutional_Neural_Networks","267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks","265385906_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition","265122528_A_240_G-opss_Mobile_Coprocessor_for_Deep_Neural_Networks","264387213_Convolutional_Neural_Networks_for_Speech_Recognition","237000567_Predicting_Parameters_in_Deep_Learning","229101022_The_OpenCL_Specification_version_1029","221620380_Handwritten_Digit_Recognition_with_a_Back-Propagation_Network","221345848_A_unified_architecture_for_natural_language_processing_Deep_neural_networks_with_multitask_learning","220771018_A_dynamically_configurable_coprocessor_for_convolutional_neural_networks"]}