{"id":"274195547_I_see_you_you_see_me_Cooperative_Localization_through_Bearing-Only_Mutually_Observing_Robots","abstract":"Cooperative localization is one of the fundamental techniques in GPS-denied environments, such as underwater, indoor, or on other planets, where teams of robots use each other to improve their pose estimation. In this paper, we present a novel schema for performing cooperative localization using bearing only measurements. These measurements correspond to the angles of pairs of landmarks located on each robot, extracted from camera images. Thus, the only exteroceptive measurements used are the camera images taken by each robot, under the condition that both cameras are mutually visible. An analytical solution is derived, together with an analysis of uncertainty as a function to the relative pose of the robots. A theoretical comparison with a standard stereo camera pose reconstruction is also provided. Finally, the feasibility and performance of the proposed method were validated, through simulations and experiments with a mobile robot setup.","authors":["Philippe Gigu√®re","Ioannis M. Rekleitis","Maxime Latulippe"],"meta":["January 2012","Conference: IROS"],"references":["244978679_A_particle_filter_tutorial_for_mobile_robot_localization","244157627_On_Multiagent_Exploration","226173869_Heterogeneous_Teams_of_Modular_Robots_for_Mapping_and_Exploration","225244509_A_Probabilistic_Approach_to_Collaborative_Multi-Robot_Localization","224623233_A_visually_guided_swimming_robot","224348207_Robot-to-Robot_Relative_Pose_Estimation_From_Range_Measurements","298939943_A_distributed_algorithm_for_cooperative_navigation_among_multiple_mobile_robots","241624227_VOILES_SAILS_A_modular_architecture_for_a_fast_parallel_development_in_an_international_multidisciplinary_project","224669046_Cooperative_positioning_with_multiple_robots","224156046_On_the_Global_Optimum_of_Planar_Range-based_Robot-to-Robot_Relative_Pose_Estimation"]}