{"id":"326977187_Actionable_Recourse_in_Linear_Classification","abstract":"Classification models are often used to make decisions that affect humans: whether to approve a loan application, extend a job offer, or provide insurance. In such applications, individuals should have the ability to change the decision of the model. When a person is denied a loan by a credit scoring model, for example, they should be able to change the input variables of the model in a way that will guarantee approval. Otherwise, this person will be denied the loan so long as the model is deployed, and -- more importantly --will lack agency over a decision that affects their livelihood.\nIn this paper, we propose to evaluate a linear classification model in terms of recourse, which we define as the ability of a person to change the decision of the model through actionable input variables (e.g., income vs. age or marital status). We present an integer programming toolkit to: (i) measure the feasibility and difficulty of recourse in a target population; and (ii) generate a list of actionable changes for a person to obtain a desired outcome. We discuss how our tools can inform different stakeholders by using them to audit recourse for credit scoring models built with real-world datasets. Our results illustrate how recourse can be significantly affected by common modeling practices, and motivate the need to evaluate recourse in algorithmic decision-making.","authors":["Alexander Spangher","Berk Ustun"],"meta":["July 2018","DOI:10.1145/3287560.3287566","Conference: 5th Workshop on Fairness, Accountability and Transparency in Machine Learning (FAT/ML)At: Stockholm, Sweden"],"references":["328257891_A_Right_to_Reasonable_Inferences_Re-Thinking_Data_Protection_Law_in_the_Age_of_Big_Data_and_AI","322851636_'It's_Reducing_a_Human_Being_to_a_Percentage'_Perceptions_of_Justice_in_Algorithmic_Decisions","320796885_Counterfactual_Explanations_Without_Opening_the_Black_Box_Automated_Decisions_and_the_GDPR","337745014_Actionable_Recourse_in_Linear_Classification","326117083_Slave_to_the_Algorithm_Why_a_'right_to_an_explanation'_is_probably_not_the_remedy_you_are_looking_for","325864367_Strategic_Classification_from_Revealed_Preferences","323766095_The_Intuitive_Appeal_of_Explainable_Machines","320867322_Accountability_of_AI_Under_the_Law_The_Role_of_Explanation","319240168_Predictive_Analytics_for_City_Agencies_Lessons_from_Children's_Services","318003528_Slave_to_the_Algorithm_Why_a_Right_to_Explanationn_is_Probably_Not_the_Remedy_You_are_Looking_for"]}