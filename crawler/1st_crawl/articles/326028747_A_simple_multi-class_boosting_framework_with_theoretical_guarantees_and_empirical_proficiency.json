{"id":"326028747_A_simple_multi-class_boosting_framework_with_theoretical_guarantees_and_empirical_proficiency","abstract":"There is a need for simple yet accurate white-box learning systems that train quickly and with lit- tle data. To this end, we showcase REBEL, a multi-class boosting method, and present a novel family of weak learners called localized similar- ities. Our framework provably minimizes the training error of any dataset at an exponential rate. We carry out experiments on a variety of synthetic and real datasets, demonstrating a con- sistent tendency to avoid overfitting. We eval- uate our method on MNIST and standard UCI datasets against other state-of-the-art methods, showing the empirical proficiency of our method.","authors":["Ron Appel","Pietro Perona"],"meta":["August 2017","Conference: 34th International Conference on Machine Learning (ICML)Volume: 70"],"references":["305287874_Improved_Multi-Class_Cost-Sensitive_Boosting_via_Estimation_of_the_Minimum-Risk_Class","277411157_Deep_Learning","260344367_Multiclass_Boosting_Theory_and_Algorithms","235601707_StructBoost_Boosting_Methods_for_Predicting_Structured_Output_Variables","228947999_Multi-class_AdaBoost","221364758_A_direct_formulation_for_totally-corrective_multi-class_boosting","307881957_LIBSVM_A_library_for_support_vector_machines","221345952_Unifying_the_error-correcting_and_output-code_AdaBoost_within_the_margin_framework","221345684_Multiclass_boosting_with_repartitioning","51946285_AOSO-LogitBoost_Adaptive_one-vs-one_LogitBoost_for_multi-class_problem","51930980_A_Theory_of_Multiclass_Boosting","3501836_The_Strength_of_Weak_Learnability","2806398_Boosting_a_Weak_Learning_Algorithm_By_Majority","2454335_Reducing_Multiclass_to_Binary_A_Unifying_Approach_for_Margin_Classifiers","2379022_Solving_Multiclass_Learning_Problems_via_Error-Correcting_Output_Codes"]}