{"id":"312945008_On_Extractable_Shared_Information","abstract":"We consider the problem of quantifying the information shared by a pair of random variables $X_{1},X_{2}$ about another variable $S$. We propose a new measure of shared information, called extractable shared information that is left monotonic; that is, the information shared about $S$ is bounded from below by the information shared about $f(S)$ for any function $f$. We show that our measure leads to a new nonnegative decomposition of the mutual information $I(S;X_1X_2)$ into shared, complementary and unique components. We study properties of this decomposition and show that a left monotonic shared information is not compatible with a Blackwell interpretation of unique information. We also discuss whether it is possible to have a decomposition in which both shared and unique information are left monotonic.","authors":["Johannes Rauh","Pradeep Kr. Banerjee","Eckehard Olbrich","JÃ¼rgen Jost"],"meta":["January 2017Entropy 19(7)","DOI:10.3390/e19070328"],"references":["312945420_Coarse-Graining_and_the_Blackwell_Order","282691683_Partial_Information_Decomposition_as_a_Unified_Approach_to_the_Specification_of_Neural_Goal_Functions","261597804_Reconsidering_unique_information_Towards_a_multivariate_information_decomposition","258424278_Quantifying_Unique_Information","257409894_Intersection_Information_Based_on_Common_Randomness","235627586_Bivariate_measure_of_redundant_information","232503650_Shared_Information_--_New_Insights_and_Problems_in_DecomposingInformation_in_Complex_Systems","225027185_Quantifying_Synergistic_Mutual_Information","317816056_Quantifying_Synergistic_Mutual_Information","228849052_The_co-information_lattice"]}