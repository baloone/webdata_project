{"id":"308141950_Comenzando_con_Weka_Filtrado_y_seleccion_de_subconjuntos_de_atributos_basada_en_su_relevancia_descriptiva_para_la_clase","abstract":"Este trabajo discute la importancia de la fase de preprocesado y selección de atributos y su nivel de relevancia en relación a la variable de clase (relevancia fuerte y débil) en la aplicación de técnicas de minería de datos y cómo, basándonos en dichos conceptos, se puede obtener un conjunto mínimo de características que nos ayude a minimizar el deterioro de rendimiento que se observa en los algoritmos clásicos de aprendizaje automático, por ejemplo en clasificación o estratificación de muestras, cuando aumentamos el número de atributos a considerar o añadimos atributos poco correlacionados con el valor de la clase o cuya relevancia es escasa en el proceso de clasificación. Para ello definiremos un experimento que consistirá en la generación de un conjunto artificial de datos al que imponemos ciertas condiciones de relevancia y sobre el que utilizaremos las diferentes técnicas de filtrado y selección de atributos disponibles en el paquete GPL Weka con especial énfasis en las técnicas de envoltura (WrapperSubsetEval) propuestas por Kohavi et al. [Kohavi97].","authors":["Jose Alberto García Gutiérrez"],"meta":["January 2016"],"references":["223713209_Wrappers_for_Feature_Subset_Selection","221996079_An_Introduction_of_Variable_and_Feature_Selection","220571706_Evolutionary_model_selection_in_unsupervised_learning","3619899_Chi2_Feature_Selection_and_Discretization_of_Numeric_Attributes","3481589_Information-Theoretic_Feature_Selection_in_Microarray_Data_Using_Variable_Complementarity","312341539_Skewing_An_efficient_alternative_to_lookahead_for_decision_tree_induction","234801304_Inductive_knowledge_acquisition_A_case_study","222303175_Selection_of_Relevant_Features_and_Examples_in_Machine_Learning","221936069_Introduction_to_Machine_Learning","220688794_C45_Programs_for_Machine_Learning"]}