{"id":"325447341_Neural_Models_for_Reasoning_over_Multiple_Mentions_Using_Coreference","authors":["Bhuwan Dhingra","Qiao Jin","Zhilin Yang","William Cohen"],"meta":["January 2018","DOI:10.18653/v1/N18-2007","Conference: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)"],"references":["322587926_Syntax_Aware_LSTM_model_for_Semantic_Role_Labeling","318671264_End-to-end_Neural_Coreference_Resolution","313760677_Frustratingly_Short_Attention_Spans_in_Neural_Language_Modeling","309461050_Broad_Context_Language_Modeling_as_Reading_Comprehension","305342143_Dynamic_Entity_Representation_with_Max-pooling_Improves_Machine_Reading","284576917_Glove_Global_Vectors_for_Word_Representation","273067823_Improved_Semantic_Representations_From_Tree-Structured_Long_Short-Term_Memory_Networks","319769995_End-To-End_Memory_Networks","319121568_Cross-Sentence_N-ary_Relation_Extraction_with_Graph_LSTMs","318868553_Dynamic_Entity_Representations_in_Neural_Language_Models","318742617_Gated-Attention_Readers_for_Text_Comprehension","318741823_Should_Neural_Network_Architecture_Reflect_Linguistic_Structure","318527968_Improved_Neural_Machine_Translation_with_a_Syntax-Aware_Encoder_and_Decoder","315099006_FastQA_A_Simple_and_Efficient_Neural_Architecture_for_Question_Answering","309738677_Bidirectional_Attention_Flow_for_Machine_Comprehension","309738318_Reference-Aware_Language_Models","305341896_Learning_Global_Features_for_Coreference_Resolution","287466320_Easy_victories_and_uphill_battles_in_coreference_resolution","278048272_Teaching_Machines_to_Read_and_Comprehend"]}