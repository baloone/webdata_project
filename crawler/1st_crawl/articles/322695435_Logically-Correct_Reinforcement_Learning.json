{"id":"322695435_Logically-Correct_Reinforcement_Learning","abstract":"We propose a novel Reinforcement Learning (RL) algorithm to synthesize policies for a Markov Decision Process (MDP), such that a linear time property is satisfied. We convert the property into a Limit Deterministic Buchi Automaton (LDBA), then construct a product MDP between the automaton and the original MDP. A reward function is then assigned to the states of the product automaton, according to accepting conditions of the LDBA. With this reward function, RL synthesizes a policy that satisfies the property: as such, the policy synthesis procedure is \"constrained\" by the given specification. Additionally, we show that the RL procedure sets up an online value iteration method to calculate the maximum probability of satisfying the given property, at any given state of the MDP - a convergence proof for the procedure is provided. Finally, the performance of the algorithm is evaluated via a set of numerical examples. We observe an improvement of one order of magnitude in the number of iterations required for the synthesis compared to existing approaches.","authors":["Mohammadhosein Hasanbeig","Alessandro Abate","Daniel Kroening"],"meta":["January 2018"],"references":["316736769_Value_Iteration_for_Long-run_Average_Reward_in_Markov_Decision_Processes","311585993_Reinforcement_Learning_With_Temporal_Logic_Rewards","292074166_Mastering_the_game_of_Go_with_deep_neural_networks_and_tree_search","261952679_Probably_Approximately_Correct_MDP_Learning_and_Control_With_Temporal_Logic_Constraints","235892045_Optimal_Control_of_MDPs_with_Temporal_Logic_Constraints","235004620_Reinforcement_Learning_and_Markov_Decision_Processes","224043586_Essentials_of_Stochastic_Processes","221402880_PRISM_40_Verification_of_Probabilistic_Real-time_Systems","220690719_Principles_of_Model_Checking","2364489_Deterministic_Generators_and_Games_for_LTL_Fragments","320494640_On_Synchronous_Binary_Log-Linear_Learning_and_Second_Order_Q-learning_This_work_was_supported_by_an_NSERC_grant","313135362_Q-learning","313067223_MoChiBA_Probabilistic_LTL_Model_Checking_Using_Limit-Deterministic_Buchi_Automata","305252941_Limit-Deterministic_Buchi_Automata_for_Linear_Temporal_Logic","282187475_Game_theory_control_solution_for_sensor_coverage_problem_in_unknown_environment","272837232_Human-level_control_through_deep_reinforcement_learning","265908742_A_Learning_Based_Approach_to_Control_Synthesis_of_Markov_Decision_Processes_for_Linear_Temporal_Logic_Specifications","264122703_Quantitative_model-checking_of_controlled_discrete-time_Markov_processes","254057503_Temporal_Logic_Motion_Planning_and_Control_With_Probabilistic_Satisfaction_Guarantees","232654228_On_the_complexity_of_omega_-automata","230887855_Markov_Decision_Processes_Discrete_Stochastic_Dynamic_Programming","221619095_An_Application_of_Reinforcement_Learning_to_Aerobatic_Helicopter_Flight","220486693_From_Nondeterministic_Buchi_and_Streett_Automata_to_Deterministic_Parity_Automata","5596000_Reinforcement_Learning_An_Introduction","2492153_Neuro-Dynamic_Programming_An_Overview","2413902_Between_MDPs_and_Semi-MDPs_A_Framework_for_Temporal_Abstraction_in_Reinforcement_Learning"]}