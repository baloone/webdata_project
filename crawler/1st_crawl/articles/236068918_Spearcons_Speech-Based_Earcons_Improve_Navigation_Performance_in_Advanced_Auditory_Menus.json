{"id":"236068918_Spearcons_Speech-Based_Earcons_Improve_Navigation_Performance_in_Advanced_Auditory_Menus","abstract":"The goal of this project is to evaluate a new auditory cue, which the authors call spearcons, in comparison to other auditory cues with the aim of improving auditory menu navigation.\nWith the shrinking displays of mobile devices and increasing technology use by visually impaired users, it becomes important to improve usability of non-graphical user interface (GUI) interfaces such as auditory menus. Using nonspeech sounds called auditory icons (i.e., representative real sounds of objects or events) or earcons (i.e., brief musical melody patterns) has been proposed to enhance menu navigation. To compensate for the weaknesses of traditional nonspeech auditory cues, the authors developed spearcons by speeding up a spoken phrase, even to the point where it is no longer recognized as speech.\nThe authors conducted five empirical experiments. In Experiments 1 and 2, they measured menu navigation efficiency and accuracy among cues. In Experiments 3 and 4, they evaluated learning rate of cues and speech itself. In Experiment 5, they assessed spearcon enhancements compared to plain TTS (text to speech: speak out written menu items) in a two-dimensional auditory menu.\nSpearcons outperformed traditional and newer hybrid auditory cues in navigation efficiency, accuracy, and learning rate. Moreover, spearcons showed comparable learnability as normal speech and led to better performance than speech-only auditory cues in two-dimensional menu navigation.\nThese results show that spearcons can be more effective than previous auditory cues in menu-based interfaces.\nSpearcons have broadened the taxonomy of nonspeech auditory cues. Users can benefit from the application of spearcons in real devices.","authors":["Bruce N Walker","Jeffrey Lindsay","Amanda Nance","Yoko Nakano"],"meta":["February 2013Human Factors The Journal of the Human Factors and Ergonomics Society 55(1):157-82","DOI:10.1177/0018720812450587","SourcePubMed"],"references":["263678241_Correcting_menu_usability_problems_with_sound","228737209_Combining_speech_and_earcons_to_assist_menu_navigation","315385087_Auditory_User_Interfaces","250890252_Soundtrack_An_Auditory_Interface_for_Blind_Users","243774288_The_Psychology_of_Menu_Selection_Designing_Cognitive_Control_of_the_HumanComputer_Interface","242316584_Earcons_and_Icons_Their_Structure_and_Common_Design_Principles","228846770_Comprehension_of_ultra-fast_speech-blind_vs_normally_hearing_persons","224737199_High_quality_time-scale_modification_for_speech","221652455_Improving_the_Usability_of_Speech-Based_Interfaces_for_Blind_Users","221652315_Screen_reader2_access_to_OS2_and_the_graphical_user_interface","221652009_Auditory_Navigation_in_Hyperspace_Design_and_Evaluation_of_a_Non-Visual_Hypermedia_System_for_Blind_Users","221622372_Enhanced_Auditory_Menu_Cues_Improve_Dual_Task_Performance_and_are_Preferred_with_In-vehicle_Technologies","221652245_User_Interface_of_a_Home_Page_Reader","221652233_An_experimental_sound-based_hierarchical_menu_navigation_system_for_visually_handicapped_use_of_graphical_user_interfaces","221652087_Advanced_Auditory_Menus_Design_And_Evaluation_of_Auditory_Scroll_Bars"]}