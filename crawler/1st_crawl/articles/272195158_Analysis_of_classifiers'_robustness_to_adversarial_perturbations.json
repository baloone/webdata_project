{"id":"272195158_Analysis_of_classifiers'_robustness_to_adversarial_perturbations","abstract":"The robustness of a classifier to arbitrary small perturbations of the\ndatapoints is a highly desirable property when the classifier is deployed in\nreal and possibly hostile environments. In this paper, we propose a theoretical\nframework for analyzing the robustness of classifiers to adversarial\nperturbations, and study two common families of classifiers. In both cases, we\nshow the existence of a fundamental limit on the robustness to adversarial\nperturbations, which is expressed in terms of a distinguishability measure\nbetween the classes. Our result implies that in tasks involving small\ndistinguishability, no classifier will be robust to adversarial perturbations,\neven if a good accuracy is achieved. Furthermore, we show that robustness to\nrandom noise does not imply, in general, robustness to adversarial\nperturbations. In fact, in high dimensional problems, linear classifiers are\nshown to be much more robust to random noise than to adversarial perturbations.\nOur analysis is complemented by experimental results on controlled and\nreal-world data. Up to our knowledge, this is the first theoretical work that\naddresses the surprising phenomenon of adversarial instability recently\nobserved for deep networks (Szegedy et al., 2014). Our work shows that this\nphenomenon is not limited to deep networks, and gives a theoretical explanation\nof the causes underlying the adversarial instability of classifiers.","authors":["Alhussein Fawzi","Omar Fawzi","Pascal Frossard"],"meta":["March 2018Machine Learning 107(2)","DOI:10.1007/s10994-017-5663-3","SourcearXiv"],"references":["305186613_Adversarial_examples_in_the_physical_world","281809961_New_fractional_error_bounds_for_polynomial_systems_with_applications_to_Hlderian_stability_in_optimization_and_spectral_theory_of_tensors","319770378_Explaining_and_harnessing_adversarial_examples","319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition","313527089_Distinctive_image_features_from_scale-invariant_key_points","311610675_DeepFool_A_Simple_and_Accurate_Method_to_Fool_Deep_Neural_Networks","311609772_Towards_Open_Set_Deep_Networks","307881957_LIBSVM_A_library_for_support_vector_machines","306218037_Learning_multiple_layers_of_features_from_tiny_images","286370353_Practical_Evasion_of_a_Learning-Based_Classifier_A_Case_Study"]}