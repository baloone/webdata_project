{"id":"320754952_TreeQN_and_ATreeC_Differentiable_Tree_Planning_for_Deep_Reinforcement_Learning","abstract":"Combining deep model-free reinforcement learning with on-line planning is a promising approach to building on the successes of deep RL. On-line planning with look-ahead trees has proven successful in environments where transition models are known a priori. However, in complex environments where transition models need to be learned from data, the deficiencies of learned models have limited their utility for planning. To address these challenges, we propose TreeQN, a differentiable, recursive, tree-structured model that serves as a drop-in replacement for any value function network in deep RL with discrete actions. TreeQN dynamically constructs a tree by recursively applying a transition model in a learned abstract state space and then aggregating predicted rewards and state-values using a tree backup to estimate Q-values. We also propose ATreeC, an actor-critic variant that augments TreeQN with a softmax layer to form a stochastic policy network. Both approaches are trained end-to-end, such that the learned model is optimised for its actual use in the planner. We show that TreeQN and ATreeC outperform n-step DQN and A2C on a box-pushing task, as well as n-step DQN and value prediction networks (Oh et al., 2017) on multiple Atari games, with deeper trees often outperforming shallower ones. We also present a qualitative analysis that sheds light on the trees learned by TreeQN.","authors":["Gregory Farquhar","Tim Rockt√§schel","Maximilian Igl","Shimon Whiteson"],"meta":["October 2017"],"references":["320473480_Mastering_the_game_of_Go_without_human_knowledge","318560334_Imagination-Augmented_Agents_for_Deep_Reinforcement_Learning","314943191_Task-based_End-to-end_Model_Learning","292074166_Mastering_the_game_of_Go_with_deep_neural_networks_and_tree_search","319284083_Curiosity-Driven_Exploration_by_Self-Supervised_Prediction","318829926_Value_Iteration_Networks","318392190_Value_Prediction_Network","313135362_Q-learning","311737122_Self-Correcting_Models_for_Model-Based_Reinforcement_Learning","311609041_Deep_Residual_Learning_for_Image_Recognition"]}