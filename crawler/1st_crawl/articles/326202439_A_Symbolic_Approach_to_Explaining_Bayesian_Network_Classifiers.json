{"id":"326202439_A_Symbolic_Approach_to_Explaining_Bayesian_Network_Classifiers","abstract":"We propose an approach for explaining Bayesian network classifiers, which is based on compiling such classifiers into decision functions that have a tractable and symbolic form. We introduce two types of explanations for why a classifier may have classified an instance positively or negatively and suggest algorithms for computing these explanations. The first type of explanation identifies a minimal set of the currently active features that is responsible for the current classification, while the second type of explanation identifies a minimal set of features whose current state (active or not) is sufficient for the classification. We consider in particular the compilation of Naive and Latent-Tree Bayesian network classifiers into Ordered Decision Diagrams (ODDs), providing a context for evaluating our proposal using case studies and experiments based on classifiers from the literature.","authors":["Andy Shih","Arthur Choi","Adnan Darwiche"],"meta":["July 2018","DOI:10.24963/ijcai.2018/708","Conference: Twenty-Seventh International Joint Conference on Artificial Intelligence {IJCAI-18}"],"references":["221404225_Monotonicity_in_Bayesian_Networks","280765005_Graph-based_algorithms_for_Boolean_function_manipulation","272825857_UCI_Machine_Learning_Repository"]}