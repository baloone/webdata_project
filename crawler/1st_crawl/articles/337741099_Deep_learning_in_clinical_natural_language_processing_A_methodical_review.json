{"id":"337741099_Deep_learning_in_clinical_natural_language_processing_A_methodical_review","abstract":"Objective: \nThis article methodically reviews the literature on deep learning (DL) for natural language processing (NLP) in the clinical domain, providing quantitative analysis to answer 3 research questions concerning methods, scope, and context of current research.\n\nMaterials and methods: \nWe searched MEDLINE, EMBASE, Scopus, the Association for Computing Machinery Digital Library, and the Association for Computational Linguistics Anthology for articles using DL-based approaches to NLP problems in electronic health records. After screening 1,737 articles, we collected data on 25 variables across 212 papers.\n\nResults: \nDL in clinical NLP publications more than doubled each year, through 2018. Recurrent neural networks (60.8%) and word2vec embeddings (74.1%) were the most popular methods; the information extraction tasks of text classification, named entity recognition, and relation extraction were dominant (89.2%). However, there was a \"long tail\" of other methods and specific tasks. Most contributions were methodological variants or applications, but 20.8% were new methods of some kind. The earliest adopters were in the NLP community, but the medical informatics community was the most prolific.\n\nDiscussion: \nOur analysis shows growing acceptance of deep learning as a baseline for NLP research, and of DL-based NLP in the medical community. A number of common associations were substantiated (eg, the preference of recurrent neural networks for sequence-labeling named entity recognition), while others were surprisingly nuanced (eg, the scarcity of French language clinical NLP with deep learning).\n\nConclusion: \nDeep learning has not yet fully penetrated clinical NLP and is growing rapidly. This review highlighted both the popular and unique trends in this active field.","authors":["Stephen T Wu","Kirk Roberts","Surabhi Datta","Jingcheng Du"],"meta":["December 2019Journal of the American Medical Informatics Association 27(3)","DOI:10.1093/jamia/ocz200"],"references":["335750430_BioBERT_a_pre-trained_biomedical_language_representation_model_for_biomedical_text_mining","334205052_Enhancing_clinical_concept_extraction_with_contextual_embeddings","335778882_Energy_and_Policy_Considerations_for_Deep_Learning_in_NLP","334601558_Publicly_Available_Clinical","334140648_An_investigation_of_single-domain_and_multidomain_medication_and_adverse_drug_event_relation_extraction_from_electronic_health_record_notes_using_advanced_deep_learning_models","334117793_A_Neural_Architecture_for_Automated_ICD_Coding","334116448_A_robust_self-learning_method_for_fully_unsupervised_cross-lingual_mappings_of_word_embeddings","334115939_Self-training_improves_Recurrent_Neural_Networks_performance_for_Temporal_Relation_Extraction","334115868_emrQA_A_Large_Corpus_for_Question_Answering_on_Electronic_Medical_Records","333135915_Detection_of_Bleeding_Events_in_Electronic_Health_Record_Notes_Using_Convolutional_Neural_Network_Models_Enhanced_With_Recurrent_Neural_Network_Autoencoders_Deep_Learning_Approach","332971629_Natural_Language_Processing_of_Clinical_Notes_on_Chronic_Diseases_Systematic_Review","332298378_Attention-based_deep_residual_learning_network_for_entity_relation_extraction_in_Chinese_EMRs","332298371_An_approach_for_medical_event_detection_in_Chinese_clinical_notes_of_electronic_health_records","332298296_A_hybrid_approach_for_named_entity_recognition_in_Chinese_electronic_medical_record","332298172_A_deep_learning_model_incorporating_part_of_speech_and_self-matching_attention_for_named_entity_recognition_of_Chinese_electronic_medical_records"]}