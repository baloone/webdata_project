{"id":"267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks","abstract":"We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 dif-ferent classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make train-ing faster, we used non-saturating neurons and a very efficient GPU implemen-tation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.","authors":["Alex Krizhevsky","Ilya Sutskever","Geoffrey E. Hinton"],"meta":["January 2012Advances in Neural Information Processing Systems 25(2)","DOI:10.1145/3065386"],"references":["258627767_Metric_Learning_for_Large_Scale_Image_Classification_Generalizing_to_New_Classes_at_Near-Zero_Cost","244947191_1974_Beyond_regression_New_tools_for_predicting_and_analysis_in_the_behavioral_sciences","228102719_Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors","221376179_Convolutional_Networks_and_Applications_in_Vision","221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database","221344904_Convolutional_deep_belief_networks_for_scalable_unsupervised_learning_of_hierarchical_representations","220860992_Best_Practices_for_Convolutional_Neural_Networks_Applied_to_Visual_Document_Analysis","220016377_High-dimensional_signature_compression_for_large-scale_image_classification","48199502_High-Performance_Neural_Networks_for_Visual_Object_Classification","40443832_A_High-Throughput_Screening_Approach_to_Discovering_Good_Forms_of_Biologically_Inspired_Visual_Representation","38098046_Convolutional_Networks_Can_Learn_to_Generate_Affinity_Graphs_for_Image_Segmentation","35657389_Beyond_regression_new_tools_for_prediction_and_analysis_in_the_behavioral_sciences","30766223_Caltech-256_Object_Category_Dataset","5625818_Why_is_Real-World_Visual_Object_Recognition_Hard","4082304_Learning_methods_for_generic_object_recognition_with_invariance_to_pose_and_lighting","319770232_Multi-column_Deep_Neural_Networks_for_Image_Classification","313060232_Learning_Internal_Representations_by_Error_Propagation","306218037_Learning_multiple_layers_of_features_from_tiny_images","288906520_Random_forests","265147627_Convolutional_Deep_Belief_Networks_on_CIFAR-10","258304769_Machine_Learning_Volume_45_Number_1_-_SpringerLink","226452698_Taylor_expansion_of_the_accumulated_rounding_error","222817667_Learning_Generative_Visual_Models_from_Few_Training_Examples_An_Incremental_Bayesian_Approach_Tested_on_101_Object_Categories","221663833_Multi-column_Deep_Neural_Networks_for_Image_Classification","221345737_Rectified_Linear_Units_Improve_Restricted_Boltzmann_Machines_Vinod_Nair","221165645_Using_Very_Deep_Autoencoders_for_Content-Based_Image_Retrieval","220520181_Lessons_from_the_Netflix_prize_challenge","216792902_Une_procedure_d'apprentissage_pour_reseau_a_seuil_asymmetrique_a_Learning_Scheme_for_Asymmetric_Threshold_Networks","216792705_What_is_the_Best_Multi-Stage_Architecture_for_Object_Recognition","37992037_LabelMe_A_Database_and_Web-Based_Tool_for_Image_Annotation","15829465_Neocognitron_A_self-organizing_neural_network_model_for_a_mechanism_of_pattern_recognition_unaffected_by_shift_in_position","2439558_Handwritten_Digit_Recognition_with_a_Back-Propagation_Network"]}