{"id":"256822280_Tree_ensembles_for_predicting_structured_outputs","abstract":"In this paper, we address the task of learning models for predicting structured outputs. We consider both global and local predictions of structured outputs, the former based on a single model that predicts the entire output structure and the latter based on a collection of models, each predicting a component of the output structure. We use ensemble methods and apply them in the context of predicting structured outputs. We propose to build ensemble models consisting of predictive clustering trees, which generalize classification trees: these have been used for predicting different types of structured outputs, both locally and globally. More specifically, we develop methods for learning two types of ensembles (bagging and random forests) of predictive clustering trees for global and local predictions of different types of structured outputs. The types of outputs considered correspond to different predictive modeling tasks: multi-target regression, multi-target classification, and hierarchical multi-label classification. Each of the combinations can be applied both in the context of global prediction (producing a single ensemble) or local prediction (producing a collection of ensembles). We conduct an extensive experimental evaluation across a range of benchmark datasets for each of the three types of structured outputs. We compare ensembles for global and local prediction, as well as single trees for global prediction and tree collections for local prediction, both in terms of predictive performance and in terms of efficiency (running times and model complexity). The results show that both global and local tree ensembles perform better than the single model counterparts in terms of predictive power. Global and local tree ensembles perform equally well, with global ensembles being more efficient and producing smaller models, as well as needing fewer trees in the ensemble to achieve the maximal performance.","authors":["Dragi Kocev","Celine Vens","Jan Struyf","Sašo Džeroski"],"meta":["March 2013Pattern Recognition 46(3):817–833","DOI:10.1016/j.patcog.2012.09.023"],"references":["288623967_Multilabel_classification_of_music_into_emotions","273859036_Multi-Label_Classification_An_Overview","243048627_Approximations_of_the_critical_region_of_the_Friedman_statistic","236952762_Random_Forests","234163993_Approximations_of_the_critical_region_of_the_Friedman_statistic","228987300_Weighted_True_Path_Rule_a_multilabel_hierarchical_algorithm_for_gene_function_prediction","227220810_Predicting_Chemical_Parameters_of_River_Water_Quality_from_Bioindicator_Data","226584462_Constraint_Based_Induction_of_Multi-objective_Regression_Trees","226246349_Decision_trees_for_hierarchical_multi-label_classification","225966462_Towards_a_General_Framework_for_Data_Mining","225716424_A_survey_of_hierarchical_classification_across_different_application_domains","225463870_Ensembles_of_Multi-Objective_Decision_Trees","222685724_Application_of_machine_learning_techniques_to_the_analysis_of_soil_ecological_data_bases_Relationships_between_habitat_features_and_Collembolan_community_characteristics","222674734_A_systematic_analysis_of_performance_measures_for_classification_tasks","221996780_Kernel-Based_Learning_of_Hierarchical_Multilabel_Classication_Models","221619254_Kernels_for_Multi--task_Learning","221345769_Multi-task_reinforcement_learning_a_hierarchical_Bayesian_approach","220723464_Multi-label_classification_of_music_into_emotions","220699086_Expectation_Propagation_for_Bayesian_Multi-task_Feature_Selection","220698914_Decision_Trees_for_Hierarchical_Multilabel_Classification_A_Case_Study_in_Functional_Genomics","310606656_Classification_and_regression_trees","285705454_Econometric_Analysis","275340906_Random_Forests","272825857_UCI_Machine_Learning_Repository","262283791_Rapid_and_brief_communication_Controlling_the_diversity_in_classifier_ensembles_through_a_measure_of_agreement","258304769_Machine_Learning_Volume_45_Number_1_-_SpringerLink","252285513_Using_single-_and_multi-target_regression_trees_and_ensembles_to_model_a_compound_index_of_vegetation_condition","244498683_Experiment_With_a_New_Boosting_Algorithm","242793084_Learning_multi-label_scene_classification1","242415961_Machine_learning_and_data_mining_for_yeast_functional_genomics","240310918_Classification_and_Regression_Trees_CART","234849967_Using_multi-objective_classification_to_model_communities_of_soil_microarthropods","233556534_First_Order_Regression","227631760_Predicting_Multivariate_Responses_in_Multiple_Linear_Regression","227290506_Simultaneous_Prediction_of_Multiple_Chemical_Parameters_of_River_Water_Quality_with_TILDE","226270700_Bagging_Predictors","225125791_On_Structured_Output_Training_Hard_Cases_and_an_Efficient_Alternative","223460637_Combining_Pattern_Classifiers_Methods_and_Algorithms_Second_Edition","222835940_Hierarchical_annotation_of_medical_images","222430151_Learning_multi-label_scene_classification","222283704_Mining_data_with_random_forests_A_survey_and_results_of_new_tests","221619768_A_Kernel_Method_for_Multi-Labelled_Classification","221534367_SVM_regression_and_multi-task_learning","221112118_The_Enron_Corpus_A_New_Dataset_for_Email_Classification_Research","220938670_Analysis_of_Time_Series_Data_with_Predictive_Clustering_Trees","220698966_Simultaneous_Prediction_of_Mulriple_Chemical_Parameters_of_River_Water_Quality_with_TILDE","220696321_Ensemble_Methods_in_Data_Mining_Improving_Accuracy_Through_Combining_Predictions","220688808_Elements_of_Machine_Learning","220688794_C45_Programs_for_Machine_Learning","220644826_Multi-task_learning_to_rank_for_web_search","220613736_Multi-label_classification_An_overview","220604321_Multi-output_regression_on_the_output_manifold","220600412_A_semi-dependent_decomposition_approach_to_learn_hierarchical_classifiers","220451973_Future_trends_in_data_mining","220344043_Convex_Multi-Task_Feature_Learning"]}