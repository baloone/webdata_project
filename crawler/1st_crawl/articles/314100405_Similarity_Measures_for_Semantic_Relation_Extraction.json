{"id":"314100405_Similarity_Measures_for_Semantic_Relation_Extraction","abstract":"Semantic relations, such as synonyms, hypernyms and co-hyponyms proved to be useful for\ntext processing applications, including text similarity, query expansion, question answering\nand word sense disambiguation. Such relations are practical because of the gap between\nlexical surface of the text and its meaning. Indeed, the same concept is often represented\nby different terms. However, existing resources often do not cover a vocabulary required by\na given system. Manual resource construction is prohibitively expensive for many projects.\nOn the other hand, precision of the existing extractors still do not meet quality of the handcrafted\nresources. All these factors motivate the development of novel extraction methods.\nThis thesis deals with similarity measures for semantic relation extraction. The main research\nquestion we address, is how to improve precision and coverage of such measures.\nFirst, we perform a large-scale study the baseline techniques. Second, we propose four\nnovel measures. One of them significantly outperforms the baselines, the others perform\ncomparably to the state-of-the-art techniques. Finally, we successfully apply one of the\nnovel measures in two text processing systems.\n\nChapter 1 begins with a description of the object of the research – semantic relations and\nresources. First, we define these objects formally and provide examples of resources commonly\nused in text processing systems, such as taxonomies, thesauri, lexical databases and\nontologies. Second, we introduce the subject of the research – semantic relation extractors\nbased on similarity measures. Finally, the chapter presents benchmarks designed to assess\nperformance of this kind of extraction systems.\nChapter 2 deals with semantic similarity measures which rely on one resource (a corpus,\na dictionary, etc.) and one extraction method (distributional analysis, lexico-syntactic patterns,\netc.). The chapter begins with an overview of related work. Then, we describe three \nexperiments. In the first one, we propose a new similarity measure SDA-MWE, which stems\nfrom the syntactic distributional analysis, and apply it to the task of automatic thesaurus\nconstruction. The second one presents a new similarity measure DefVectors based on defi-\nnitions. Finally, in the third experiment, we propose a new similarity measure PatternSim,\nwhich extracts “definitions” from a huge corpus with lexico-syntactic patterns. Three measures\ndescribed in this chapter, perform comparably to the baselines, each with its pros and\ncons in terms of precision and coverage. We conclude that one way to significantly improve\nover the baselines could be to use the complementarity of different measures. This idea is\ndeveloped in the next chapter.\nChapter 3 evaluates a wide range of baseline semantic similarity measures to identify their\nsystematic advantages and disadvantages. The existing measures differ both in the kinds\nof information they use and in the ways this information is transformed into a similarity\nscore. First, in this chapter, we present a comparative study of heterogeneous baseline measures.\nSeveral authors already compared existing approaches, but we perform a study on\na large scale, as we compare 37 similarity measures based on semantic networks, text corpora,\nWeb as a corpus, dictionaries and encyclopedia. Second, we go further than most\nof the surveys and compare the measures with respect to the semantic relation types they\nprovide (hypernyms, meronyms, etc.). Our results suggest that the studied approaches are\nhighly heterogeneous in terms of precision, coverage and semantic relation distributions.\nWe address the problem of measure combination in the next chapter.\nChapter 4 describes several hybrid semantic similarity measures combining evidence from\ncomplementary sources. First, in this chapter, we present a systematic analysis of 16 baseline\nmeasures combined with 9 fusion methods and 3 measure selection techniques. Some\nattempts were already made to combine the baseline measures to improve the performance.\nHowever, we are first to propose hybrid similarity measures based on all main types of resources\n– semantic networks, text corpora, Web as a corpus, dictionaries and encyclopedia.\nSecond, we describe several novel hybrid measure which combine 15 baselines with the supervised\nlearning: Logit-E15, C-SVM-linear-E15, C-SVM-radial-E15, etc. They outperform\nall tested single and unsupervised hybrid measures by a large margin. Our results show that\nmeasures based on complementary sources of information indeed significantly outperform\nthe baselines measures.\nChapter 5 presents two applications of semantic similarity measures to text processing. Both\nsystems rely on the PatternSim measure introduced in Chapter 2. First, we describe Serelex,\na system that given a query, provides a list of related terms and displays them in a form of\nan interactive graph or a set of images. Second, we describe a new short text categorization\nsystem, developed for processing filenames of P2P networks. We show that the relations\n\nextracted with the similarity measure PatternSim improve the accuracy of the classification\nwith the help of the vocabulary projection technique. Finally, in this chapter, we provide\na list of further text processing applications, where semantic similarity measures may be\nuseful. We conclude that the developed semantic similarity measures can indeed be practical\nfor the real text processing systems.","authors":["Alexander Panchenko"],"meta":["February 2013","DOI:10.13140/RG.2.2.17076.45448","Thesis for: PhDAdvisor: Cédrick Fairon, Andrey Philippovich","Project: Serelex.org: a lexical-semantic search engine"],"references":["314102164_A_Study_of_Heterogeneous_Similarity_Measures_for_Semantic_Relation_Extraction","322743701_De_la_reconnaissance_de_formes_linguistiques_a_l'analyse_syntaxique","319770816_Combining_Pattern_Classifiers_Methods_and_Algorithms","315827789_Wiley_Series_in_Probability_and_Statistics","314818992_Building_a_web_thesaurus_from_web_link_structure","313619129_A_structured_vector_space_model_for_word_meaning_in_context","313618594_Automatic_retrieval_and_clustering_of_similar_words","313227243_Learning_syntactic_patterns_for_automatic_hypernym_discovery","313102322_Verbs_semantics_and_lexical_selection","312985702_A_cluster-based_approach_to_thesaurus_construction"]}