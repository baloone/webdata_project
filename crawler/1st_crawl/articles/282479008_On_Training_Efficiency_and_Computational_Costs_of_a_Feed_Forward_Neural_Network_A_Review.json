{"id":"282479008_On_Training_Efficiency_and_Computational_Costs_of_a_Feed_Forward_Neural_Network_A_Review","abstract":"A comprehensive review on the problem of choosing a suitable activation function for the hidden layer of a feed forward neural network has been widely investigated. Since the nonlinear component of a neural network is the main contributor to the network mapping capabilities, the different choices that may lead to enhanced performances, in terms of training, generalization, or computational costs, are analyzed, both in general-purpose and in embedded computing environments. Finally, a strategy to convert a network configuration between different activation functions without altering the network mapping capabilities will be presented.","authors":["Antonino Laudani","Gabriele Maria Lozito","Francesco Riganti Fulginei","Alessandro Salvini"],"meta":["August 2015Computational Intelligence and Neuroscience 2015(4):1-13","DOI:10.1155/2015/818243"],"references":["284514502_Minimum_complexity_echo_state_network","319770146_Second_Order_Derivatives_for_Network_Pruning_Optimal_Brain_Surgeon","313601183_Optimal_brain_damage_in","306150595_Neural_Networks_A_Comprehensive_Foundation","286591548_Implementation_of_PWL_and_LUT_based_approximation_for_hyperbolic_tangent_activation_function_in_VLSI","286571303_High_precision_FPGA_implementation_of_neural_network_activation_functions","286421301_Microcontroller_based_maximum_power_point_tracking_through_FCC_and_MLP_Neural_Networks","285699349_A_neural_networks-based_maximum_power_point_tracker_with_improved_dynamics_for_variable_dc-link_grid-connected_photovoltaic_power_plants","284500238_Approximation_by_superposition_of_sigmoidale_function","283586888_An_efficient_architecture_for_floating_point_based_MISO_neural_neworks_on_FPGA"]}