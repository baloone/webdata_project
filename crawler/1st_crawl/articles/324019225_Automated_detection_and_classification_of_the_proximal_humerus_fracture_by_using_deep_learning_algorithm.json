{"id":"324019225_Automated_detection_and_classification_of_the_proximal_humerus_fracture_by_using_deep_learning_algorithm","abstract":"Background and purpose — We aimed to evaluate the ability of artificial intelligence (a deep learning algorithm) to detect and classify proximal humerus fractures using plain anteroposterior shoulder radiographs.\nPatients and methods — 1,891 images (1 image per person) of normal shoulders (n = 515) and 4 proximal humerus fracture types (greater tuberosity, 346; surgical neck, 514; 3-part, 269; 4-part, 247) classified by 3 specialists were evaluated. We trained a deep convolutional neural network (CNN) after augmentation of a training dataset. The ability of the CNN, as measured by top-1 accuracy, area under receiver operating characteristics curve (AUC), sensitivity/specificity, and Youden index, in comparison with humans (28 general physicians, 11 general orthopedists, and 19 orthopedists specialized in the shoulder) to detect and classify proximal humerus fractures was evaluated.\nResults — The CNN showed a high performance of 96% top-1 accuracy, 1.00 AUC, 0.99/0.97 sensitivity/specificity, and 0.97 Youden index for distinguishing normal shoulders from proximal humerus fractures. In addition, the CNN showed promising results with 65–86% top-1 accuracy, 0.90–0.98 AUC, 0.88/0.83–0.97/0.94 sensitivity/specificity, and 0.71–0.90 Youden index for classifying fracture type. When compared with the human groups, the CNN showed superior performance to that of general physicians and orthopedists, similar performance to orthopedists specialized in the shoulder, and the superior performance of the CNN was more marked in complex 3- and 4-part fractures.\nInterpretation — The use of artificial intelligence can accurately detect and classify proximal humerus fractures on plain shoulder AP radiographs. Further studies are necessary to determine the feasibility of applying artificial intelligence in the clinic and whether its use could improve care and outcomes compared with current orthopedic assessments.","authors":["Seok Won Chung","Seung Seog Han","Ji Whan Lee","Kyung-Soo Oh"],"meta":["March 2018Acta Orthopaedica 89(4):1-6","DOI:10.1080/17453674.2018.1453714"],"references":["318255127_Artificial_intelligence_for_analyzing_orthopedic_trauma_radiographs_Deep_learning_algorithms-are_they_on_par_with_humans_for_diagnosing_fractures","281622607_Computer-aided_classification_of_lung_nodules_on_computed_tomography_images_via_deep_learning_technique","277411157_Deep_Learning","265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge","240308782_Stacked_Autoencoders_for_Unsupervised_Feature_Learning_and_Multiple_Organ_Detection_in_a_Pilot_Study_Using_4D_Patient_Data","240308775_Representation_Learning_A_Review_and_New_Perspectives","316443493_Deep_Learning_at_Chest_Radiography_Automated_Classification_of_Pulmonary_Tuberculosis_by_Using_Convolutional_Neural_Networks","312890808_Dermatologist-level_classification_of_skin_cancer_with_deep_neural_networks","311164170_Development_and_Validation_of_a_Deep_Learning_Algorithm_for_Detection_of_Diabetic_Retinopathy_in_Retinal_Fundus_Photographs","305825605_Large_Scale_Deep_Learning_for_Computer_Aided_Detection_of_Mammographic_Lesions"]}