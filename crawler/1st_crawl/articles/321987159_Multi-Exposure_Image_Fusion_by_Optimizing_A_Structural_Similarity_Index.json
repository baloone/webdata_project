{"id":"321987159_Multi-Exposure_Image_Fusion_by_Optimizing_A_Structural_Similarity_Index","abstract":"We propose a multi-exposure image fusion (MEF) algorithm by optimizing a novel objective quality measure, namely the color MEF structural similarity (MEF-SSIM\n<sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">c</sub>\n) index. The design philosophy we introduce here is substantially different from existing ones. Instead of pre-defining a systematic computational structure for MEF (e.g., multiresolution transformation and transform domain fusion followed by image reconstruction), we directly operate in the space of all images, searching for the image that optimizes MEF-SSIM\n<sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">c</sub>\n. Specifically, we first construct the MEF-SSIM\n<sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">c</sub>\nindex by improving upon and expanding the application scope of the existing MEF-SSIM algorithm. We then describe a gradient ascent-based algorithm, which starts from any initial point in the space of all possible images and iteratively moves towards the direction that improves MEF-SSIM\n<sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">c</sub>\nuntil convergence. Numerical and subjective experiments demonstrate that the proposed algorithm consistently produces better quality fused images both visually and in terms of MEF-SSIM\n<sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">c</sub>\n. The final high quality fused image appears to have little dependence on the initial image. The proposed optimization framework is readily extensible to construct better MEF algorithms when better objective quality models for MEF are available.","authors":["Kede Ma","Zhengfang Duanmu","Hojatollah Yeganeh","Zhou Wang"],"meta":["December 2017IEEE Transactions on Computational Imaging PP(99):1-1","DOI:10.1109/TCI.2017.2786138"],"references":["319477556_Robust_Match_Fusion_Using_Optimization","313873079_Robust_Multi-Exposure_Image_Fusion_A_Structural_Patch_Decomposition_Approach","286098929_Perceptual_evaluation_of_multi-exposure_image_fusion_algorithms","278040014_Perceptual_Quality_Assessment_for_Multi-Exposure_Image_Fusion","277413576_High_Dynamic_Range_Image_Compression_by_Optimizing_Tone_Mapped_Image_Quality_Index","266085372_Robust_Match_Fusion_Using_Optimization","264791653_Exposure_Fusion_Using_Boosting_Laplacian_Pyramid","260508610_Fast_Multi-exposure_Image_Fusion_with_Median_Filter_and_Recursive_Filter","242935652_Bilateral_Filter_Based_Compositing_for_Variable_Exposure_Photography","236228168_Guided_Image_Filtering","235392779_Image_Fusion_With_Guided_Filtering","232225860_A_Variational_Approach_for_the_Fusion_of_Exposure_Bracketed_Pairs","220182366_Objective_Assessment_of_Multiresolution_Image_Fusion_Algorithms_for_Context_Enhancement_in_Night_Vision_A_Comparative_Study","23296252_Maximum_differentiation_MAD_competition_A_methodology_for_comparing_computational_models_of_perceptual_quantities","3596479_Enhanced_image_capture_through_fusion","3404800_Comments_on_'Information_measure_for_performance_of_image_fusion'","3327793_Image_Quality_Assessment_From_Error_Visibility_to_Structural_Similarity","313571339_Enhanced_image_capture_through_fusion","312771295_Image_quality_assessment_From_error_visibility_to_structural_similarity","308746581_Multi-exposure_image_fusion_A_patch-wise_approach","285122418_Performance_evaluation_of_image_fusion_techniques","268794927_Weighted_Guided_Image_Filtering","264990138_Selectively_Detail-Enhanced_Fusion_of_Differently_Exposed_Images_With_Moving_Objects","261567231_A_Differentiable_Approximation_Approach_to_Contrast-Aware_Image_Fusion","258763477_ExpoBlend_Information_preserving_exposure_blending_based_on_normalized_log-domain_entropy","257466868_Gradient_field_multi-exposure_images_fusion_for_high_dynamic_range_image_visualization","240326082_The_Pyramid_as_a_Structure_for_Efficient_Computation","234047754_QoE-Based_Multi-Exposure_Fusion_in_Hierarchical_Multivariate_Gaussian_CRF","233879929_Perceptual_Video_Coding_Based_on_SSIM-Inspired_Divisive_Normalization","230770816_Applied_Statistics_and_Probability_for_Engineers","229805949_Exposure_Fusion_A_Simple_and_Practical_Alternative_to_High_Dynamic_Range_Photography","229155690_Detail-Enhanced_Exposure_Fusion","229058134_Convex_Optimization","224355724_A_novel_image_fusion_metric_based_on_multi-scale_analysis","224258548_SSIM-Motivated_Rate_Distortion_Optimization_for_Video_Coding","222897039_A_new_metric_based_on_extended_spatial_frequency_and_its_application_to_DWT_based_fusion_algorithms","222681366_Fusion_of_multi-exposure_images","222620431_A_novel_similarity_based_quality_metric_for_image_fusion","220610745_A_new_automated_quality_assessment_algorithm_for_image_fusion","220338578_A_human_perception_inspired_quality_metric_for_image_fusion_based_on_regional_information","215458823_High_dynamic_range_imaging_acquisition_display_and_image-based_lighting","51759511_On_the_Mathematical_Properties_of_the_Structural_Similarity_Index","51686556_Gradient-Directed_Multiexposure_Composition","51162683_Probabilistic_Exposure_Fusion","51106281_Generalized_Random_Walks_for_Fusion_of_Multi-Exposure_Images","4044744_A_new_quality_metric_for_image_fusion","3766290_Bilateral_Filtering_for_Gray_and_Color_Images","3388999_Image_fusion_metric_based_on_mutual_information_and_Tsallis_entropy"]}