{"id":"338662323_Constructing_energy-efficient_mixed-precision_neural_networks_through_principal_component_analysis_for_edge_intelligence","abstract":"The ‘Internet of Things’ has brought increased demand for artificial intelligence-based edge computing in applications ranging from healthcare monitoring systems to autonomous vehicles. Quantization is a powerful tool to address the growing computational cost of such applications and yields significant compression over full-precision networks. However, quantization can result in substantial loss of performance for complex image classification tasks. To address this, we propose a principal component analysis (PCA)-driven methodology to identify the important layers of a binary network, and design mixed-precision networks. The proposed Hybrid-Net achieves a more than 10% improvement in classification accuracy over binary networks such as XNOR-Net for ResNet and VGG architectures on CIFAR-100 and ImageNet datasets, while still achieving up to 94% of the energy efficiency of XNOR-Nets. This work advances the feasibility of using highly compressed neural networks for energy-efficient neural computing in edge devices. Neural networks are often implemented with reduced precision in order to meet the tight energy and memory budget required by edge computing devices. Chakraborty et al. develop a technique for assessing which layers can be quantized, and by how much, without sacrificing too much on performance.","authors":["Indranil Chakraborty","Deboleena Roy","Isha Garg","Aayush Ankit"],"meta":["January 2020Nature Machine Intelligence 2(1):1-13","DOI:10.1038/s42256-019-0134-0"],"references":["338162455_A_Low_Effort_Approach_to_Structured_CNN_Design_Using_PCA","320920360_Compression-aware_Training_of_Deep_Networks","319501484_WRPN_Wide_Reduced-Precision_Networks","344897580_Generalization_by_weight-elimination_applied_to_currency_exchange_rate_prediction","338513454_Learning_to_Quantize_Deep_Networks_by_Optimizing_Quantization_Intervals_With_Task_Loss","328129716_LQ-Nets_Learned_Quantization_for_Highly_Accurate_and_Compact_Deep_Neural_Networks_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Part_VIII","328127926_Bi-Real_Net_Enhancing_the_Performance_of_1-Bit_CNNs_with_Improved_Representational_Capability_and_Advanced_Training_Algorithm_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Pa","325000453_Hybrid_Binary_Networks_Optimizing_for_Accuracy_Efficiency_and_Memory","319770230_XNOR-Net_ImageNet_Classification_Using_Binary_Convolutional_Neural_Networks","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","317827358_Balanced_Quantization_An_Effective_and_Efficient_Approach_to_Quantized_Neural_Networks","313712534_Soft_Weight-Sharing_for_Neural_Network_Compression","315870954_DeepSense_A_Unified_Deep_Learning_Framework_for_Time-Series_Mobile_Sensing_Data_Processing","314092488_Low-Precision_Batch-Normalized_Activations","312383457_A_quantitative_analysis_of_current_security_concerns_and_solutions_for_cloud_computing"]}