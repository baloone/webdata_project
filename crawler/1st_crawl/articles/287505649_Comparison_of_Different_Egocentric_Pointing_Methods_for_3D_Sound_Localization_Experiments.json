{"id":"287505649_Comparison_of_Different_Egocentric_Pointing_Methods_for_3D_Sound_Localization_Experiments","abstract":"This study evaluates several methods for reporting the perceived location of real sound sources. It is well known that the method used for collecting judgments in auditory-localization experiments has a strong influence on the accuracy of a subject’s response. Previous works on auditory-localization tasks revealed that egocentric pointing methods (which are based on a body-centered coordinate system) allow for more accurate judgments than verbal reporting or exocentric pointing techniques (which are based on a 2D or 3D reporting device). Three different egocentric methods are compared: the most commonly applied “manual pointing” and “head pointing” methods, and the “proximal pointing” method, which forces the participants to indicate the apparent direction by pointing in the proximal region of the head with a marker held at the fingertips. The two first methods involve a rotation of the body of the participant, whereas the third method only involves movements of the arm(s) and hand(s) with a fixed head. Sound stimuli were presented randomly over 24 loudspeakers that were uniformly distributed on the upper hemisphere around the subject. The merits of the different methods are compared and discussed with regard to localization errors and to practical considerations. Although they show similar trends, each of the different methods affects the pointing accuracy in a specific way. The proximal pointing method, for example, is more accurate for sources located at high elevation angles. However, at rear locations close to the median plane an increased bias appears due to difficulties in performing the motor task to reach these positions. The proximal pointing method shows faster response times, which may be advantageous when planning 3D sound localization experiments.","authors":["Hélène Bahu","Thibaut Carpentier","Markus Noisternig","Olivier Warusfel"],"meta":["January 2016Acta Acustica united with Acustica 102(1):107-118","DOI:10.3813/AAA.918928","Project: BiLi Project"],"references":["266086398_From_ear_to_body_The_auditory-motor_loop_in_spatial_cognition","259492590_The_influence_of_vision_on_sound_localization_abilities_in_both_the_horizontal_and_vertical_planes","258446201_Revised_Standards_for_Statistical_Evidence","253644795_Investigation_on_Localisation_Accuracy_for_First_and_Higher_Order_Ambisonics_Reproduced_Sound_Sources","236461297_From_ear_to_hand_The_role_of_the_auditory-motor_loop_in_pointing_to_an_auditory_source","308965403_Comparison_of_a_2D-_and_3D-Based_Graphical_User_Interface_for_Localization_Listening_Tests","298846371_Free-field_equivalent_localization_of_virtual_audio","298090215_Contribution_of_spectral_cues_to_human_sound_localization","240096082_Localization_cues_of_sound_sources_in_the_upper_hemisphere","233571030_An_Interactive_Virtual-Environment_Generator_for_Psychoacoustic_Research_II_Collection_of_Head-Related_Impulse_Responses_and_Evaluation_of_Auditory_Localization"]}