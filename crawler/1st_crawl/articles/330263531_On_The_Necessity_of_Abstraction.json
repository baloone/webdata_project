{"id":"330263531_On_The_Necessity_of_Abstraction","abstract":"A generally intelligent agent faces a dilemma: it requires a complex sensorimotor space to be capable of solving a wide range of problems, but many tasks are only feasible given the right problem-specific formulation. I argue that a necessary but understudied requirement for general intelligence is the ability to form task-specific abstract representations. I show that the reinforcement learning paradigm structures this question into how to learn action abstractions and how to learn state abstractions, and discuss the field's progress on these topics.","authors":["George Konidaris"],"meta":["October 2019Current Opinion in Behavioral Sciences 29(6419):1-7","DOI:10.1016/j.cobeha.2018.11.005"],"references":["326209278_State_Abstractions_for_Lifelong_Reinforcement_Learning","324314435_Abstraction_Selection_in_Model-Based_Reinforcement_Learning","323078755_From_Skills_to_Symbols_Learning_Symbolic_Representations_for_Abstract_High-Level_Planning","329473176_A_general_reinforcement_learning_algorithm_that_masters_chess_shogi_and_Go_through_self-play","325944131_Symbol_acquisition_for_probabilistic_high-level_planning","323257379_Diversity_is_All_You_Need_Learning_Skills_without_a_Reward_Function","319736060_When_Waiting_is_not_an_Option_Learning_Options_with_a_Deliberation_Cost","318721154_DARLA_Improving_Zero-Shot_Transfer_in_Reinforcement_Learning","317010374_Automatic_Goal_Generation_for_Reinforcement_Learning_Agents","314237753_A_Laplacian_Framework_for_Option_Discovery_in_Reinforcement_Learning"]}