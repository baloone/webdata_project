{"id":"319035676_Recent_Trends_in_Deep_Learning_Based_Natural_Language_Processing","abstract":"Deep learning methods employ multiple processing layers to learn hierarchical representations of data, and have produced state-of-the-art results in many domains. Recently, a variety of model designs and methods have blossomed in the context of natural language processing (NLP). In this paper, we review significant deep learning related models and methods that have been employed for numerous NLP tasks and provide a walk-through of their evolution. We also summarize, compare and contrast the various models and put forward a detailed understanding of the past, present and future of deep learning in NLP.","authors":["Tom Young","Devamanyu Hazarika","Soujanya Poria","Erik Cambria"],"meta":["August 2017"],"references":["322583998_Adversarial_Learning_for_Neural_Dialogue_Generation","319770465_Sequence_to_Sequence_Learning_with_Neural_Networks","319770439_Efficient_Estimation_of_Word_Representations_in_Vector_Space","319770355_Generative_Adversarial_Nets","319770229_Auto-Encoding_Variational_Bayes","319770184_Speech_Recognition_With_Deep_Recurrent_Neural_Networks","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","319769995_End-To-End_Memory_Networks","319769905_Sequence_Level_Training_with_Recurrent_Neural_Networks","318828956_Seqgan_sequence_generative_adversarial_nets_with_policy_gradient"]}