{"id":"332025066_Privacy_as_Protection_of_the_Incomputable_Self_From_Agnostic_to_Agonistic_Machine_Learning","abstract":"This Article takes the perspective of law and philosophy, integrating insights from computer science. First, I will argue that in the era of big data analytics we need an understanding of privacy that is capable of protecting what is uncountable, incalculable or incomputable about individual persons. To instigate this new dimension of the right to privacy, I expand previous work on the relational nature of privacy, and the productive indeterminacy of human identity it implies, into an ecological understanding of privacy, taking into account the technological environment that mediates the constitution of human identity. Second, I will investigate how machine learning actually works, detecting a series of design choices that inform the accuracy of the outcome, each entailing trade-offs that determine the relevance, validity and reliability of the algorithm’s accuracy for real life problems. I argue that incomputability does not call for a rejection of machine learning per se but calls for a research design that enables those who will be affected by the algorithms to become involved and to learn how machines learn — resulting in a better understanding of their potential and limitations. A better understanding of the limitations that are inherent in machine learning will deflate some of the eschatological expectations, and provide for better decision-making about whether and if so how to implement machine learning in specific domains or contexts. I will highlight how a reliable research design aligns with purpose limitation as core to its methodological integrity. This Article, then, advocates a practice of “agonistic machine learning” that will contribute to responsible decisions about the integration of data-driven applications into our environments while simultaneously bringing them under the Rule of Law. This should also provide the best means to achieve effective protection against overdetermination of individuals by machine inferences .","authors":["Mireille Hildebrandt"],"meta":["March 2019Theoretical Inquiries in Law 20(1):83-121","DOI:10.1515/til-2019-0004"],"references":["312597416_Why_a_Right_to_Explanation_of_Automated_Decision-Making_Does_Not_Exist_in_the_General_Data_Protection_Regulation","303479231_'Hypernudge'_Big_Data_as_a_mode_of_regulation_by_design","254898221_The_Dawn_of_a_Critical_Transparency_Right_for_the_Profiling_Era","326193434_The_Right_to_Explanation_Explained","318003528_Slave_to_the_Algorithm_Why_a_Right_to_Explanationn_is_Probably_Not_the_Remedy_You_are_Looking_for","304548505_EU_regulations_on_algorithmic_decision-making_and_a_right_to_explanation","279274771_No_free_lunch_theorems_for_optimization","276044649_Pragmatism_An_Open_Question","248557977_Godel''''s_Incompleteness_Theorems","245859472_Deliberative_Democracy_or_A_gonistic_Pluralism"]}