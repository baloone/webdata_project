{"id":"321066424_BubbleView_An_Interface_for_Crowdsourcing_Image_Importance_Maps_and_Tracking_Visual_Attention","abstract":"In this article, we present BubbleView, an alternative methodology for eye tracking using discrete mouse clicks to measure which information people consciously choose to examine. BubbleView is a mouse-contingent, moving-window interface in which participants are presented with a series of blurred images and click to reveal “bubbles” -- small, circular areas of the image at original resolution, similar to having a confined area of focus like the eye fovea. Across 10 experiments with 28 different parameter combinations, we evaluated BubbleView on a variety of image types: information visualizations, natural images, static webpages, and graphic designs, and compared the clicks to eye fixations collected with eye-trackers in controlled lab settings. We found that BubbleView clicks can both (i) successfully approximate eye fixations on different images, and (ii) be used to rank image and design elements by importance. BubbleView is designed to collect clicks on static images, and works best for defined tasks such as describing the content of an information visualization or measuring image importance. BubbleView data is cleaner and more consistent than related methodologies that use continuous mouse movements. Our analyses validate the use of mouse-contingent, moving-window methodologies as approximating eye fixations for different image and task types.","authors":["Nam Wook Kim","Zoya Bylinskii","Michelle A. Borkin","Krzysztof Z. Gajos"],"meta":["November 2017ACM Transactions on Computer-Human Interaction 24(5):1-40","DOI:10.1145/3131275"],"references":["318298404_TabletGaze_dataset_and_analysis_for_unconstrained_appearance-based_gaze_estimation_in_mobile_tablets","317248451_Saliency_Revisited_Analysis_of_Mouse_Movements_versus_Fixations","301462083_Gaze_vs_Mouse_A_Fast_and_Accurate_Gaze-Only_Click_Alternative","286207176_An_eye-movement_analysis_of_web-page_usability","282793850_SALICON_Saliency_in_Context","276296083_CAT2000_A_Large_Scale_Fixation_Dataset_for_Boosting_Saliency_Research","262347719_EYEDIAP_a_database_for_the_development_and_evaluation_of_gaze_estimation_algorithms_from_RGB_and_RGB-D_cameras","260709140_Does_an_Eye_Tracker_Tell_the_Truth_about_Visualizations_Findings_while_Investigating_Visualizations_for_Decision_Making","259978343_Eye_Tracking_and_Head_Movement_Detection_A_State-of-Art_Survey","259961066_Predicting_human_gaze_beyond_pixels","259703630_Eye_Tracking_in_Human-Computer_Interaction_and_Usability_Research_Ready_to_Deliver_the_Promises","255729260_The_Determinants_of_Web_Page_Viewing_Behavior_An_Eye-Tracking_Study","254913339_Eye_Tracking_A_Comprehensive_Guide_To_Methods_And_Measures","236170031_The_Management_of_Visual_Attention_in_Graphic_Displays","326912590_The_Eyes_Never_Lie_The_Use_of_Eyetracking_Data_in_HCI_Research","320967345_Saliency_Revisited_Analysis_of_Mouse_Movements_Versus_Fixations","319035835_Learning_Visual_Importance_for_Graphic_Designs_and_Data_Visualizations","313673198_Ergonomic_evaluation_of_user-interfaces_by_means_of_eye-movement_data","313326136_Eye_Fixation_Metrics_for_Large_Scale_Evaluation_and_Comparison_of_Information_Visualizations","311610990_Shallow_and_Deep_Convolutional_Networks_for_Saliency_Prediction","311610376_Eye_Tracking_for_Everyone","308189211_Where_Should_Saliency_Models_Look_Next","305821467_Appearance-based_gaze_estimation_in_the_wild","305375498_WebGazer_Scalable_Webcam_Eye_Tracking_Using_User_Interactions","304128215_Human_Attention_in_Visual_Question_Answering_Do_Humans_and_Deep_Networks_Look_at_the_Same_Regions","301932081_Spatio-Temporal_Modeling_and_Prediction_of_Visual_Attention_in_Graphical_User_Interfaces","301876608_What_Do_Different_Evaluation_Metrics_Tell_Us_About_Saliency_Models","300727725_A_Crowdsourced_Alternative_to_Eye-tracking_for_Visualization_Understanding","300726009_DesignScape","295458310_Eye_Tracking_in_User_Experience_Design","295161357_Webpage_Saliency","290483874_Eye_tracking_eye-based_human-computer_interaction","286402897_Privacy_considerations_for_a_pervasive_eye_tracking_world","284858203_Eye_tracking_in_HCI_and_usability_research","283155993_Predicting_Eye_Fixations_on_Webpage_Withan_Ensemble_of_Early_Features_and_High-Level_Representations_fromDeep_Network","282844329_DeepFix_A_Fully_Convolutional_Neural_Network_for_Predicting_Human_Eye_Fixations","282046160_Beyond_Memorability_Visualization_Recognition_and_Recall","279843693_A_Benchmark_of_Computational_Models_of_Saliency_to_Predict_Human_Fixations","276064438_Towards_the_quantitative_evaluation_of_visual_attention_models","275588350_TurkerGaze_Crowdsourcing_Saliency_with_Webcam_based_Eye_Tracking","274967261_Appearance-Based_Gaze_Estimation_in_the_Wild","271754456_The_gaze-contingent_moving_window_in_reading_Development_and_review","263669669_Learning_Layouts_for_Single-PageGraphic_Designs","263002356_Microsoft_COCO_Common_Objects_in_Context","261227383_Fine-Grained_Crowdsourcing_for_Fine-Grained_Recognition","260716639_What_do_saliency_models_predict","243726409_Non-intrusive_gaze_tracking_using_arti_cial_neural_networks","239761345_User_See_User_Point_Gaze_and_Cursor_Alignment_in_Web_Search","234800029_What_can_a_mouse_cursor_tell_us_more_Correlation_of_eyemouse_movements_on_web_browsing","230786785_Eye_fixations_and_cognitive_processes1_2","228765579_An_Eye_Movement_Analysis_of_Web_Page_Usability","228750148_The_Eyes_Never_Lie_The_Use_of_Eye_Tracking_Data_in_HCI_Research","228446463_Methods_for_comparing_scanpaths_and_saliency_maps_Strengths_and_weaknesses","230622951_Quantitative_Analysis_of_Human-Model_Agreement_in_Visual_Saliency_Modeling_A_Comparative_Study","227617339_Advances_in_Relating_Eye_Movements_and_Cognition"]}