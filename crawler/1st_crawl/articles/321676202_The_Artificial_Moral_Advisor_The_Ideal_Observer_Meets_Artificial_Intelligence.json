{"id":"321676202_The_Artificial_Moral_Advisor_The_Ideal_Observer_Meets_Artificial_Intelligence","abstract":"We describe a form of moral artificial intelligence that could be used to improve human moral decision-making. We call it the “artificial moral advisor” (AMA). The AMA would implement a quasi-relativistic version of the “ideal observer” famously described by Roderick Firth. We describe similarities and differences between the AMA and Firth’s ideal observer. Like Firth’s ideal observer, the AMA is disinterested, dispassionate, and consistent in its judgments. Unlike Firth’s observer, the AMA is non-absolutist, because it would take into account the human agent’s own principles and values. We argue that the AMA would respect and indeed enhance individuals’ moral autonomy, help individuals achieve wide and a narrow reflective equilibrium, make up for the limitations of human moral psychology in a way that takes conservatives’ objections to human bioenhancement seriously, and implement the positive functions of intuitions and emotions in human morality without their downsides, such as biases and prejudices.","authors":["Alberto Giubilini","Julian Savulescu"],"meta":["June 2018Philosophy & Technology 31(4):1-20","DOI:10.1007/s13347-017-0285-z"],"references":["346680983_The_Affect_Heuristic","340308928_The_affect_heuristic_in_judgments_of_risks_and_benefits","325671748_The_emotional_dog_and_its_rational_tail_A_social_intuitionist_approach_to_moral_judgment","305454340_From_oral_to_moral","301780232_A_Philosophical_Disease_Bioethics_Culture_and_Identity","300363922_Moral_Enhancement_and_Artificial_Intelligence_Moral_AI","288809387_Unfit_for_the_Future_The_Need_for_Moral_Enhancement","287524699_Natural_Moralities_A_Defense_of_Pluralistic_Relativism","285827880_Thinking_Fast_and_Slow","282470000_What_in_the_World_Is_Moral_Disgust"]}