{"id":"279703564_Representational_Learning_with_ELMs_for_Big_Data","abstract":"Geoffrey Hinton and Pascal Vincent showed that a restricted Boltzmann machine (RBM) and auto-encoders (AE) could be used for feature engineering. These engineered features then could be used to train multiple-layer neural networks, or deep networks. Two types of deep networks based on RBM exist: the deep belief network (DBN)1 and the deep Boltzmann machine (DBM). Guang-Bin Huang and colleagues introduced the extreme learning machine (ELM) as an single-layer feed-forward neural networks (SLFN) with a fast learning speed and good generalization capability. The ELM for SLFNs shows that hidden nodes can be randomly generated. ELM-AE output weights can be determined analytically, unlike RBMs and traditional auto-encoders, which require iterative algorithms. ELM-AE can be seen as a special case of ELM, where the input is equal to output, and the randomly generated weights are chosen to be orthogonal.","authors":["Liyanaarachchi Lekamalage Chamara Kasun","Hongming Zhou","Guang-Bin Huang","Chi-Man Vong"],"meta":["November 2013Intelligent Systems, IEEE 28(6):31-34"],"references":["301840852_Extensions_of_Lipschitz_mappings_into_a_Hilbert_space","220320676_Stacked_Denoising_Autoencoders_Learning_Useful_Representations_in_a_Deep_Network_with_a_Local_Denoising_Criterion","220320264_Efficient_Learning_of_Deep_Boltzmann_Machines","6928613_Universal_Approximation_Using_Incremental_Constructive_Feedforward_Networks_With_Random_Hidden_Nodes","2985446_Gradient-Based_Learning_Applied_to_Document_Recognition","342232632_Extreme_Learning_Machine_Theory_and_Applications","306157314_Extreme_learning_machine_for_regression_and_multiclass_classification","233393016_The_No-Prop_algorithm_A_new_learning_algorithm_for_multilayer_neural_networks","51704039_Extreme_learning_machine_for_regression_and_multiclass_classification_IEEE_Trans_Syst_Man_Cybern_422_513-529","6912170_Reducing_the_Dimensionality_of_Data_with_Neural_Networks"]}