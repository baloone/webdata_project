{"id":"329638183_DeepTest_automated_testing_of_deep-neural-network-driven_autonomous_cars","abstract":"Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads.\nHowever, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases.\nIn this paper, we design, implement, and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.","authors":["Yuchi Tian","Kexin Pei","Suman Jana","Baishakhi Ray"],"meta":["May 2018","DOI:10.1145/3180155.3180220","Conference: the 40th International Conference"],"references":["318370372_Safety_Verification_of_Deep_Neural_Networks","316955778_Extending_Defensive_Distillation","316911609_Safety_Verification_of_Deep_Neural_Networks","315852155_Practical_Black-Box_Attacks_against_Machine_Learning","313879240_On_the_Statistical_Detection_of_Adversarial_Examples","313713721_On_Detecting_Adversarial_Perturbations","313394663_Reluplex_An_Efficient_SMT_Solver_for_Verifying_Deep_Neural_Networks","309797568_Delving_into_Transferable_Adversarial_Examples_and_Black-box_Attacks","309448167_Accessorize_to_a_Crime_Real_and_Stealthy_Attacks_on_State-of-the-Art_Face_Recognition","309401703_Safety_Verification_of_Deep_Neural_Networks","307560165_Deep_neural_networks_are_easily_fooled_High_confidence_predictions_for_unrecognizable_images","306304648_Distillation_as_a_Defense_to_Adversarial_Perturbations_Against_Deep_Neural_Networks","303970050_Adversarial_Perturbations_Against_Deep_Neural_Networks_for_Malware_Classification","303521296_Adversarial_Training_Methods_for_Semi-Supervised_Text_Classification","303486514_Measuring_Neural_Net_Robustness_with_Constraints","303137904_Greedy_layer-wise_training_of_deep_networks","301879941_Improving_the_Robustness_of_Deep_Neural_Networks_via_Stability_Training","301817984_Crafting_Adversarial_Input_Sequences_for_Recurrent_Neural_Networks","284788388_The_Limitations_of_Deep_Learning_in_Adversarial_Settings","284219659_Understanding_Adversarial_Training_Increasing_Local_Stability_of_Neural_Nets_through_Robust_Optimization","284097112_Distillation_as_a_Defense_to_Adversarial_Perturbations_against_Deep_Neural_Networks","281376985_Man_vs_Machine_Practical_Adversarial_Detection_of_Malicious_Crowdsourcing_Workers","269935591_Explaining_and_Harnessing_Adversarial_Examples","269722671_Towards_Deep_Neural_Network_Architectures_Robust_to_Adversarial_Examples","269280482_Deep_Neural_Networks_Are_Easily_Fooled_High_Confidence_Predictions_for_Unrecognizable_Images","326854186_Adversarial_Examples_for_Generative_Models","323248062_Feature_Squeezing_Detecting_Adversarial_Examples_in_Deep_Neural_Networks","322277018_Tensorflow_Large-scale_machine_learning_on_heterogeneous_distributed_systems","320358768_DeepXplore_Automated_Whitebox_Testing_of_Deep_Learning_Systems","319770427_Can_we_still_avoid_automatic_face_detection","319770378_Explaining_and_harnessing_adversarial_examples","319284636_Simple_Black-Box_Adversarial_Attacks_on_Deep_Neural_Networks","317919653_Towards_Evaluating_the_Robustness_of_Neural_Networks","317558194_Certified_Defenses_for_Data_Poisoning_Attacks","317157703_Improving_the_Robustness_of_Deep_Neural_Networks_via_Stability_Training","317010619_DeepXplore_Automated_Whitebox_Testing_of_Deep_Learning_Systems","316904628_Automatically_Evading_Classifiers_A_Case_Study_on_PDF_Malware_Classifiers","316598963_Parseval_Networks_Improving_Robustness_to_Adversarial_Examples","315798531_Feature_Squeezing_Detecting_Adversarial_Examples_in_Deep_Neural_Networks","314153095_Detecting_Adversarial_Samples_from_Artifacts","313385761_Data_Mining_Practical_Machine_Learning_Tools_and_Techniques","311919941_Crafting_adversarial_input_sequences_for_recurrent_neural_networks","311736938_Simple_Black-Box_Adversarial_Perturbations_for_Deep_Networks","310824288_Testing_advanced_driver_assistance_systems_using_multi-objective_search_and_neural_networks","306226844_Towards_Evaluating_the_Robustness_of_Neural_Networks","304533937_Learning_representations_by_back_propagating_errors_Cogn","303563688_Can_we_still_avoid_automatic_face_detection","303032467_The_Limitations_of_Deep_Learning_in_Adversarial_Settings","286370353_Practical_Evasion_of_a_Learning-Based_Classifier_A_Case_Study","267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks","259440613_Intriguing_properties_of_neural_networks","227640806_Comparison_of_Values_of_Pearson's_and_Spearman's_Correlation_Coefficients_on_the_Same_Sets_of_Data","262206388_An_orchestrated_survey_on_automated_software_test_case_generation","261588607_The_Proof_and_Measurement_of_Association_Between_Two_Things","242357592_Metamorphic_testing_a_new_approach_for_generating_next_test_cases"]}