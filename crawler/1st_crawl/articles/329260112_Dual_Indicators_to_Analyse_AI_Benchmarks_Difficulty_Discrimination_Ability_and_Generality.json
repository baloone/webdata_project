{"id":"329260112_Dual_Indicators_to_Analyse_AI_Benchmarks_Difficulty_Discrimination_Ability_and_Generality","abstract":"With the purpose of better analysing the result of AI benchmarks, we present two indicators on the side of the AI problems, difficulty and discrimination, and two indicators on the side of the AI systems, ability and generality. The first three are adapted from psychometric models in item response theory (IRT), whereas generality is defined as a new metric that evaluates whether an agent is consistently good at easy problems and bad at difficult ones. We illustrate how these key indicators give us more insight on the results of two popular benchmarks in AI, the Arcade Learning Environment (Atari 2600 games) and the General Video Game AI competition, and we include some guidelines to estimate and interpret these indicators for other AI benchmarks and competitions.","authors":["Fernando Mart√≠nez Plumed","Jose Hernandez-Orallo"],"meta":["November 2018IEEE Transactions on Games PP(99):1-1","DOI:10.1109/TG.2018.2883773"],"references":["320185803_A_New_AI_Evaluation_Cosmos_Ready_to_Play_the_Game","309032785_Making_Sense_of_Item_Response_Theory_in_Machine_Learning","306331182_Evaluation_in_artificial_intelligence_from_task-oriented_to_ability-oriented_measurement","294736874_Classical_Planning_with_Simulators_Results_on_the_Atari_Video_Games","292577192_The_2014_International_Planning_Competition_Progress_and_Trends","292074166_Mastering_the_game_of_Go_with_deep_neural_networks_and_tree_search","284476282_Dueling_Network_Architectures_for_Deep_Reinforcement_Learning","282182152_Deep_Reinforcement_Learning_with_Double_Q-learning","280104499_Massively_Parallel_Methods_for_Deep_Reinforcement_Learning","273350325_The_2014_General_Video_Game_Playing_Competition","272741511_Width_and_Serialization_of_Classical_Planning_Problems","268631015_Goodness-of-Fit_Assessment_of_Item_Response_Theory_Models","265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge","262169272_Rolling_horizon_evolution_versus_tree_search_for_navigation_in_single-player_real-time_games","260711387_A_Survey_of_Real-Time_Strategy_Game_AI_Research_and_Competition_in_StarCraft","237052357_Watson_Beyond_Jeopardy","235985858_A_Survey_of_Monte_Carlo_Tree_Search_Methods","229328831_The_Arcade_Learning_Environment_An_Evaluation_Platform_for_General_Agents","332013489_Blind_Search_for_Atari-Like_Online_Planning_Revisited","320746745_General_video_game_playing_escapes_the_no_free_lunch_theorem","319770330_Prioritized_Experience_Replay","316184689_The_Reactor_A_Sample-Efficient_Actor-Critic_Architecture","314943017_Evolution_Strategies_as_a_Scalable_Alternative_to_Reinforcement_Learning","313843716_Multi-objective_Adaptation_of_a_Parameterized_GVGAI_Agent_Towards_Several_Games","312986214_Some_studies_in_machine_learning_using_the_game_of_checkers","311626790_Tech_giants_open_virtual_worlds_to_bevy_of_AI_programs","309738235_Learning_to_Play_in_a_Day_Faster_Deep_Reinforcement_Learning_by_Optimality_Tightening","308866123_Towards_generating_arcade_game_rules_with_VGDL","292635877_Believable_bots_Can_computers_play_like_people","286801326_A_Panorama_of_Artificial_and_Computational_Intelligence_in_Games","285974348_What_the_no_free_lunch_theorems_really_mean_how_to_improve_search_algorithms","283692878_The_Mario_AI_Championship_2009-2012","281266055_No_Free_Lunch_Theorems_for_Optimization","272837232_Human-level_control_through_deep_reinforcement_learning","272825857_UCI_Machine_Learning_Repository","236853551_Some_Latent_Trait_Models_and_Their_Use_in_Inferring_an_Examinee's_Ability","222544943_Deep_blue","222532667_Measuring_Universal_Intelligence_Towards_an_Anytime_Intelligence_Test","220604585_General_Game_Playing_Overview_of_the_AAAI_Competition"]}