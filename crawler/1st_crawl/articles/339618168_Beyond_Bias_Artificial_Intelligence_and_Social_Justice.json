{"id":"339618168_Beyond_Bias_Artificial_Intelligence_and_Social_Justice","abstract":"sparked an extensive literature about bias in AI. Bias, as important as it is, is a special case of the overall problem of social justice. Beyond Bias focuses on the general problem. It incorporates contributions from the extensive discussion of AI and fairness in the computer science literature. In particular, it draws on Fairness Through Awareness, an influential article by the Harvard computer scientist Cynthia Dwork and her co-authors. Adapting Dwork’s approach, Beyond Bias reexpresses intuitive, well-motivated fairness constraints in a more mathematical way that shows how to apply the constraints to mathematically and computationally complex AI systems. The mathematics nonetheless uses only elementary arithmetic (unlike Dwork et al.). \n\nBeyond Bias adapts the fairness constraints that it reexpresses from the Yale economist John Roemer. As Roemer notes in Equality of Opportunity, a conception of “equality of opportunity . . . prevalent today in Western democracies . . . says that society should do what it can to ‘level the playing field’ among individuals who compete for positions.” Beyond Bias shows that AI systems can unfairly tilt the playing field. The reason lies in the pervasive (and unavoidable) use of “proxy variables”—e. g., using credit ratings to predict driving safety (as many insurance companies do). The credit ratings are the substitute—the proxy—for details about individuals’ driving practices. Beyond Bias is the first article to apply a level playing field concept of fairness to issues of fairness in AI systems. \n\nBeyond Bias briefly reviews the history of the use of proxy variables to evaluate consumers from the late Nineteenth Century to the present. It was already clear at the close of the Nineteenth Century that proxy-driven analysis could make seemingly unrelated aspects of one’s life “have a profound impact on [one’s] future potential in matters economic or social,” as Dan Bouk notes in HOW OUR DAYS BECAME NUMBERED: RISK AND THE RISE OF THE STATISTICAL INDIVIDUAL. The concern was that proxy-driven analysis would unfairly tilt the playing field, and that concern continues to this day. \n\nBeyond Bias outlines a regulatory approach that ensures level playing field fairness by incorporating its mathematical constraints on AI systems.","authors":["Robert Sloan","Richard Warner"],"meta":["March 2020Virginia Journal of Law & Technology ___(___):___","DOI:10.2139/ssrn.3530090"],"references":["338841880_Closing_the_AI_accountability_gap_defining_an_end-to-end_framework_for_internal_algorithmic_auditing","332416926_Algorithms_And_Human_Freedom"]}