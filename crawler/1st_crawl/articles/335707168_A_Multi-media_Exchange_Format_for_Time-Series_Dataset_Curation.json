{"id":"335707168_A_Multi-media_Exchange_Format_for_Time-Series_Dataset_Curation","abstract":"Exchanging data as character-separated values (CSV) is slow, cumbersome and error-prone. Especially for time-series data, which is common in Activity Recognition, synchronizing several independently recorded sensors is challenging. Adding second level evidence, like video recordings from multiple angles and time-coded annotations, further complicates the matter of curating such data. A possible alternative is to make use of standardized multi-media formats. Sensor data can be encoded in audio format, and time-coded information, like annotations, as subtitles. Video data can be added easily. All this media can be merged into a single container file, which makes the issue of synchronization explicit. The incurred performance overhead by this encoding is shown to be negligible and compression can be applied to optimize storage and transmission overhead.","authors":["Philipp Scholl","Benjamin VÃ¶lker","Bernd Becker","Kristof Van Laerhoven"],"meta":["September 2019","DOI:10.1007/978-3-030-13001-5_8","In book: Human Activity Sensing (pp.111-119)"],"references":["266603365_Towards_Benchmarked_Sleep_Detection_with_Inertial_Wrist-worn_Sensing_Units","253644828_A_Tutorial_on_Human_Activity_Recognition_Using_Body-Worn_Inertial_Sensors","227017257_Human_Activity_Recognition_from_Wireless_Sensor_Network_Data_Benchmark_and_Software","224174653_Collecting_complex_activity_datasets_in_highly_rich_networked_sensor_environments","220947286_HASC_Challenge_Gathering_Large_Scale_Human_Activity_Corpus_for_the_Real-World_Activity_Understandings","215990408_The_WEKA_data_mining_software_An_update","307881957_LIBSVM_A_library_for_support_vector_machines","221016001_Using_a_Live-In_Laboratory_for_Ubiquitous_Computing_Research"]}