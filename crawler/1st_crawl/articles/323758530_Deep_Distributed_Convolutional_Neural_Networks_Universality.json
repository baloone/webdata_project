{"id":"323758530_Deep_Distributed_Convolutional_Neural_Networks_Universality","abstract":"Deep learning based on structured deep neural networks has provided powerful applications in various fields. The structures imposed on the deep neural networks are crucial, which makes deep learning essentially different from classical schemes based on fully connected neural networks. One of the commonly used deep neural network structures is generated by convolutions. The produced deep learning algorithms form the family of deep convolutional neural networks. Despite of their power in some practical domains, little is known about the mathematical foundation of deep convolutional neural networks such as universality of approximation. In this paper, we propose a family of new structured deep neural networks: deep distributed convolutional neural networks. We show that these deep neural networks have the same order of computational complexity as the deep convolutional neural networks, and we prove their universality of approximation. Some ideas of our analysis are from ridge approximation, wavelets, and learning theory.","authors":["Ding-Xuan Zhou"],"meta":["March 2018Analysis and Applications 16(92)","DOI:10.1142/S0219530518500124"],"references":["323694548_Construction_of_Neural_Networks_for_Realization_of_Localized_Deep_Learning","316902965_Learning_Theory_of_Distributed_Spectral_Algorithms","307473101_Why_Does_Deep_and_Cheap_Learning_Work_So_Well","306186572_Distributed_Learning_with_Regularized_Least_Squares","253870727_Neural_Networks_for_Localized_Approximation","312641661_Thresholded_Spectral_Algorithms_for_Sparse_Approximations","306186507_Deep_vs_shallow_networks_An_approximation_theory_perspective","273067270_Unregularized_Online_Learning_Algorithms_with_General_Loss_Functions","269721972_Consistency_Analysis_of_an_Empirical_Minimum_Error_Entropy_Algorithm","256736756_Fundamentality_of_Ridge_Functions"]}