{"id":"289073179_Action_is_in_the_eye_of_the_beholder_Eye-gaze_driven_model_for_spatio-temporal_action_localization","abstract":"We propose a weakly-supervised structured learning approach for recognition and spatio-temporal localization of actions in video. As part of the proposed approach, we develop a generalization of the Max-Path search algorithm which allows us to efficiently search over a structured space of multiple spatio-temporal paths while also incorporating context information into the model. Instead of using spatial annotations in the form of bounding boxes to guide the latent model during training, we utilize human gaze data in the form of a weak supervisory signal. This is achieved by incorporating eye gaze, along with the classification, into the structured loss within the latent SVM learning framework. Experiments on a challenging benchmark dataset, UCF-Sports, show that our model is more accurate, in terms of classification, and achieves state-of-the-art results in localization. In addition, our model can produce top-down saliency maps conditioned on the classification label and localized latent paths.","authors":["N. Shapovalova","Michalis Raptis","Leonid Sigal","G. Mori"],"meta":["January 2013Advances in Neural Information Processing Systems"],"references":["252095046_Pattern_recognition_attention_and_information_bottlenecks_in_the_primate_visual_system"]}