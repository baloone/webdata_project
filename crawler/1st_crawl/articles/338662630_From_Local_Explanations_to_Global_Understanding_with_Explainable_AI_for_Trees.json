{"id":"338662630_From_Local_Explanations_to_Global_Understanding_with_Explainable_AI_for_Trees","abstract":"Tree-based machine learning models such as random forests, decision trees and gradient boosted trees are popular nonlinear predictive models, yet comparatively little attention has been paid to explaining their predictions. Here we improve the interpretability of tree-based models through three main contributions. (1) A polynomial time algorithm to compute optimal explanations based on game theory. (2) A new type of explanation that directly measures local feature interaction effects. (3) A new set of tools for understanding global model structure based on combining many local explanations of each prediction. We apply these tools to three medical machine learning problems and show how combining many high-quality local explanations allows us to represent global structure while retaining local faithfulness to the original model. These tools enable us to (1) identify high-magnitude but low-frequency nonlinear mortality risk factors in the US population, (2) highlight distinct population subgroups with shared risk characteristics, (3) identify nonlinear interaction effects among risk factors for chronic kidney disease and (4) monitor a machine learning model deployed in a hospital by identifying which features are degrading the modelâ€™s performance over time. Given the popularity of tree-based machine learning models, these improvements to their interpretability have implications across a broad set of domains. Tree-based machine learning models are widely used in domains such as healthcare, finance and public services. The authors present an explanation method for trees that enables the computation of optimal local explanations for individual predictions, and demonstrate their method on three medical datasets.","authors":["Scott Lundberg","Gabriel Erion","Hugh Chen","Alex DeGrave"],"meta":["January 2020Nature Machine Intelligence 2(1)","DOI:10.1038/s42256-019-0138-9"],"references":["338447967_A_Benchmark_for_Interpretability_Methods_in_Deep_Neural_Networks","331397043_Unmasking_Clever_Hans_Predictors_and_Assessing_What_Machines_Really_Learn","328775195_Clinical_Decision_Support_in_the_Era_of_Artificial_Intelligence","328199860_Explainable_machine-learning_predictions_for_the_prevention_of_hypoxaemia_during_surgery","324727926_Towards_better_understanding_of_Gradient-based_Attribution_Methods_for_Deep_Neural_Networks","317487999_White_blood_cell_count_predicts_the_odds_of_kidney_function_decline_in_a_Chinese_community-based_population","330625665_Influence-Directed_Explanations_for_Deep_Convolutional_Networks","323141377_Influence-Directed_Explanations_for_Deep_Convolutional_Networks","320971142_Network_Dissection_Quantifying_Interpretability_of_Deep_Visual_Representations","319770247_Why_Should_I_Trust_You_Explaining_the_Predictions_of_Any_Classifier","317062430_A_Unified_Approach_to_Interpreting_Model_Predictions","315703040_Association_between_Monocyte_Count_and_Risk_of_Incident_CKD_and_Progression_to_ESRD","316270940_Network_Dissection_Quantifying_Interpretability_of_Deep_Visual_Representations","313527377_American_Heart_Association_Statistics_Committee_Stroke_Statistics_Subcommittee_Heart_Disease_and_Stroke_Statistics-2016_update_a_report_from_the_American_Heart_Association","311533119_Heart_disease_and_stroke_statistics_2016_update"]}