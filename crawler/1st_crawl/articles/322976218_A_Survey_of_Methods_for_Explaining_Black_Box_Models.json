{"id":"322976218_A_Survey_of_Methods_for_Explaining_Black_Box_Models","abstract":"In the last years many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness sometimes at the cost of scarifying accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, delineating explicitly or implicitly its own definition of interpretability and explanation. The aim of this paper is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.","authors":["Riccardo Guidotti","Anna Monreale","Franco Turini","Dino Pedreschi"],"meta":["February 2018ACM Computing Surveys 51(5)","DOI:10.1145/3236009"],"references":["323355750_Artificial_Intelligence_and_Legal_Liability","320442349_Multi-Value_Rule_Sets","318981705_Challenges_for_Transparency","317734266_Interpretable_Predictions_of_Tree-based_Ensembles_via_Actionable_Feature_Tweaking","346624964_The_Black_Box_Society_The_Secret_Algorithms_That_Control_Money_and_Information","319770512_Reconstructing_an_image_from_its_local_descriptors","319770006_Learning_Deep_Features_for_Discriminative_Localization","318916854_The_Selective_Labels_Problem_Evaluating_Algorithmic_Predictions_in_the_Presence_of_Unobservables","318223014_Interpretable_Explorable_Approximations_of_Black_Box_Models","317191249_Mind_the_Gap_A_Generative_Approach_to_Interpretable_Feature_Selection_and_Extraction"]}