{"id":"337940965_Terminologies_augmented_recurrent_neural_network_model_for_clinical_named_entity_recognition","abstract":"Objective: \nWe aimed to enhance the performance of a supervised model for clinical named-entity recognition (NER) using medical terminologies. In order to evaluate our system in French, we built a corpus for 5 types of clinical entities.\n\nMethods: \nWe used a terminology-based system as baseline, built upon UMLS and SNOMED. Then, we evaluated a biGRU-CRF, and a hybrid system using the prediction of the terminology-based system as feature for the biGRU-CRF. In French, we built APcNER, a corpus of 147 documents annotated for 5 entities (Drug names, Signs or symptoms, Diseases or disorders, Diagnostic procedures or lab tests and Therapeutic procedures). We evaluated each NER systems using exact and partial match definition of F-measure for NER. The APcNER contains 4,837 entities, which took 28 hours to annotate. The inter-annotator agreement as measured by Cohen's Kappa was substantial for non-exact match (Κ= 0.61) and moderate considering exact match (Κ = 0.42). In English, we evaluated the NER systems on the i2b2-2009 Medication Challenge for Drug name recognition, which contained 8,573 entities for 268 documents, and i2b2-small a version reduced to match APcNER number of entities.\n\nResults: \nFor drug name recognition on both i2b2-2009 and APcNER, the biGRU-CRF performed better that the terminology-based system, with an exact-match F-measure of 91.1% versus 73% and 81.9% versus 75% respectively. For i2b2-small and APcNER, the hybrid system outperformed the biGRU-CRF, with an exact-match F-measure of 85.6% versus 87.8% and 88.4% versus 81.9% respectively. On APcNER corpus, the micro-average F-measure of the hybrid system on the 5 entities was 69.5% in exact match and 84.1% in non-exact match.\n\nConclusion: \nAPcNER is a French corpus for clinical-NER of five types of entities which covers a large variety of document types. The extension of the supervised model with terminology has allowed an easy increase in performance, especially for rare entities, and established near state of the art results on the i2b2-2009 corpus.","authors":["Ivan Lerner","Nicolas Paris","Xavier Tannier"],"meta":["December 2019Journal of Biomedical Informatics 102:103356","DOI:10.1016/j.jbi.2019.103356"],"references":["324979474_NCRF_An_Open-source_Neural_Sequence_Labeling_Toolkit","321198377_Clinical_Information_Extraction_Applications_A_Literature_Review","319524409_Semi-Supervised_Recurrent_Neural_Network_for_Adverse_Drug_Reaction_Mention_Extraction","316429020_SwellShark_A_Generative_Model_for_Biomedical_Named_Entity_Recognition_without_Labeled_Data","313778648_A_French_clinical_corpus_with_comprehensive_semantic_annotations_development_of_the_Medical_Entity_and_Relation_LIMSI_annOtated_Text_corpus_MERLOT","305334469_Neural_Architectures_for_Named_Entity_Recognition","304505738_Learning_for_Biomedical_Information_Extraction_Methodological_Review_of_Recent_Advances","303499206_MIMIC-III_a_freely_accessible_critical_care_database","291690574_Unsupervised_entity_and_relation_extraction_from_clinical_records_in_Italian","282045274_A_Study_of_Active_Learning_Methods_for_Named_Entity_Recognition_in_Clinical_Text","272091377_The_Stanford_CoreNLP_Natural_Language_Processing_Toolkit","255975021_Unsupervised_Biomedical_Named_Entity_Recognition_Experiments_with_Clinical_and_Biological_Texts","224890852_Extracting_medication_information_from_clinical_text","220873696_Multi-Criteria-based_Active_Learning_for_Named_Entity_Recognition","46158277_Community_annotation_experiment_for_ground_truth_generation_for_the_i2B2_medication_challenge","8954995_The_Unified_Medical_Language_System_UMLS_Integrating_Biomedical_Terminology","2473899_Text_Chunking_Using_Transformation-Based_Learning","331439650_FABLE_A_Semi-Supervised_Prescription_Information_Extraction_System","328836451_Initializing_a_hospital-wide_data_quality_program_The_AP-HP_experience","319770439_Efficient_Estimation_of_Word_Representations_in_Vector_Space","256483065_brat_a_Web-based_Tool_for_NLP-Assisted_Text_Annotation","220875017_Practical_very_large_scale_CRFs","2256832_Preventing_Overfitting_of_Cross-Validation_Data"]}