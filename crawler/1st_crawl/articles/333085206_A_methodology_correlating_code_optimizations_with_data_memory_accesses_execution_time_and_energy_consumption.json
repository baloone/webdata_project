{"id":"333085206_A_methodology_correlating_code_optimizations_with_data_memory_accesses_execution_time_and_energy_consumption","abstract":"The advent of data proliferation and electronic devices gets low execution time and energy consumption software in the spotlight. The key to optimizing software is the correct choice, order as well as parameters of optimization transformations that has remained an open problem in compilation research for decades for various reasons. First, most of the transformations are interdependent and thus addressing them separately is not effective. Second, it is very hard to couple the transformation parameters to the processor architecture (e.g., cache size) and algorithm characteristics (e.g., data reuse); therefore, compiler designers and researchers either do not take them into account at all or do it partly. Third, the exploration space, i.e., the set of all optimization configurations that have to be explored, is huge and thus searching is impractical. In this paper, the above problems are addressed for data-dominant affine loop kernels, delivering significant contributions. A novel methodology is presented reducing the exploration space of six code optimizations by many orders of magnitude. The objective can be execution time (ET), energy consumption (E) or the number of L1, L2 and main memory accesses. The exploration space is reduced in two phases: firstly, by applying a novel register blocking algorithm and a novel loop tiling algorithm and secondly, by computing the maximum and minimum ET/E values for each optimization set. The proposed methodology has been evaluated for both embedded and general-purpose CPUs and for seven well-known algorithms, achieving high memory access, speedup and energy consumption gain values (from 1.17 up to 40) over gcc compiler, hand-written optimized code and Polly. The exploration space from which the near-optimum parameters are selected is reduced from 17 up to 30 orders of magnitude.","authors":["Vasilios Kelefouras","Karim Djemame"],"meta":["October 2019The Journal of Supercomputing 75(1)","DOI:10.1007/s11227-019-02880-z"],"references":["325329394_Combining_Software_Cache_Partitioning_and_Loop_Tiling_for_Effective_Shared_Cache_Management","322517943_A_Survey_on_Compiler_Autotuning_using_Machine_Learning","319600563_MiCOMP_Mitigating_the_Compiler_Phase-Ordering_Problem_Using_Optimization_Sub-Sequences_and_Machine_Learning","303980080_COBAYN_Compiler_autotuning_framework_using_Bayesian_networks","289538523_Predictive_Modeling_Methodology_for_Compiler_Phase-Ordering","330229972_An_Autotuning_Framework_for_Scalable_Execution_of_Tiled_Code_via_Iterative_Polyhedral_Compilation","314105597_Minimizing_the_cost_of_iterative_compilation_with_active_learning","308206931_Loopy_Programmable_and_Formally_Verified_Loop_Transformations","300244538_Use_of_Previously_Acquired_Positioning_of_Optimizations_for_Phase_Ordering_Exploration","282510632_Array_Interleaving-An_Energy-Efficient_Data_Layout_Transformation"]}