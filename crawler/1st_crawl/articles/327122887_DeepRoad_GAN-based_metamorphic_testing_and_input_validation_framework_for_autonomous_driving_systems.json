{"id":"327122887_DeepRoad_GAN-based_metamorphic_testing_and_input_validation_framework_for_autonomous_driving_systems","abstract":"While Deep Neural Networks (DNNs) have established the fundamentals of image-based autonomous driving systems, they may exhibit erroneous behaviors and cause fatal accidents. To address the safety issues in autonomous driving systems, a recent set of testing techniques have been designed to automatically generate artificial driving scenes to enrich test suite, e.g., generating new input images transformed from the original ones. However, these techniques are insufficient due to two limitations: first, many such synthetic images often lack diversity of driving scenes, and hence compromise the resulting efficacy and reliability. Second, for machine-learning-based systems, a mismatch between training and application domain can dramatically degrade system accuracy, such that it is necessary to validate inputs for improving system robustness.\nIn this paper, we propose DeepRoad, an unsupervised DNN-based framework for automatically testing the consistency of DNN-based autonomous driving systems and online validation. First, DeepRoad automatically synthesizes large amounts of diverse driving scenes without using image transformation rules (e.g. scale, shear and rotation). In particular, DeepRoad is able to produce driving scenes with various weather conditions (including those with rather extreme conditions) by applying Generative Adversarial Networks (GANs) along with the corresponding real-world weather scenes. Second, DeepRoad utilizes metamorphic testing techniques to check the consistency of such systems using synthetic images. Third, DeepRoad validates input images for DNN-based systems by measuring the distance of the input and training images using their VGGNet features. We implement DeepRoad to test three well-recognized DNN-based autonomous driving systems in Udacity self-driving car challenge. The experimental results demonstrate that DeepRoad can detect thousands of inconsistent behaviors for these systems, and effectively validate input images to potentially enhance the system robustness as well.","authors":["Mengshi Zhang","Yuqun Zhang","Lingming Zhang","Cong Liu"],"meta":["September 2018","DOI:10.1145/3238147.3238187","Conference: the 33rd ACM/IEEE International Conference"],"references":["322060135_Unpaired_Image-to-Image_Translation_Using_Cycle-Consistent_Adversarial_Networks","329638183_DeepTest_automated_testing_of_deep-neural-network-driven_autonomous_cars","328144916_Real-to-Virtual_Domain_Unification_for_End-to-End_Autonomous_Driving_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Part_IV","327969786_DeepSafe_A_Data-Driven_Approach_for_Assessing_Robustness_of_Neural_Networks_16th_International_Symposium_ATVA_2018_Los_Angeles_CA_USA_October_7-10_2018_Proceedings","325498688_Managing_the_Test_Process","325489129_Introduction_to_Software_Testing","322383299_Real-to-Virtual_Domain_Unification_for_End-to-End_Autonomous_Driving","322328971_A_Note_on_the_Inception_Score","322306464_Semantic-aware_Grad-GAN_for_Virtual-to-Real_Urban_Scene_Adaption","322058208_DualGAN_Unsupervised_Dual_Learning_for_Image-to-Image_Translation"]}