{"id":"283644387_Continuous_Distributed_Representation_of_Biological_Sequences_for_Deep_Proteomics_and_Genomics","abstract":"We introduce a new representation and feature extraction method for biological sequences. Named bio-vectors (BioVec) to refer to biological sequences in general with protein-vectors (ProtVec) for proteins (amino-acid sequences) and gene-vectors (GeneVec) for gene sequences, this representation can be widely used in applications of deep learning in prote-omics and genomics. In the present paper, we focus on protein-vectors that can be utilized in a wide array of bioinformatics investigations such as family classification, protein visuali-zation, structure prediction, disordered protein identification, and protein-protein interaction prediction. In this method, we adopt artificial neural network approaches and represent a protein sequence with a single dense n-dimensional vector. To evaluate this method, we apply it in classification of 324,018 protein sequences obtained from Swiss-Prot belonging to 7,027 protein families, where an average family classification accuracy of 93% Â± 0.06% is obtained, outperforming existing family classification methods. In addition, we use ProtVec representation to predict disordered proteins from structured proteins. Two databases of disordered sequences are used: the DisProt database as well as a database featuring the disordered regions of nucleoporins rich with phenylalanine-glycine repeats (FG-Nups). Using support vector machine classifiers, FG-Nup sequences are distinguished from struc-tured protein sequences found in Protein Data Bank (PDB) with a 99.8% accuracy, and unstructured DisProt sequences are differentiated from structured DisProt sequences with 100.0% accuracy. These results indicate that by only providing sequence data for various proteins into this model, accurate information about protein structure can be determined. Importantly, this model needs to be trained only once and can then be applied to extract a comprehensive set of information regarding proteins of interest. Moreover, this representation can be considered as pre-training for various applications of deep learning in bioinfor-matics.","authors":["Ehsaneddin Asgari","Mohammad R K Mofrad"],"meta":["October 2015PLoS ONE 10(11):e0141287","DOI:10.1371/journal.pone.0141287"],"references":["283513925_Evolutionarily_Conserved_Sequence_Features_Regulate_the_Formation_of_the_FG_Network_at_the_Center_of_the_Nuclear_Pore_Complex","269768042_RNA_splicing_The_human_splicing_code_reveals_new_insights_into_the_genetic_determinants_of_disease","266201822_Natural_Language_Processing_Almost_from_Scratch","258956167_Higher_Nucleoporin-Importinb_Affinity_at_the_Nuclear_Basket_Increases_Nucleocytoplasmic_Import","257882504_Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality","319770439_Efficient_Estimation_of_Word_Representations_in_Vector_Space","313137884_Pfam_the_protein_families_database","307955489_Distributed_representations_of_words_and_phrases_and_their_compositionality","302889970_Distributed_representations_of_words_and_phrases_and_their_compositionality_In_Conference_on_Advances_in_Neural_Information_Processing_Systems","260231515_word2vec_Explained_deriving_Mikolov_et_al's_negative-sampling_word-embedding_method"]}