{"id":"234002937_Information_value_of_Multiple_Response_questions","abstract":"Answers to Multiple Response (MR) questions carry more information than we usually utilize. Simple idea that all options of MR questions should be scored as independent test items has two major difficulties: 1) false options have item-response characteristics that are hard to model and use with other items; and 2) responses to individual options within the same MR question could be too dependent on each other. These difficulties lead to an overestimation of item discrimination and test information function. A few scoring methods that could increase information value obtained from MR questions are proposed and evaluated in this paper. In formative tests, like tests for standards-setting or diagnostic tests, it is more important to find out what exactly examinees do or do not know than how much they know. For this purpose, because of interpretation simplicity, test makers usually utilize only two item types: Multiple Choice (MC) and Constructed Response (CR) questions. However, there is a need for other question types, especially in computer-based testing, that would bridge the gap between completely closed and completely open questions. Multiple Response (MR) questions have been examined as a promising candidate in a few recent studies (Eggen & Lampe, 2011; Hohensinn & Kubinger; Jiao, Liu, Haynie, Woo, & Gorham, 2012). MULTIPLE RESPONSE QUESTIONS","authors":["Srđan Verbić"],"meta":["December 2012Psihologija 459072214(303):467-485","DOI:10.2298/PSI1204467V","Project: e-Assessment in Serbia"],"references":["281912731_Comparison_of_the_reliability_of_scoring_methods_of_multiple-response_items_matching_items_and_sequencing_items","254089344_Comparison_Between_Dichotomous_and_Polytomous_Scoring_of_Innovative_Items_in_a_Large-Scale_Computerized_Adaptive_Test","251713499_Multiple_Choice_and_Constructed_Response_Tests_Do_Test_Format_and_Scoring_Matter","316657773_The_Basics_of_Item_Response_Theory_Using_R","289963481_Item_Response_Theory_Principles_and_Applications","284944608_Writing_the_test_item","276316411_The_Merits_of_Multiple-Answer_Items_as_Evaluated_by_Using_Six_Scoring_Formulas","272593046_The_development_investigation_and_evaluation_of_new_item_types_for_the_GRE_Analytical_measure","262196767_Item_Response_Theory_For_Psychologists","261651840_boot_Bootstrap_R_S--Plus_Functions"]}