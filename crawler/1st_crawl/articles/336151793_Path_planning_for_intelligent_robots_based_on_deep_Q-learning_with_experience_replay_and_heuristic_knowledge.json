{"id":"336151793_Path_planning_for_intelligent_robots_based_on_deep_Q-learning_with_experience_replay_and_heuristic_knowledge","abstract":"Path planning and obstacle avoidance are two challenging problems in the study of intelligent robots. In this paper, we develop a new method to alleviate these problems based on deep Q-learning with experience replay and heuristic knowledge. In this method, a neural network has been used to resolve the curse of dimensionality issue of the Q-table in reinforcement learning. When a robot is walking in an unknown environment, it collects experience data which is used for training a neural network; such a process is called experience replay. Heuristic knowledge helps the robot avoid blind exploration and provides more effective data for training the neural network. The simulation results show that in comparison with the existing methods, our method can converge to an optimal action strategy with less time and can explore a path in an unknown environment with fewer steps and larger average reward.","authors":["Lan Jiang","Hongyun Huang","Zuohua Ding"],"meta":["September 2019IEEE/CAA Journal of Automatica Sinica PP(99):1-11","DOI:10.1109/JAS.2019.1911732"],"references":[]}