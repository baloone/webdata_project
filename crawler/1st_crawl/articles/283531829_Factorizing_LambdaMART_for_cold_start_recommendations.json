{"id":"283531829_Factorizing_LambdaMART_for_cold_start_recommendations","abstract":"Recommendation systems often rely on point-wise loss metrics such as the mean\nsquared error. However, in real recommendation settings only few items are\npresented to a user. This observation has recently encouraged the use of\nrank-based metrics. LambdaMART is the state-of-the-art algorithm in learning to\nrank which relies on such a metric. Despite its success it does not have a\nprincipled regularization mechanism relying in empirical approaches to control\nmodel complexity leaving it thus prone to overfitting.\nMotivated by the fact that very often the users' and items' descriptions as\nwell as the preference behavior can be well summarized by a small number of\nhidden factors, we propose a novel algorithm, LambdaMART Matrix Factorization\n(LambdaMART-MF), that learns a low rank latent representation of users and\nitems using gradient boosted trees. The algorithm factorizes lambdaMART by\ndefining relevance scores as the inner product of the learned representations\nof the users and items. The low rank is essentially a model complexity\ncontroller; on top of it we propose additional regularizers to constraint the\nlearned latent representations that reflect the user and item manifolds as\nthese are defined by their original feature based descriptors and the\npreference behavior. Finally we also propose to use a weighted variant of NDCG\nto reduce the penalty for similar items with large rating discrepancy.\nWe experiment on two very different recommendation datasets, meta-mining and\nmovies-users, and evaluate the performance of LambdaMART-MF, with and without\nregularization, in the cold start setting as well as in the simpler matrix\ncompletion setting. In both cases it outperforms in a significant manner\ncurrent state of the art algorithms.","authors":["Phong Nguyen","Jun Wang","Alexandros Kalousis"],"meta":["September 2016Machine Learning 104(2-3)","DOI:10.1007/s10994-016-5579-3","SourcearXiv"],"references":["313715751_COFI_RANK_-_maximum_margin_matrix_factorization_for_collaborative_ranking","305386928_Maximum-margin_matrix_factorization","264623974_Matrix_Completion_on_Graphs","231609271_Learning_Heterogeneous_Similarity_Measures_for_Hybrid-Recommendations_inMeta-Mining","228936665_From_ranknet_to_lambdarank_to_lambdamart_An_overview","225662552_Ontology-Based_Meta-Mining_of_Knowledge_Discovery_Workflows","304288579_LambdaMF_Learning_Nonsmooth_Ranking_Functions_in_Matrix_Factorization_Using_Lambda","303256438_Maximum_margin_matrix_factorization_for_collaborative_ranking","280687718_Greedy_Function_Approximation_A_Gradient_Boosting_Machine","258560356_Preference_Learning","221619685_Maximum-Margin_Matrix_Factorization","221519967_fLDA_Matrix_factorization_through_latent_dirichlet_allocation","221300070_On_the_Local_Optimality_of_LambdaRank","224207514_Graph_Regularized_Nonnegative_Matrix_Factorization_for_Data_Representation","221301037_IR_evaluation_methods_for_retrieving_highly_relevant_documents"]}