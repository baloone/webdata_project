{"id":"325374535_Deep_Learning_for_Entity_Matching_A_Design_Space_Exploration","abstract":"Entity matching (EM) finds data instances that refer to the same real-world entity. In this paper we examine applying deep learning (DL) to EM, to understand DL's benefits and limitations. We review many DL solutions that have been developed for related matching tasks in text processing (e.g., entity linking, textual entailment, etc.). We categorize these solutions and define a space of DL solutions for EM, as embodied by four solutions with varying representational power: SIF, RNN, Attention, and Hybrid. Next, we investigate the types of EM problems for which DL can be helpful. We consider three such problem types, which match structured data instances, textual instances, and dirty instances, respectively. We empirically compare the above four DL solutions with Magellan, a state-of-the-art learning-based EM solution. The results show that DL does not outperform current solutions on structured EM, but it can significantly outperform them on textual and dirty EM. For practitioners, this suggests that they should seriously consider using DL for textual and dirty EM problems. Finally, we analyze DL's performance and discuss future research directions.","authors":["Sidharth Mudgal","Han Li","Theodoros Rekatsinas","AnHai Doan"],"meta":["May 2018","DOI:10.1145/3183713.3196926","Conference: the 2018 International Conference"],"references":["334476066_Snorkel_rapid_training_data_creation_with_weak_supervision","322591116_Recurrent_Neural_Network-Based_Sentence_Encoder_with_Gated_Attention_for_Natural_Language_Inference","322590845_Deep_Joint_Entity_Disambiguation_with_Local_Neural_Attention","321347204_Snorkel_Rapid_Training_Data_Creation_with_Weak_Supervision","319736499_DiSAN_Directional_Self-Attention_Network_for_RNNCNN-free_Language_Understanding","318958791_Recurrent_Neural_Network-Based_Sentence_Encoder_with_Gated_Attention_for_Natural_Language_Inference","316849732_Generating_Concise_Entity_Matching_Rules","313672142_Bilateral_Multi-Perspective_Matching_for_Natural_Language_Sentences","311990784_Character-Level_Question_Answering_with_Attention","306093778_End-to-End_Relation_Extraction_using_LSTMs_on_Sequences_and_Tree_Structures","306093654_Improved_Representation_Learning_for_Question_Answer_Matching","305881526_Matching_Networks_for_One_Shot_Learning","304834009_Learning_Text_Similarity_with_Siamese_Recurrent_Networks","304470296_Visual_Analysis_of_Hidden_State_Dynamics_in_Recurrent_Neural_Networks","301847971_A_Deep_Learning_Approach_to_Unsupervised_Ensemble_Learning","301657953_Comparative_Analysis_of_Approximate_Blocking_Techniques_for_Entity_Resolution","300873377_Recurrent_Neural_Networks","284576917_Glove_Global_Vectors_for_Word_Representation","275670021_Leveraging_Deep_Neural_Networks_and_Knowledge_Graphs_for_Entity_Disambiguation","325371426_Fonduer_Knowledge_Base_Construction_from_Richly_Formatted_Data","320885821_Accurate_Sentence_Matching_with_Hybrid_Siamese_Networks","320179857_DeepER_--_Deep_Entity_Resolution","319770411_Torch7_A_Matlab-like_Environment_for_Machine_Learning","318829716_Bilateral_Multi-Perspective_Matching_for_Natural_Language_Sentences","318741395_Bag_of_Tricks_for_Efficient_Text_Classification","317558625_Attention_Is_All_You_Need","315096289_Fonduer_Knowledge_Base_Construction_from_Richly_Formatted_Data","314237746_A_Comparative_Study_of_Word_Embeddings_for_Reading_Comprehension","311990523_A_Decomposable_Attention_Model_for_Natural_Language_Inference","311925796_Understanding_Neural_Networks_through_Representation_Erasure","309738189_A_Compare-Aggregate_Model_for_Matching_Text_Sequences","308757691_Database_Meets_Deep_Learning_Challenges_and_Opportunities","307896907_Magellan_Toward_building_entity_matching_management_systems","306093178_Improving_Coreference_Resolution_by_Learning_Entity-Level_Distributed_Representations","305388986_Enriching_Word_Vectors_with_Subword_Information","305341896_Learning_Global_Features_for_Coreference_Resolution","305334394_Capturing_Semantic_Similarity_for_Entity_Linking_with_Convolutional_Neural_Networks","305334391_Visualizing_and_Understanding_Neural_Models_in_NLP","304372682_End-to-end_attention-based_large_vocabulary_speech_recognition","303921830_Simple_Question_Answering_by_Attentive_Convolutional_Neural_Network","303840186_A_Decomposable_Attention_Model_for_Natural_Language_Inference","303681701_Learning_Natural_Language_Inference_using_Bidirectional_LSTM_model_and_Inner-Attention","303448270_TensorLog_A_Differentiable_Deductive_Database","284039049_Recursive_deep_models_for_semantic_compositionality_over_a_sentiment_treebank","281145060_Effective_Approaches_to_Attention-based_Neural_Machine_Translation","281144792_End-to-End_Attention-based_Large_Vocabulary_Speech_Recognition","281041692_Data_Matching","277959376_Visualizing_and_Understanding_Recurrent_Networks","273397652_Entity_Linking_with_a_Knowledge_Base_Issues_Techniques_and_Solutions","270878508_Parsing_with_Compositional_Vector_Grammars","266201822_Natural_Language_Processing_Almost_from_Scratch","265313581_Data_Curation_at_Scale_The_Data_Tamer_System","265252627_Neural_Machine_Translation_by_Jointly_Learning_to_Align_and_Translate","269935367_Deep_Metric_Learning_Using_Triplet_Network","269935079_Adam_A_Method_for_Stochastic_Optimization"]}