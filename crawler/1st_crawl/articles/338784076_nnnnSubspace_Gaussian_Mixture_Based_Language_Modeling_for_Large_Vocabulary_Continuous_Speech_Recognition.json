{"id":"338784076_nnnnSubspace_Gaussian_Mixture_Based_Language_Modeling_for_Large_Vocabulary_Continuous_Speech_Recognition","abstract":"This paper focuses on adaptable continuous space language modeling approach of combining longer context information of recurrent neural network (RNN) with adaptation ability of subspace Gaussian mixture model (SGMM) which has been widely used in acoustic modeling for automatic speech recognition (ASR).\nIn large vocabulary continuous speech recognition (LVCSR) it is a challenging problem to construct language models that can capture the longer context information of words and ensure generalization and adaptation ability. Recently, language modeling based on RNN and its variants have been broadly studied in this field.\nThe goal of our approach is to obtain the history feature vectors of a word with longer context information and model every word by subspace Gaussian mixture model such as Tandem system used in acoustic modeling for ASR. Also, it is to apply fMLLR adaptation method, which is widely used in SGMM based acoustic modeling, for adaptation of subspace Gaussian mixture based language model (SGMLM).\nAfter fMLLR adaptation, SGMLMs based on Top-Down and Bottom-Up obtain WERs of 5.70 % and 6.01%, which are better than 4.15% and 4.61% of that without adaptation, respectively. Also, with fMLLR adaptation, Top-Down and Bottom-Up based SGMLMs yield absolute word error rate reduction of 1.48%, 1.02% and a relative perplexity reduction of 10.02%, 6.46% compared to RNNLM without adaptation, respectively.","authors":["Ri Hyon Sun","Ri Jong Chol"],"meta":["February 2020Speech Communication 117(5)","DOI:10.1016/j.specom.2020.01.001"],"references":["228828379_The_Kaldi_speech_recognition_toolkit","228677164_Subspace_Gaussian_mixture_models_for_speech_recognition","224246503_Extensions_of_recurrent_neural_network_language_model","220733940_A_novel_estimation_of_feature-space_MLLR_for_full-covariance_models","220733781_Comparing_multilayer_perceptron_to_Deep_Belief_Network_Tandem_features_for_robust_ASR","220733078_Boosted_MMI_for_model_and_feature-space_discriminative_training","3333724_Robust_Decision_Tree_State_Tying_for_Continuous_Speech_Recognition","3192550_Weighted_Parzen_windows_for_pattern_classification","311469848_Recurrent_neural_network_based_language_model","288345724_Class-based_n-gram_models_of_natural_language","242101249_Tandem_connectionist_feature_extraction_for_conventional_HMM_systems","222577940_The_subspace_Gaussian_mixture_model-A_structured_model_for_speech_recognition","222496856_Algorithms_for_bigram_and_trigram_word_clustering","221486577_Feature_and_model_space_speaker_adaptation_with_full_covariance_Gaussians","220735724_Multilingual_Acoustic_Modeling_for_Speech_Recognition_based_on_Subspace_Gaussian_Mixture_Models","220629805_Random_Forests_and_the_Data_Sparseness_Problem_in_Language_Modeling","4249232_Gaussian_Mixture_Language_Models_for_Speech_Recognition","3175558_A_tree-based_statistical_language_model_for_natural_language_speech_recognition_IEEE_Trans_on_ASSP_ASSP-3771001-1008S"]}