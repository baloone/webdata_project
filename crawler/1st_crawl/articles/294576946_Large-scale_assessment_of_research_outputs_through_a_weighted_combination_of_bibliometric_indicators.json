{"id":"294576946_Large-scale_assessment_of_research_outputs_through_a_weighted_combination_of_bibliometric_indicators","abstract":"The paper describes a method to combine the information on the number of citations and the relevance of the publishing journal (as measured by the Impact Factor or similar impact indicators) of a publication to rank it with respect to the world scientific production in the specific subfield. The linear or non-linear combination of the two indicators is represented on the scatter plot of the papers in the specific subfield in order to immediately visualize the effect of a change in weights. The final rank of the papers is therefore obtained by partitioning the two-dimensional space through linear or higher order curves. The procedure is intuitive and versatile since it allows, after adjusting few parameters, an automatic and calibrated assessment at the level of the subfield. The derived evaluation is homogeneous among different scientific domains and can be used to address the quality of research at the departmental (or higher) levels of aggregation. We apply this method, that is designed to be feasible on a scale typical of a national evaluation exercise and to be effective in terms of cost and time, to some instances of the Thomson Reuters Web of Science database and discuss the results in view of what was done recently in Italy for the Evaluation of Research Quality exercise 2004â€“2010. We show how the main limitations of the bibliometric methodology used in that context can be easily overcome.","authors":["Alberto Anfossi","Alberto Ciolfi","Filippo Costa","Giorgio Parisi"],"meta":["February 2016Scientometrics 107(2)","DOI:10.1007/s11192-016-1882-9"],"references":["276487877_Evaluating_scientific_research_in_Italy_The_2004-10_research_evaluation_exercise","257649801_The_Assessment_of_Science_The_Relative_Merits_of_Post-Publication_Review_the_Impact_Factor_and_the_Number_of_Citations","250221944_Using_a_Balanced_Approach_to_Bibliometrics_Quantitative_Performance_Measures_in_the_Australian_Research_Quality_Framework","250198777_Peer_review_for_the_evaluation_of_academic_research_Lessons_from_the_Italian_experience","249750593_Out_With_the_Old_and_in_With_the_New_the_RAE_Bibliometrics_and_the_New_REF","244508246_The_correlation_between_RAE_ratings_and_citation_counts_in_psychology_Technical_Report","238706392_Peer_reviews_and_bibliometric_indicators_A_comparative_study_at_a_Norwegian_University","236921379_Impact_Factor_Distortions","220365069_Evaluating_research_From_informed_peer_review_to_bibliometrics","220364460_National_research_assessment_exercises_A_comparison_of_peer_review_and_bibliometrics_rankings","26326167_A_Principal_Component_Analysis_of_39_Scientific_Impact_Measures","24311585_Fersht_AThe_most_influential_journals_impact_factor_and_Eigenfactor_Proc_Natl_Acad_Sci_USA_1066883-4","24012694_New_developments_in_the_use_of_citation_analysis_in_research_evaluation","5444851_Comparison_of_SCImago_journal_rank_indicator_with_journal_impact_factor","289390207_DORA_San_Francisco_Declaration_on_Research_Assessment_May_2013","270767552_Bibliometric_Indicators_Why_Do_We_Need_More_Than_One","250199127_The_UK_Research_Assessment_Exercise_the_evolution_of_a_national_research_evaluation_system","250199042_Modifying_publication_practices_in_response_to_funding_formulas","247937355_Critical_review_of_the_application_of_citation_studies_to_the_Research_Assessment_Exercises","220065930_The_effect_of_scholar_collaboration_on_impact_and_quality_of_academic_papers","46430110_The_influence_of_author_self-citations_on_bibliometric_macro_indicators","28763656_The_correlation_between_RAE_ratings_and_citation_counts_in_psychology","28574894_The_Influence_of_Peer_Review_on_the_Research_Assessment_Exercise","23560491_Assessing_citations_with_the_Eigenfactor_TM_Metrics","14154390_Why_the_Impact_Factor_of_Journals_Should_Not_Be_Used_for_Evaluating_Research"]}