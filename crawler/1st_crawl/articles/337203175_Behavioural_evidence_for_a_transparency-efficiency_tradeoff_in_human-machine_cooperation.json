{"id":"337203175_Behavioural_evidence_for_a_transparency-efficiency_tradeoff_in_human-machine_cooperation","abstract":"Recent advances in artificial intelligence and deep learning have made it possible for bots to pass as humans, as is the case with the recent Google Duplex—an automated voice assistant capable of generating realistic speech that can fool humans into thinking they are talking to another human. Such technologies have drawn sharp criticism due to their ethical implications, and have fueled a push towards transparency in human–machine interactions. Despite the legitimacy of these concerns, it remains unclear whether bots would compromise their efficiency by disclosing their true nature. Here, we conduct a behavioural experiment with participants playing a repeated prisoner’s dilemma game with a human or a bot, after being given either true or false information about the nature of their associate. We find that bots do better than humans at inducing cooperation, but that disclosing their true nature negates this superior efficiency. Human participants do not recover from their prior bias against bots despite experiencing cooperative attitudes exhibited by bots over time. These results highlight the need to set standards for the efficiency cost we are willing to pay in order for machines to be transparent about their non-human nature. Algorithms and bots are capable of performing some behaviours at human or super-human levels. Humans, however, tend to trust algorithms less than they trust other humans. The authors find that bots do better than humans at inducing cooperation in certain human–machine interactions, but only if the bots do not disclose their true nature as artificial.","authors":["Fatimah Ishowo-Oloko","Jean-François Bonnefon","Zakariyah Soroye","Jacob Crandall"],"meta":["November 2019Nature Machine Intelligence 1(11):1-5","DOI:10.1038/s42256-019-0113-5"],"references":["315454825_Cooperating_with_Machines","308036045_Multinational_investigation_of_cross-societal_cooperation","285370842_Association_Between_Clinician_Computer_Use_and_Communication_With_Patients_in_Safety-Net_Clinics","334062374_Five_Rules_for_the_Evolution_of_Cooperation","323766095_The_Intuitive_Appeal_of_Explainable_Machines","322665816_Protecting_artificial_team-mates_more_seems_like_less","311672024_Accountability_in_algorithmic_decision-making","292076284_Accountability_in_algorithmic_decision_making","290210923_Intuition_deliberation_and_the_evolution_of_cooperation","286690845_The_scored_society_Due_process_for_automated_predictions","268449803_Algorithm_Aversion_People_Erroneously_Avoid_Algorithms_After_Seeing_Them_Err","273118658_The_Evolution_of_Cooperation","270016259_The_Evolution_of_Cooperation","269020931_Towards_Minimizing_Disappointment_in_Repeated_Games","268661605_Learning_to_Interact_with_a_Human_Partner"]}