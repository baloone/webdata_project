{"id":"329978116_ABCNN_Attention-Based_Convolutional_Neural_Network_for_Modeling_Sentence_Pairs","abstract":"How to model a pair of sentences is a critical issue in many NLP tasks such as answer selection (AS), paraphrase identification (PI) and textual entailment (TE). Most prior work (i) deals with one individual task by fine-tuning a specific system; (ii) models each sentence’s representation separately, rarely considering the impact of the other sentence; or (iii) relies fully on manually designed, task-specific linguistic features. This work presents a general Attention Based Convolutional Neural Network (ABCNN) for modeling a pair of sentences. We make three contributions. (i) The ABCNN can be applied to a wide variety of tasks that require modeling of sentence pairs. (ii) We propose three attention schemes that integrate mutual influence between sentences into CNNs; thus, the representation of each sentence takes into consideration its counterpart. These interdependent sentence pair representations are more powerful than isolated sentence representations. (iii) ABCNNs achieve state-of-the-art performance on AS, PI and TE tasks. We release code at: https://github.com/yinwenpeng/Answer_Selection .","authors":["Wenpeng Yin","Hinrich Schütze","Bing Xiang","Bowen Zhou"],"meta":["December 2016Transactions of the Association for Computational Linguistics 4(4):259-272","DOI:10.1162/tacl_a_00097"],"references":["308845461_The_application_of_two-level_attention_models_in_deep_convolutional_neural_network_for_fine-grained_image_classification","270283023_Signature_Verification_using_a_Siamese_Time_Delay_Neural_Network","264978373_UNAL-NLP_Combining_Soft_Cardinality_Features_for_Semantic_Textual_Similarity_Relatedness_and_Entailment","264003485_SemEval-2014_Task_1_Evaluation_of_Compositional_Distributional_Semantic_Models_on_Full_Sentences_through_Semantic_Relatedness_and_Textual_Entailment","262484733_A_SICK_cure_for_the_evaluation_of_compositional_distributional_semantic_models","221012718_What_is_the_Jeopardy_Model_A_Quasi-Synchronous_Grammar_for_QA","220817006_Discriminative_Learning_over_Constrained_Latent_Representations","220320677_Adaptive_Subgradient_Methods_for_Online_Learning_and_Stochastic_Optimization","13853244_Long_Short-term_Memory","325933705_ABC-CNN_An_attention_based_convolutional_neural_network_for_visual_question_answering","319770416_DRAW_A_Recurrent_Neural_Network_For_Image_Generation","319770369_Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality","311610308_Learning_Transferrable_Knowledge_for_Semantic_Segmentation_with_Deep_Convolutional_Neural_Network","304408489_Look_and_Think_Twice_Capturing_Top-Down_Visual_Attention_with_Feedback_Convolutional_Neural_Networks","301445967_Multi-Perspective_Sentence_Similarity_Modeling_with_Convolutional_Neural_Networks","301445887_WikiQA_A_Challenge_Dataset_for_Open-Domain_Question_Answering","301409028_ECNU_One_Stone_Two_Birds_Ensemble_of_Heterogenous_Measures_for_Semantic_Relatedness_and_Textual_Entailment","301408986_Illinois-LH_A_Denotational_and_Distributional_Approach_to_Semantics","301405437_Convolutional_Neural_Network_for_Paraphrase_Identification","301404932_MultiGranCNN_An_Architecture_for_General_Matching_of_Text_Chunks_on_Multiple_Levels_of_Granularity","270877996_Automatic_Coupling_of_Answer_Extraction_and_Information_Retrieval","270877716_Question_Answering_Using_Enhanced_Lexical_Semantic_Models","262352255_A_comparison_of_vector-based_representations_for_semantic_composition","262156969_Re-examining_Machine_Translation_Metrics_for_Paraphrase_Identification","224890821_ROUGE_A_Package_for_Automatic_Evaluation_of_summaries","222688606_COGEX_A_semantically_and_contextually_enriched_logic_prover_for_question_answering","221299987_Structured_retrieval_for_question_answering","221012812_Using_Semantic_Roles_to_Improve_Question_Answering","220816708_Tree_Edit_Models_for_Recognizing_Textual_Entailments_Paraphrases_and_Answers_to_Questions","200044309_WordNet_A_Lexical_Database_for_English"]}