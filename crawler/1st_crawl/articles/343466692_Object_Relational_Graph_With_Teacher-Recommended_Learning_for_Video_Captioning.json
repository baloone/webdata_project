{"id":"343466692_Object_Relational_Graph_With_Teacher-Recommended_Learning_for_Video_Captioning","authors":["Ziqi Zhang","Shi Yaya","Chunfeng Yuan","Bing Li"],"meta":["June 2020","DOI:10.1109/CVPR42600.2020.01329","Conference: 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"],"references":["339558750_Joint_Syntax_Representation_Learning_and_Visual_Cue_Translation_for_Video_Captioning","327389328_Cold_Fusion_Training_Seq2Seq_Models_Together_with_Language_Models","323571030_Less_Is_More_Picking_Informative_Frames_for_Video_Captioning","321325134_Can_Spatiotemporal_3D_CNNs_Retrace_the_History_of_2D_CNNs_and_ImageNet","321160935_Neural_Motifs_Scene_Graph_Parsing_with_Global_Context","319235902_Cold_Fusion_Training_Seq2Seq_Models_Together_with_Language_Models","317040382_The_Kinetics_Human_Action_Video_Dataset","273471465_On_Using_Monolingual_Corpora_in_Neural_Machine_Translation","273005574_Describing_Videos_by_Exploiting_Temporal_Structure","270878844_Meteor_Universal_Language_Specific_Translation_Evaluation_for_Any_Target_Language","269636281_Translating_Videos_to_Natural_Language_Using_Deep_Recurrent_Neural_Networks","268689555_CIDEr_Consensus-based_Image_Description_Evaluation","265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge","2588204_BLEU_a_Method_for_Automatic_Evaluation_of_Machine_Translation","339763732_SibNet_Sibling_Convolutional_Encoder_for_Video_Captioning","339558422_Relation-Aware_Graph_Attention_Network_for_Visual_Question_Answering","339555680_VaTeX_A_Large-Scale_High-Quality_Multilingual_Dataset_for_Video-and-Language_Research","339555496_Controllable_Video_Captioning_With_POS_Sequence_Guidance_Based_on_Gated_Fusion_Network","338513514_Object-Aware_Aggregation_With_Bidirectional_Temporal_Graph_for_Video_Captioning","338513223_Memory-Attended_Recurrent_Network_for_Video_Captioning","338509479_Spatio-Temporal_Dynamics_and_Semantic_Attribute_Enriched_Visual_Encoding_for_Video_Captioning","338508238_Auto-Encoding_Scene_Graphs_for_Image_Captioning","337775128_Context-Aware_Visual_Policy_Network_for_Fine-Grained_Image_Captioning","336710487_Hierarchical_Global-Local_Temporal_Modeling_for_Video_Captioning","335829360_Learn_Spelling_from_Teachers_Transferring_Knowledge_from_Language_Models_to_Sequence-to-Sequence_Speech_Recognition","335323689_Motion_Guided_Spatial_Attention_for_Video_Captioning","329747669_M3_Multimodal_Memory_Modelling_for_Video_Captioning","329747467_Reconstruction_Network_for_Video_Captioning","329743941_Bidirectional_Attentive_Fusion_with_Context_Gating_for_Dense_Video_Captioning","328157217_Less_Is_More_Picking_Informative_Frames_for_Video_Captioning_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Part_XIII","327808311_An_Analysis_of_Incorporating_an_External_Language_Model_into_a_Sequence-to-Sequence_Model","321210786_Non-local_Neural_Networks","320727381_Graph_Attention_Networks","320541263_Catching_the_Temporal_Regions-of-Interest_for_Video_Captioning","311610992_Hierarchical_Recurrent_Neural_Encoder_for_Video_Representation_with_Application_to_Captioning","311610608_Video_Paragraph_Captioning_Using_Hierarchical_Recurrent_Neural_Networks","310441005_Aggregated_Residual_Transformations_for_Deep_Neural_Networks","307991731_Semi-Supervised_Classification_with_Graph_Convolutional_Networks","307283619_MSR-VTT_A_Large_Video_Description_Dataset_for_Bridging_Video_and_Language","301874967_Inception-v4_Inception-ResNet_and_the_Impact_of_Residual_Connections_on_Learning","276149387_Jointly_Modeling_Embedding_and_Translation_to_Bridge_Video_and_Language","275897170_Sequence_to_Sequence_--_Video_to_Text","269935079_Adam_A_Method_for_Stochastic_Optimization","224890821_ROUGE_A_Package_for_Automatic_Evaluation_of_summaries","220874980_Collecting_Highly_Parallel_Data_for_Paraphrase_Evaluation"]}