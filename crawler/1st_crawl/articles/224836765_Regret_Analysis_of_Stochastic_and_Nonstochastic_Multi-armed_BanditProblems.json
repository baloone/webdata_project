{"id":"224836765_Regret_Analysis_of_Stochastic_and_Nonstochastic_Multi-armed_BanditProblems","abstract":"Multi-armed bandit problems are the most basic examples of sequential\ndecision problems with an exploration-exploitation trade-off. This is the\nbalance between staying with the option that gave highest payoffs in the past\nand exploring new options that might give higher payoffs in the future.\nAlthough the study of bandit problems dates back to the Thirties,\nexploration-exploitation trade-offs arise in several modern applications, such\nas ad placement, website optimization, and packet routing. Mathematically, a\nmulti-armed bandit is defined by the payoff process associated with each\noption. In this survey, we focus on two extreme cases in which the analysis of\nregret is particularly simple and elegant: i.i.d. payoffs and adversarial\npayoffs. Besides the basic setting of finitely many actions, we also analyze\nsome of the most important variants and extensions, such as the contextual\nbandit model.","authors":["Sébastien Bubeck","Nicolò Cesa-Bianchi"],"meta":["April 2012Foundations and Trends® in Machine Learning 5(1)","DOI:10.1561/2200000024","SourcearXiv"],"references":["279900356_Online_Optimization_in_X-Armed_Bandits","268402704_Finite-Time_Analysis_of_Stratified_Sampling_for_Monte_Carlo","267429724_PAC-Bayesian_Analysis_of_Contextual_Bandits","247932412_The_Multiplicative_Weights_Update_Method_a_Meta_Algorithm_and_Applications","238836142_Optimal_Adaptive_Policies_for_Markov_Decision_Processes","238378872_Modification_of_UCT_with_Patterns_in_Monte-Carlo_Go","236736773_Non-Asymptotic_Analysis_of_Stochastic_Approximation_Algorithms_for_Machine_Learning","234802435_Introduction_to_derivative-free_optimization_MPS-SIAM_series_on_Optimization","234061317_Multi-Bandit_Best_Arm_Identification","231582510_Kullback-Leibler_Upper_Confidence_Bounds_for_Optimal_Sequential_Allocation","230627940_Improved_Algorithms_for_Linear_Stochastic_Bandits_extended_version","229024205_X-Armed_Bandits","228699264_Robust_Stochastic_Approximation_Approach_to_Stochastic_Programming","228460778_10_The_Convex_Optimization_Approach_to_Regret_Minimization","228095602_Online_Bandit_Learning_against_an_Adaptive_Adversary_from_Regret_toPolicy_Regret","226782689_Multi-Armed_Bandit_Problems","225191529_Recursive_Aggregation_of_Estimators_by_Mirror_Descent_Algorithm_with_Averaging","225106340_Active_Learning_in_Multi-armed_Bandits","321330277_The_Price_of_Bandit_Information_for_Online_Optimization","313611092_The_epoch-greedy_algorithm_for_contextual_multi-armed_bandits","313606782_Nearly_tight_bounds_for_the_continuum-armed_bandit_problem","313606558_Parametric_bandits_The_generalized_linear_case","298876907_The_nonstochastic_multiarmed_bandit_problem","290676002_NEWTRON_An_efficient_bandit_algorithm_for_online_multiclass_prediction","290288101_Improved_Second-Order_Bounds_for_Prediction_with_Expert_Advice","281530900_Incomplete_information_and_internal_regret_in_prediction_of_individual_sequences","280792286_Bandits_Games_and_Clustering_Foundations","278691337_Fundamentals_of_Convex_Analysis","273002355_Convex_Optimization","266529330_An_Empirical_Evaluation_of_Thompson_Sampling","266231173_Committing_Bandits","265458837_An_elementary_introduction_to_modern_convex_geometry","258727169_Bandits_With_Heavy_Tail","245581594_Bayes_and_Minimax_Solutions_of_Sequential_Decision_Problems","243772635_On_the_Sample_Complexity_of_Reinforcement_Learning","242580265_Approximation_to_Bayes_risk_in_repeated_play","239292007_Asymptotically_efficient_adaptive_allocation_rules1","236736847_Problem_complexity_and_method_efficiency_in_optimization","236736791_A_Stochastic_Approximation_Method","232502820_Regret_Bounds_for_Restless_Markov_Bandits","229024479_General_Convergence_Results_for_Linear_Discriminant_Updates","228759096_Random_gradient-free_minimization_of_convex_functions","226908641_UCB_revisited_Improved_regret_bounds_for_the_stochastic_multi-armed_bandit_problem","226793652_Relative_Loss_Bounds_for_Multidimensional_Regression_Problems","225176417_PAC_Bounds_for_Multi-armed_Bandit_and_Markov_Decision_Processes","224983695_Thompson_Sampling_An_Asymptotically_Optimal_Finite_Time_Analysis","224959372_Multiple_Identifications_in_Multi-Armed_Bandits","224493575_Beating_the_Adaptive_Bandit_with_High_Probability","224471879_Regret_and_Convergence_Bounds_for_a_Class_of_Continuum-Armed_Bandit_Problems","222872547_Mirror_descent_and_nonlinear_projected_subgradient_methods_for_convex_optimization","222556058_A_General_Class_of_Adaptive_Strategies","222523650_Pure_exploration_in_finitely-armed_and_continuous-armed_bandits","222401036_Arbitrary_side_observations_in_bandit_problems","222302500_Efficient_Algorithms_for_Online_Decision_Problems","221665493_The_best_of_both_worlds_Stochastic_and_adversarial_bandits"]}