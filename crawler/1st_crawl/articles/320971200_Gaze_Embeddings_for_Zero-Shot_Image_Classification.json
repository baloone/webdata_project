{"id":"320971200_Gaze_Embeddings_for_Zero-Shot_Image_Classification","authors":["Nour Karessli","Zeynep Akata","Bernt Schiele","Andreas Bulling"],"meta":["July 2017","DOI:10.1109/CVPR.2017.679","Conference: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"],"references":["312023646_ScreenGlint_Practical_In-situ_Gaze_Estimation_on_Smartphones","305196650_Going_deeper_with_convolutions","303332633_Learning_Deep_Representations_of_Fine-grained_Visual_Descriptions","301878974_Latent_Embeddings_for_Zero-shot_Classification","289035243_Eye_tracking_assisted_extraction_of_attentionally_important_objects_from_videos","284576917_Glove_Global_Vectors_for_Word_Representation","275011966_Evaluation_of_Output_Embeddings_for_Fine-Grained_Image_Classification","274319657_Label-Embedding_for_Image_Classification","272521882_Prediction_of_Search_Targets_From_Fixations_in_Open-World_Settings","269040942_Multiple_Instance_Reinforcement_Learning_for_Efficient_Weakly-Supervised_Detection_in_Images","263091517_The_Secrets_of_Salient_Object_Segmentation","261524983_Label-Embedding_for_Attribute-Based_Classification","261479310_Studying_Relationships_Between_Human_Gaze_Description_and_Computer_Vision","259609791_From_Where_and_How_to_What_We_See","257882504_Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality","234131208_Zero-Shot_Learning_Through_Cross-Modal_Transfer","224254911_Evaluating_knowledge_transfer_and_zero-shot_learning_in_a_large-scale_setting","224135964_Attribute_and_Simile_Classifiers_for_Face_Verification","221364579_Recognizing_human_actions_by_attributes","221111453_Sparse_Dictionary-based_Representation_and_Recognition_of_Action_Attributes","221111179_Relative_attributes","220811146_Identifying_fixations_and_saccades_in_eye-tracking_protocols","220320388_Large_Margin_Methods_for_Structured_and_Interdependent_Output_Variables","46572499_Caltech-UCSD_Birds_200","15630111_Pupil_Dilation_as_a_Measure_of_Processing_Load_in_Simultaneous_Interpretation_and_Other_Language_Tasks","4082302_Is_bottom-up_attention_useful_for_object_recognition","313534687_Active_segmentation_with_fixation","311613031_Learning_Deep_Representations_of_Fine-Grained_Visual_Descriptions","311609768_Latent_Embeddings_for_Zero-Shot_Classification","310439564_Describing_objects_by_their_attributes","306285617_Seeing_with_Humans_Gaze-Assisted_Neural_Image_Captioning","279156222_Leveraging_the_Wisdom_of_the_Crowd_for_Fine-Grained_Recognition","278712418_Training_Object_Class_Detectors_from_Eye_Tracking_Data","262361687_Pictorial_Human_Spaces_How_Well_Do_Humans_Perceive_a_3D_Articulated_Pose","261227383_Fine-Grained_Crowdsourcing_for_Fine-Grained_Recognition","261121789_Cats_and_dogs","259882033_Attribute-Based_Classification_for_Zero-Shot_Visual_Object_Categorization","232650517_Describing_objects_by_their_attributes","225189851_A_Discriminative_Latent_Model_of_Object_Classes_and_Attributes","224254733_Image_Ranking_and_Retrieval_based_on_Multi-Attribute_Queries","224135936_Joint_learning_of_visual_attributes_object_classes_and_visual_saliency","221571659_Can_computers_learn_from_humans_to_see_better_Inferring_scene_semantics_from_viewers'_eye_movements","221551861_Automated_Flower_Classification_over_a_Large_Number_of_Classes","221362408_Comparing_data-dependent_and_data-independent_embeddings_for_classification_and_ranking_of_Internet_images","221111619_Human_action_recognition_by_learning_bases_of_action_attributes_and_parts","221109992_Learning_to_Predict_Where_Humans_Look","200044309_WordNet_A_Lexical_Database_for_English","29642269_Learning_saliency_maps_for_object_categorization"]}