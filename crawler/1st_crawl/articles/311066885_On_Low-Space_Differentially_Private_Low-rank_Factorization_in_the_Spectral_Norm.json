{"id":"311066885_On_Low-Space_Differentially_Private_Low-rank_Factorization_in_the_Spectral_Norm","abstract":"Low-rank factorization is used in many areas of computer science where one performs spectral analysis on large sensitive data stored in the form of matrices. In this paper, we study differentially private low-rank factorization of a matrix with respect to the spectral norm in the turnstile update model. In this problem, given an input matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ updated in the turnstile manner and a target rank $k$, the goal is to find two rank-$k$ orthogonal matrices $\\mathbf{U}_k \\in \\mathbb{R}^{m \\times k}$ and $\\mathbf{V}_k \\in \\mathbb{R}^{n \\times k}$, and one positive semidefinite diagonal matrix $\\textbf{\\Sigma}_k \\in \\mathbb{R}^{k \\times k}$ such that $\\mathbf{A} \\approx \\mathbf{U}_k \\textbf{\\Sigma}_k \\mathbf{V}_k^\\mathsf{T}$ with respect to the spectral norm. Our main contributions are two computationally efficient and sub-linear space algorithms for computing a differentially private low-rank factorization. We consider two levels of privacy. In the first level of privacy, we consider two matrices neighboring if their difference has a Frobenius norm at most $1$. In the second level of privacy, we consider two matrices as neighboring if their difference can be represented as an outer product of two unit vectors. Both these privacy levels are stronger than those studied in the earlier papers such as Dwork {\\it et al.} (STOC 2014), Hardt and Roth (STOC 2013), and Hardt and Price (NIPS 2014). As a corollary to our results, we get non-private algorithms that compute low-rank factorization in the turnstile update model with respect to the spectral norm. We note that, prior to this work, no algorithm that outputs low-rank factorization with respect to the spectral norm in the turnstile update model was known; i.e., our algorithm gives the first non-private low-rank factorization with respect to the spectral norm in the turnstile update mode.","authors":["Jalaj Upadhyay"],"meta":["November 2016","Project: Low rank approximation"],"references":["342165324_Clustering_Large_Graphs_via_the_Singular_Value_Decomposition","301880570_Fast_and_Space-optimal_Low-rank_Factorization_in_the_Streaming_Model_With_Application_in_Differential_Privacy","301840852_Extensions_of_Lipschitz_mappings_into_a_Hilbert_space","323371798_Calibrating_Noise_to_Sensitivity_in_Private_Data_Analysis","312077467_Low-Rank_PSD_Approximation_in_Input-Sparsity_Time","310826772_Competitive_recommendation_systems","308061191_The_Algorithmic_Foundations_of_Differential_Privacy","303901394_Optimal_principal_component_analysis_in_distributed_and_streaming_models","287283345_Analyze_Gauss_Optimal_bounds_for_privacy-preserving_principal_component_analysis","286961370_On_differentially_private_low_rank_approximation"]}