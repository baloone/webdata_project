{"id":"317173612_Prediction_of_visual_attention_with_deep_CNN_on_artificially_degraded_videos_for_studies_of_attention_of_patients_with_Dementia","abstract":"Studies of visual attention of patients with Dementia such as Parkinson’s Disease Dementia and Alzheimer Disease is a promising way for non-invasive diagnostics. Past research showed, that people suffering from dementia are not reactive with regard to degradations on still images. Attempts are being made to study their visual attention relatively to the video content. Here the delays in their reactions on novelty and “unusual” novelty of the visual scene are expected. Nevertheless, large-scale screening of population is possible only if sufficiently robust automatic prediction models can be built. In the medical protocols the detection of Dementia behavior in visual content observation is always performed in comparison with healthy, “normal control” subjects. Hence, it is a research question per see as to develop an automatic prediction models for specific visual content to use in psycho-visual experience involving Patients with Dementia (PwD). The difficulty of such a prediction resides in a very small amount of training data. In this paper the reaction of healthy normal control subjects on degraded areas in videos was studied. Furthermore, in order to build an automatic prediction model for salient areas in intentionally degraded videos for PwD studies, a deep learning architecture was designed. Optimal transfer learning strategy for training the model in case of very small amount of training data was deployed. The comparison with gaze fixation maps and classical visual attention prediction models was performed. Results are interesting regarding the reaction of normal control subjects against degraded areas in videos.","authors":["Souad Chaabouni","Jenny Benois-Pineau","François Tison","Chokri Ben Amar"],"meta":["November 2017Multimedia Tools and Applications 76(1):1-20","DOI:10.1007/s11042-017-4796-5","Project: Study and prediction of visual attention with deep learning with a view to  evaluation of patients with neurodegenerative diseases"],"references":["311610824_Saliency_Unified_A_Deep_Architecture_for_simultaneous_Eye_Fixation_Prediction_and_Salient_Object_Segmentation","301817599_Deep_Learning_for_Saliency_Prediction_in_Natural_Video","279864363_End-to-end_Convolutional_Network_for_Saliency_Prediction","345236556_Prediction_of_visual_saliency_in_video_with_deep_CNNs","319770381_How_transferable_are_features_in_deep_neural_networks","311610990_Shallow_and_Deep_Convolutional_Networks_for_Saliency_Prediction","307516184_Transfer_learning_with_deep_networks_for_saliency_prediction_in_natural_video","304664839_Prediction_of_visual_attention_with_Deep_CNN_for_studies_of_neurodegenerative_diseases","294857708_IEEE_Computer_Society_Conference_on_Computer_Vision_and_Pattern_Recognition","286108249_Large-Scale_Optimization_of_Hierarchical_Features_for_Saliency_Prediction_in_Natural_Images","268079628_How_transferable_are_features_in_deep_neural_networks","267811743_Deep_Gaze_I_Boosting_Saliency_Prediction_with_Feature_Maps_Trained_on_ImageNet","264979485_Caffe_Convolutional_Architecture_for_Fast_Feature_Embedding","262367634_Fusion_of_Multiple_Visual_Cues_for_Visual_Saliency_Extraction_from_Wearable_Camera_Settings_with_Strong_Motion","262053409_Learning_to_predict_eye_fixations_for_semantic_contents_using_multi-layer_sparse_network"]}