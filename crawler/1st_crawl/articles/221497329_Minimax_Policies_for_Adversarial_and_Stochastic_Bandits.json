{"id":"221497329_Minimax_Policies_for_Adversarial_and_Stochastic_Bandits","abstract":"We fill in a long open gap in the characterization of the minimax rate for the multi-armed bandit prob- lem. Concretely, we remove an extraneous loga- rithmic factor in the previously known upper bound and propose a new family of randomized algorithms based on an implicit normalization, as well as a new analysis. We also consider the stochastic case, and prove that an appropriate modification of the upper confidence bound policy UCB1 (Auer et al., 2002) achieves the distribution-free optimal rate while still having a distribution-dependent rate log- arithmic in the number of plays.","authors":["Jean-Yves Audibert","SÃ©bastien Bubeck"],"meta":["June 2009","SourceDBLP","Conference: COLT 2009 - The 22nd Conference on Learning Theory, Montreal, Quebec, Canada, June 18-21, 2009"],"references":[]}