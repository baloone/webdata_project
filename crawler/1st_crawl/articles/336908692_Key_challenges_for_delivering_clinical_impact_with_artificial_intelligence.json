{"id":"336908692_Key_challenges_for_delivering_clinical_impact_with_artificial_intelligence","abstract":"Background: \nArtificial intelligence (AI) research in healthcare is accelerating rapidly, with potential applications being demonstrated across various domains of medicine. However, there are currently limited examples of such techniques being successfully deployed into clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice.\n\nMain body: \nKey challenges for the translation of AI systems in healthcare include those intrinsic to the science of machine learning, logistical difficulties in implementation, and consideration of the barriers to adoption as well as of the necessary sociocultural or pathway changes. Robust peer-reviewed clinical evaluation as part of randomised controlled trials should be viewed as the gold standard for evidence generation, but conducting these in practice may not always be appropriate or feasible. Performance metrics should aim to capture real clinical applicability and be understandable to intended users. Regulation that balances the pace of innovation with the potential for harm, alongside thoughtful post-market surveillance, is required to ensure that patients are not exposed to dangerous interventions nor deprived of access to beneficial innovations. Mechanisms to enable direct comparisons of AI systems must be developed, including the use of independent, local and representative test sets. Developers of AI algorithms must be vigilant to potential dangers, including dataset shift, accidental fitting of confounders, unintended discriminatory bias, the challenges of generalisation to new populations, and the unintended negative consequences of new algorithms on health outcomes.\n\nConclusion: \nThe safe and timely translation of AI research into clinically validated and appropriately regulated systems that can benefit everyone is challenging. Robust clinical evaluation, using metrics that are intuitive to clinicians and ideally go beyond measures of technical accuracy to include quality of care and patient outcomes, is essential. Further work is required (1) to identify themes of algorithmic bias and unfairness while developing mitigations to address these, (2) to reduce brittleness and improve generalisability, and (3) to develop methods for improved interpretability of machine learning predictions. If these goals can be achieved, the benefits for patients are likely to be transformational.","authors":["Christopher J Kelly","Alan Karthikesalingam","Mustafa Suleyman","Greg Corrado"],"meta":["December 2019BMC Medicine 17(1)","DOI:10.1186/s12916-019-1426-2"],"references":["336339974_Deep_Neural_Networks_Improve_Radiologists'_Performance_in_Breast_Cancer_Screening","334816064_A_Clinically_Applicable_Approach_to_Continuous_Prediction_of_Future_Acute_Kidney_Injury","333657502_Reply_to_the_letter_to_the_editor_'Man_against_machine_diagnostic_performance_of_a_deep_learning_convolutional_neural_network_for_dermoscopic_melanoma_recognition_in_comparison_to_58_dermatologists'_b","332762107_Deep_learning_predicts_hip_fracture_using_confounding_patient_and_healthcare_variables","332728777_Artificial_Intelligence_using_Deep_Learning_to_Screen_for_Referable_and_Vision-threatening_Diabetic_Retinopathy_in_Africa_a_Clinical_Validation_Study","356086647_Why_is_my_classifier_discriminatory","335176729_Association_Between_Surgical_Skin_Markings_in_Dermoscopic_Images_and_Diagnostic_Performance_of_a_Deep_Learning_Convolutional_Neural_Network_for_Melanoma_Recognition","335100120_A_nonparametric_updating_method_to_correct_clinical_prediction_model_drift","335077351_Making_Machine_Learning_Models_Clinically_Useful","334854304_An_artificial_intelligence-enabled_ECG_algorithm_for_the_identification_of_patients_with_atrial_fibrillation_during_sinus_rhythm_a_retrospective_analysis_of_outcome_prediction"]}