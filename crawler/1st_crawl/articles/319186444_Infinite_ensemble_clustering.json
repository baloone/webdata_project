{"id":"319186444_Infinite_ensemble_clustering","abstract":"Ensemble clustering aims to fuse several diverse basic partitions into a consensus one, which has been widely recognized as a promising tool to discover novel clusters and deliver robust partitions, while representation learning with deep structure shows appealing performance in unsupervised feature pre-treatment. In the literature, it has been empirically found that with the increasing number of basic partitions, ensemble clustering gets better performance and lower variances, yet the best number of basic partitions for a given data set is a pending problem. In light of this, we propose the Infinite Ensemble Clustering (IEC), which incorporates marginalized denoising auto-encoder with dropout noises to generate the expectation representation for infinite basic partitions. Generally speaking, a set of basic partitions is firstly generated from the data. Then by converting the basic partitions to the 1-of-K codings, we link the marginalized denoising auto-encoder to the infinite basic partition representation. Finally, we follow the layer-wise training procedure and feed the concatenated deep features to K-means for final clustering. According to different types of marginalized auto-encoders, the linear and non-linear versions of IEC are proposed. Extensive experiments on diverse vision data sets with different levels of visual descriptors demonstrate the superior performance of IEC compared to the state-of-the-art ensemble clustering and deep clustering methods. Moreover, we evaluate the performance of IEC in the application of pan-omics gene expression analysis application via survival analysis.","authors":["Hongfu Liu","Ming Shao","Sheng Li","Yun Fu"],"meta":["March 2018Data Mining and Knowledge Discovery 32(1):1-32","DOI:10.1007/s10618-017-0539-5"],"references":["310579244_Robust_Spectral_Ensemble_Clustering","308854188_Hashing_with_binary_autoencoders","345898706_A_Novel_Clustering_Method_for_Patient_Stratification","339506576_Learning_Deep_Architectures_for_AI","328594099_Deep_Transfer_Low-Rank_Coding_for_Cross-Domain_Learning","319770199_Marginalized_Denoising_Auto-encoders_for_Nonlinear_Representations","313751326_Simultaneous_Clustering_and_Ensemble","312830651_Efficient_Feature_Coding_Based_on_Auto-encoder_Network_for_Image_Classification","312185761_Spectral_Ensemble_Clustering_via_Weighted_K-Means_Theoretical_and_Practical_Evidence","310825021_Infinite_Ensemble_for_Image_Clustering","303137904_Greedy_layer-wise_training_of_deep_networks","299647625_Transcriptomics_resources_of_human_tissues_and_organs","301668721_Big_data_visualization_identifies_the_multidimensional_molecular_landscape_of_human_gliomas","300153095_DIAS_A_Disassemble-Assemble_Framework_for_Highly_Sparse_Text_Clustering","299970583_Spectral_Ensemble_Clustering"]}