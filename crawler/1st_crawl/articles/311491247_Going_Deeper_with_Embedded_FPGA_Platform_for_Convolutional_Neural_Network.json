{"id":"311491247_Going_Deeper_with_Embedded_FPGA_Platform_for_Convolutional_Neural_Network","abstract":"In recent years, convolutional neural network (CNN) based methods have achieved great success in a large number of applications and have been among the most powerful and widely used techniques in computer vision. However, CNN-based methods are com-putational-intensive and resource-consuming, and thus are hard to be integrated into embedded systems such as smart phones, smart glasses, and robots. FPGA is one of the most promising platforms for accelerating CNN, but the limited bandwidth and on-chip memory size limit the performance of FPGA accelerator for CNN.\nIn this paper, we go deeper with the embedded FPGA platform on accelerating CNNs and propose a CNN accelerator design on embedded FPGA for Image-Net large-scale image classification. We first present an in-depth analysis of state-of-the-art CNN models and show that Convolutional layers are computational-centric and Fully-Connected layers are memory-centric.\nThen the dynamic-precision data quantization method and a convolver design that is efficient for all layer types in CNN are proposed to improve the bandwidth and resource utilization. Results show that only 0.4% accuracy loss is introduced by our data quantization flow for the very deep VGG16 model when 8/4-bit quantization is used. A data arrangement method is proposed to further ensure a high utilization of the external memory bandwidth. Finally, a state-of-the-art CNN, VGG16-SVD, is implemented on an embedded FPGA platform as a case study. VGG16-SVD is the largest and most accurate network that has been implemented on FPGA end-to-end so far. The system on Xilinx Zynq ZC706 board achieves a frame rate at 4.45 fps with the top-5 accuracy of 86.66% using 16-bit quantization. The average performance of convolutional layers and the full CNN is 187.8 GOP/s and 137.0 GOP/s under 150MHz working frequency, which outperform previous approaches significantly.","authors":["Jiantao Qiu","Sen Song","Yu Wang","Huazhong Yang"],"meta":["February 2016","DOI:10.1145/2847263.2847265","Conference: the 2016 ACM/SIGDA International Symposium"],"references":["311100814_Comparing_Biases_for_Minimal_Network_Construction_with_Back-Propagation","305196650_Going_deeper_with_convolutions","265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge","264979485_Caffe_Convolutional_Architecture_for_Fast_Feature_Embedding","261368736_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation","261100864_CNN_Features_Off-the-Shelf_An_Astounding_Baseline_for_Recognition","221619185_Comparing_Biases_for_Minimal_Network_Construction_with_Back-Propagation","216792707_CNP_An_FPGA-based_processor_for_Convolutional_Networks","216792688_NeuFlow_A_Runtime-Reconfigurable_Dataflow_Processor_for_Vision","216792683_Large-Scale_FPGA-based_Convolutional_Networks","3336900_Reconfigurable_pipelined_2-D_convolvers_for_fast_digital_signal_processing","2985446_Gradient-Based_Learning_Applied_to_Document_Recognition","2501411_Second_Order_Derivatives_for_Network_Pruning_Optimal_Brain_Surgeon","346345558_DianNao_a_small-footprint_high-throughput_accelerator_for_ubiquitous_machine-learning","319770367_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","319770146_Second_Order_Derivatives_for_Network_Pruning_Optimal_Brain_Surgeon","313601183_Optimal_brain_damage_in","312727767_Going_deeper_with_convolutions","312448985_DaDianNao_A_machine-learning_supercomputer","312446405_Optimizing_fpgabased_accelerator_design_for_deep_convolutional_neural_networks","311609041_Deep_Residual_Learning_for_Image_Recognition","310752533_Visualizing_and_understanding_convolutional_networks","308867995_Efficient_and_accurate_approximations_of_nonlinear_convolutional_networks","301367952_Optimizing_FPGA-based_Accelerator_Design_for_Deep_Convolutional_Neural_Networks","286512696_Deep_Residual_Learning_for_Image_Recognition","283024298_DaDianNao_A_Machine-Learning_Supercomputer","280082402_ShiDianNao_shifting_vision_processing_closer_to_the_sensor","277959043_Learning_both_Weights_and_Connections_for_Efficient_Neural_Networks","277896547_PuDianNao_A_Polyvalent_Machine_Learning_Accelerator","268451925_Efficient_and_Accurate_Approximations_of_Nonlinear_Convolutional_Networks","267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks","265385906_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition","265122528_A_240_G-opss_Mobile_Coprocessor_for_Deep_Neural_Networks","262380602_Speeding_up_Convolutional_Neural_Networks_with_Low_Rank_Expansions","261845797_DianNao_A_Small-Footprint_High-Throughput_Accelerator_for_Ubiquitous_Machine-Learning","258424423_Visualizing_and_Understanding_Convolutional_Neural_Networks","221130850_A_Massively_Parallel_Coprocessor_for_Convolutional_Neural_Networks","220771018_A_dynamically_configurable_coprocessor_for_convolutional_neural_networks","29651784_Towards_Hardware_Acceleration_of_Neuroevolution_for_Multimedia_Processing_Applications_on_Mobile_Devices"]}