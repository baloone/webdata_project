{"id":"310329157_Exploration_A_Study_of_Count-Based_Exploration_for_Deep_Reinforcement_Learning","abstract":"Count-based exploration algorithms are known to perform near-optimally when used in conjunction with tabular reinforcement learning (RL) methods for solving small discrete Markov decision processes (MDPs). It is generally thought that count-based methods cannot be applied in high-dimensional state spaces, since most states will only occur once. Recent deep RL exploration strategies are able to deal with high-dimensional continuous state spaces through complex heuristics, often relying on optimism in the face of uncertainty or intrinsic motivation. In this work, we describe a surprising finding: a simple generalization of the classic count-based approach can reach near state-of-the-art performance on various high-dimensional and/or continuous deep RL benchmarks. States are mapped to hash codes, which allows to count their occurrences with a hash table. These counts are then used to compute a reward bonus according to the classic count-based exploration theory. We find that simple hash functions can achieve surprisingly good results on many challenging tasks. Furthermore, we show that a domain-dependent learned hash code may further improve these results. Detailed analysis reveals important aspects of a good hash function: 1) having appropriate granularity and 2) encoding information relevant to solving the MDP. This exploration strategy achieves near state-of-the-art performance on both continuous control tasks and Atari 2600 games, hence providing a simple yet powerful baseline for solving MDPs that require considerable exploration.","authors":["Haoran Tang","Rein Houthooft","Davis Foote","Adam Stooke"],"meta":["November 2016"],"references":["303822096_Unifying_Count-Based_Exploration_and_Intrinsic_Motivation","303698546_VIME_Variational_Information_Maximizing_Exploration","301845990_Exploratory_Gradient_Boosting_for_Reinforcement_Learning_in_Complex_Domains","319770820_Histograms_of_Oriented_Gradients_for_Human_Detection","319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition","319769991_Trust_Region_Policy_Optimization","303993105_Strategic_Attentive_Writer_for_Learning_Macro-Actions","301874314_Pixel_Recurrent_Neural_Networks","301846299_Deep_Exploration_via_Bootstrapped_DQN","301843033_Learning_functions_across_many_orders_of_magnitudes"]}