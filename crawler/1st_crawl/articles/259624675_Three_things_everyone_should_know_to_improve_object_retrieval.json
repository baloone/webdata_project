{"id":"259624675_Three_things_everyone_should_know_to_improve_object_retrieval","abstract":"The objective of this work is object retrieval in large scale image datasets, where the object is specified by an image query and retrieval should be immediate at run time in the manner of Video Google [28]. We make the following three contributions: (i) a new method to compare SIFT descriptors (RootSIFT) which yields superior performance without increasing processing or storage requirements; (ii) a novel method for query expansion where a richer model for the query is learnt discriminatively in a form suited to immediate retrieval through efficient use of the inverted index; (iii) an improvement of the image augmentation method proposed by Turcot and Lowe [29], where only the augmenting features which are spatially consistent with the augmented image are kept. We evaluate these three methods over a number of standard benchmark datasets (Oxford Buildings 5k and 105k, and Paris 6k) and demonstrate substantial improvements in retrieval performance whilst maintaining immediate retrieval speeds. Combining these complementary methods achieves a new state-of-the-art performance on these datasets.","authors":["R. Arandjelovic"],"meta":["June 2012Proceedings / CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE Computer Society Conference on Computer Vision and Pattern Recognition","DOI:10.1109/CVPR.2012.6248018","Conference: IEEE Conference on Computer Vision and Pattern Recognition"],"references":["317083797_Hamming_Embedding_and_Weak_Geometric_Consistency_for_Large_Scale_Image_Search","280851624_Asymmetric_Hamming_Embedding","232629068_Picking_the_best_DAISY","226549772_Learning_a_Fine_Vocabulary","224254894_Total_recall_II_Query_expansion_revisited","224254761_Hello_Neighbor_Accurate_Object_Retrieval_with_k-Reciprocal_Nearest_Neighbors","224164326_Aggregating_local_descriptors_into_a_compact_image_representation","221573487_Asymmetric_hamming_embedding_taking_the_best_of_our_bits_for_large_scale_image_search","221362657_Large-scale_image_categorization_with_explicit_data_embedding","221361531_E-cient_representation_of_local_geometry_for_large_scale_object_retrieval","221304796_Avoiding_Confusing_Features_in_Place_Recognition","221304451_The_Quadratic-Chi_Histogram_Distance_Family","221110190_Object_Categorization_by_Learned_Universal_Visual_Dictionary","215721498_Scale_Affine_Invariant_Interest_Point_Detectors","50403541_Improving_Bag-of-Features_for_Large_Scale_Image_Search","48411499_On_the_burstiness_of_visual_elements","319770255_Hamming_embedding_and_weak_geometric_consistency_for_large_scale_image_search","307881957_LIBSVM_A_library_for_support_vector_machines","232614544_Efficient_representation_of_local_geometry_for_large_scale_object_retrieval","228715647_LIBSVM_A_library_for_support_vector_machines","224744237_Video_Google_A_Text_Retrieval_Approach_to_Object_Matching_in_Videos","224323294_Lost_in_Quantization_Improving_Particular_Object_Retrieval_in_Large_Scale_Image_Databases","224135238_Better_matching_with_fewer_features_The_selection_of_useful_features_in_large_database_recognition_problems","221361304_Object_retrieval_with_large_vocabularies_and_fast_spatial_matching","221305396_Kernel_Codebooks_for_Scene_Categorization","221305188_Feature_Tracking_for_Wide-Baseline_Image_Retrieval","221304452_Descriptor_learning_for_efficient_retrieval_Computer_Vision_ECCV_2010","221303903_A_Linear_Time_Histogram_Metric_for_Improved_SIFT_Matching","221260038_Generalized_Descriptor_Compression_for_Storage_and_Matching","220265809_Object_Mining_Using_a_Matching_Graph_on_Very_Large_Image_Collections","200038910_Distinctive_Image_Features_from_Scale-Invariant_Keypoints","51539295_Efficient_Additive_Kernels_via_Explicit_Feature_Maps","41028481_Matas_J_Large-scale_discovery_of_spatially_related_images_IEEE_PAMI_32_371-377","4301701_Total_Recall_Automatic_Query_Expansion_with_a_Generative_Feature_Model_for_Object_Retrieval","4246228_Scalable_Recognition_with_a_Vocabulary_Tree"]}