{"id":"38358385_Bootstrap_Methods_Another_Look_at_the_Jackknife","abstract":"We discuss the following problem given a random sample X = (X\n1, X\n2,…, X\nn) from an unknown probability distribution F, estimate the sampling distribution of some prespecified random variable R(X, F), on the basis of the observed data x. (Standard jackknife theory gives an approximate mean and variance in the case R(X, F) = \\(\\theta \\left( {\\hat F} \\right) - \\theta \\left( F \\right)\\), θ some parameter of interest.) A general method, called the “bootstrap”, is introduced, and shown to work satisfactorily on a variety of estimation problems. The jackknife is shown to be a linear approximation method for the bootstrap. The exposition proceeds by a series of examples: variance of the sample median, error rates in a linear discriminant analysis, ratio estimation, estimating regression parameters, etc.","authors":["Bradley Efron"],"meta":["January 1979The Annals of Statistics 7(1)","DOI:10.1214/aos/1176344552"],"references":["239799507_Jackknifing_in_Unbalanced_Situations","271953683_The_Jackknife-A_review","268538261_Error_Analysis_by_Replaced_Samples","243082381_On_the_Generalized_Jackknife_and_its_Relation_to_Statistical_Differentials","200705604_Mathematical_Methods_Of_Statistics","38357941_Necessary_and_Sufficient_Conditions_for_Asymptotic_Joint_Normality_of_a_Statistic_and_Its_Subsample_Values","38357838_An_Unbalanced_Jackknife","36059012_Estimation_of_Error_Rates_in_Disciminant_Analysis","31448248_On_Estimating_a_Symmetric_Distribution","3082436_Bibliography_on_Estimation_of_Misclassification_IEEE_Tr_Info_Theory_20472-479"]}