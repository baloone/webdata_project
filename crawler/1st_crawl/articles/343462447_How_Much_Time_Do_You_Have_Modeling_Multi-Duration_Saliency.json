{"id":"343462447_How_Much_Time_Do_You_Have_Modeling_Multi-Duration_Saliency","authors":["Camilo Fosco","Anelise Newman","Pat Sukhum","Yun Bin Zhang"],"meta":["June 2020","DOI:10.1109/CVPR42600.2020.00453","Conference: 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"],"references":["318359805_Scan-path_Prediction_on_360_Degree_Images_using_Saliency_Volumes","317930158_Paying_More_Attention_to_Saliency_Image_Captioning_with_Saliency_and_Context_Attention","313727338_Components_of_visual_orienting","312387559_Fast-AT_Fast_Automatic_Thumbnail_Generation_using_Deep_Neural_Networks","312157449_Quantitative_Analysis_of_Automatic_Image_Cropping_Algorithms_A_Dataset_and_Comparative_Study","312061353_SalGAN_Visual_Saliency_Prediction_with_Generative_Adversarial_Networks","311106390_Predicting_Human_Eye_Fixations_via_an_LSTM-based_Saliency_Attentive_Model","283471087_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Image_Segmentation","282798204_Saliency_in_Crowd","282793850_SALICON_Saliency_in_Context","276296083_CAT2000_A_Large_Scale_Fixation_Dataset_for_Boosting_Saliency_Research","259961066_Predicting_human_gaze_beyond_pixels","228446463_Methods_for_comparing_scanpaths_and_saliency_maps_Strengths_and_weaknesses","224039895_Crowdsourcing_Gaze_Data_Collection","51174891_Eye_guidance_in_natural_vision_Reinterpreting_salience","40869089_Faces_and_text_attract_gaze_independent_of_the_task_Experimental_data_and_computer_model","341696320_TurkEyes_A_Web-Based_Toolbox_for_Crowdsourcing_Attention_Data","338996498_EML-NET_An_Expandable_Multi-Layer_NETwork_for_saliency_prediction","329747400_Good_View_Hunting_Learning_Photo_Composition_from_Dense_View_Pairs","329744331_COCO-Stuff_Thing_and_Stuff_Classes_in_Context","329740202_Squeeze-and-Excitation_Networks","324903904_Human_Visual_Scanpath_Prediction_Based_on_RGB-D_Saliency","323352021_Saccade_gaze_prediction_using_a_recurrent_neural_network","321066424_BubbleView_An_Interface_for_Crowdsourcing_Image_Importance_Maps_and_Tracking_Visual_Attention","320968382_Xception_Deep_Learning_with_Depthwise_Separable_Convolutions","320967345_Saliency_Revisited_Analysis_of_Mouse_Movements_Versus_Fixations","319501512_Squeeze-and-Excitation_Networks","311610990_Shallow_and_Deep_Convolutional_Networks_for_Saliency_Prediction","311610376_Eye_Tracking_for_Everyone","311609999_Automatic_Image_Cropping_A_Computational_Complexity_Study","309167356_Scanpath_estimation_based_on_foveated_image_saliency","308189211_Where_Should_Saliency_Models_Look_Next","305375498_WebGazer_Scalable_Webcam_Eye_Tracking_Using_User_Interactions","303812083_DeepLab_Semantic_Image_Segmentation_with_Deep_Convolutional_Nets_Atrous_Convolution_and_Fully_Connected_CRFs","301921832_Fully_convolutional_networks_for_semantic_segmentation","301876608_What_Do_Different_Evaluation_Metrics_Tell_Us_About_Saliency_Models","300412448_SALICON_Reducing_the_Semantic_Gap_in_Saliency_Prediction_by_Adapting_Deep_Neural_Networks","300410272_Understanding_and_Predicting_Image_Memorability_at_a_Large_Scale","262399254_Abnormal_Object_Detection_by_Canonical_Scene-Based_Contextual_Model","258641195_The_Intrinsic_Memorability_of_Face_Photographs","257014899_Context_models_and_out-of-context_objects","232506240_How_people_look_at_pictures_a_study_of_the_psychology_and_perception_in_art","221111619_Human_action_recognition_by_learning_bases_of_action_attributes_and_parts","51075777_Fixations_on_Low_Resolution_Images","12076686_Computational_Modeling_of_Visual_Attention","8679093_Inhibition_of_return_A_graphical_meta-analysis_of_its_time_course_and_an_empirical_test_of_its_temporal_and_spatial_properties"]}