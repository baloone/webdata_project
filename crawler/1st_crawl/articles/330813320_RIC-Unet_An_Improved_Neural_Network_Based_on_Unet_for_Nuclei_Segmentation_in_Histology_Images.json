{"id":"330813320_RIC-Unet_An_Improved_Neural_Network_Based_on_Unet_for_Nuclei_Segmentation_in_Histology_Images","abstract":"As a prerequisite for cell detection, cell classification and cancer grading, nuclei segmentation in histology images has attracted wide attention in recent years. It is quite a challenging task due to the diversity in staining procedure, cell morphology and cell arrangement between different histopathology images, especially with different color contrast. In this paper, a Unet-based neural network, RIC-Unet(Residual- Inception-Channel attention-Unet), for nuclei segmentation is proposed. The techniques of residual blocks, multi-scale and channel attention mechanism are applied on RIC-Unet to segment nuclei more accurately. RIC-Unet is compared with two traditional segmentation methods: CP and Fiji, two original CNN methods: CNN2, CNN3, and original U-net on The Cancer Genomic Atlas(TCGA) dataset. Besides, in this paper, we use Dice, F1-score, and aggregated Jaccard index(AJI) to evaluate these methods. The average of RICUnet and U-net on these three indicators are 0.8008 vs 0.7844, 0.8278 vs 0.8155 and 0.5635 vs 0.5462. In addition, our method won the third place in the computational precision medicine nuclei segmentation challenge together with MICCAI 2018.","authors":["Zitao Zeng","Weihao Xie","Yunzhe Zhang","Yao Lu"],"meta":["February 2019IEEE Access PP(99):1-1","DOI:10.1109/ACCESS.2019.2896920"],"references":["319637556_A_Deep_Residual_Inception_Network_for_HEp-2_Cell_Classification","314271512_A_Dataset_and_a_Technique_for_Generalized_Nuclear_Segmentation_for_Computational_Pathology","311610999_DCAN_Deep_Contour-Aware_Networks_for_Accurate_Gland_Segmentation","305426540_Topology_Aware_Fully_Convolutional_Networks_For_Histology_Gland_Segmentation","277334270_SegNet_A_Deep_Convolutional_Encoder-Decoder_Architecture_for_Robust_Semantic_Pixel-Wise_Labelling","268447498_Computational_Pathology_to_Discriminate_Benign_from_Malignant_Intraductal_Proliferations_of_the_Breast","221624097_A_Method_for_Normalizing_Histology_Slides_for_Quantitative_Analysis","6719447_CellProfiler_Image_analysis_software_for_identifying_and_quantifying_cell_phenotypes","3326757_Prince_JL_Snakes_Shapes_and_Gradient_Vector_Flow_IEE_Transactions_on_Image_Processing_73_359-369","329743787_Learning_a_Discriminative_Feature_Network_for_Semantic_Segmentation","329740202_Squeeze-and-Excitation_Networks","322059369_Focal_Loss_for_Dense_Object_Detection","320968233_RefineNet_Multi-path_Refinement_Networks_for_High-Resolution_Semantic_Segmentation","320964595_Residual_Attention_Network_for_Image_Classification","320963613_SCA-CNN_Spatial_and_Channel-Wise_Attention_in_Convolutional_Networks_for_Image_Captioning","319770183_Imagenet_classification_with_deep_convolutional_neural_networks","317679203_Rethinking_Atrous_Convolution_for_Semantic_Image_Segmentation","311609041_Deep_Residual_Learning_for_Image_Recognition","303812083_DeepLab_Semantic_Image_Segmentation_with_Deep_Convolutional_Nets_Atrous_Convolution_and_Fully_Connected_CRFs","301921832_Fully_convolutional_networks_for_semantic_segmentation","301874967_Inception-v4_Inception-ResNet_and_the_Impact_of_Residual_Connections_on_Learning","284400357_Measures_of_the_Amount_of_Ecologic_Association_Between_Species","282346844_An_Automatic_Learning-Based_Framework_for_Robust_Nucleus_Segmentation","278241330_Special_issue_on_medical_image_computing_and_computer-assisted_intervention_-_MICCAI_2003","263390366_Recurrent_Models_of_Visual_Attention","242500664_Information_Retrieval_Research_Proc_Joint_ACMBCS_Symposium_in_Information_Storage_and_Retrieval_Cambridge_June_1980","220182043_Watersheds_in_Digital_Spaces_An_Efficient_Algorithm_Based_on_Immersion_Simulations","202972390_A_Threshold_Selection_Method_from_Gray-Level_Histograms","47760356_Proceedings_of_Medical_Image_Computing_and_Computer-Assisted_Intervention_-_MICCAI_2004"]}