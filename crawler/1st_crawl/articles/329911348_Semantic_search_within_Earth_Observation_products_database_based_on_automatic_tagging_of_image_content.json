{"id":"329911348_Semantic_search_within_Earth_Observation_products_database_based_on_automatic_tagging_of_image_content","abstract":"Since 1972 and the launch of Landsat 1-the first Earth Observation civilian satellite-millions of images have been acquired all over the Earth by a constantly growing fleet of more and more sophisticated satellites. Generally, searching within this huge amount of Earth Observation (EO) images is limited by the description of the acquisition conditions stored in the related metadata files, i.e. Where (footprint), When (time of acquisition) and How (viewing angles, instrument, etc.). Thus the larger community of end users misses the What filter-i.e. a way to filter search in term of image content. RESTo [1] uses the iTag [2] footprint-based tagging system to enhance image metadata and hopefully provides a way to express semantic queries on images content in term of land use. We investigated the performance of RESTo against a 12 millions simulated Sentinel-2 granules database representative of the forthcoming French national mirror site of Sentinel products (PEPS).","authors":["Jérôme Gasperi"],"meta":["November 2014","Conference: Big Data From SpaceAt: Frascati, Italy","Project: iTag - Semantic enhancement of Earth Observation data"],"references":["216797523_Architectural_Styles_and_the_Design_of_Network-based_Software_Architectures"]}