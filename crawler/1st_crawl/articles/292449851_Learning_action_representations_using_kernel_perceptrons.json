{"id":"292449851_Learning_action_representations_using_kernel_perceptrons","abstract":"Action representation is fundamental to many aspects of cognition, including language.\nTheories of situated cognition suggest that the form of such representation is distinctively\ndetermined by grounding in the real world. This thesis tackles the question of\nhow to ground action representations, and proposes an approach for learning action\nmodels in noisy, partially observable domains, using deictic representations and kernel\nperceptrons.\nAgents operating in real-world settings often require domain models to support\nplanning and decision-making. To operate effectively in the world, an agent must be\nable to accurately predict when its actions will be successful, and what the effects of its\nactions will be. Only when a reliable action model is acquired can the agent usefully\ncombine sequences of actions into plans, in order to achieve wider goals. However,\nlearning the dynamics of a domain can be a challenging problem: agentsâ€™ observations\nmay be noisy, or incomplete; actions may be non-deterministic; the world itself may\nbe noisy; or the world may contain many objects and relations which are irrelevant.\nIn this thesis, I first show that voted perceptrons, equipped with the DNF family\nof kernels, easily learn action models in STRIPS domains, even when subject to noise\nand partial observability. Key to the learning process is, firstly, the implicit exploration\nof the space of conjunctions of possible fluents (the space of potential action preconditions)\nenabled by the DNF kernels; secondly, the identification of objects playing\nsimilar roles in different states, enabled by a simple deictic representation; and lastly,\nthe use of an attribute-value representation for world states.\nNext, I extend the model to more complex domains by generalising both the kernel\nand the deictic representation to a relational setting, where world states are represented\nas graphs. Finally, I propose a method to extract STRIPS-like rules from the learnt\nmodels. I give preliminary results for STRIPS domains and discuss how the method\ncan be extended to more complex domains. As such, the model is both appropriate for\nlearning data generated by robot explorations as well as suitable for use by automated\nplanning systems. This combination is essential for the development of autonomous\nagents which can learn action models from their environment and use them to generate\nsuccessful plans.","authors":["Kira Margaret Thom Mourao"],"meta":["November 2012"],"references":[]}