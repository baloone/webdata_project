{"id":"274404144_Propagation_of_Data_Fusion","abstract":"In a relational database, tuples are called “duplicate” if they describe the same real-world entity. If such duplicate tuples are observed, it is recommended to remove them and to replace them with one tuple that represents the joint information of the duplicate tuples to a maximal extent. This remove-and-replace operation is called a fusion operation. Within the setting of a relational database management system, the removal of the original duplicate tuples can breach referential integrity. In this paper, a strategy is proposed to maintain referential integrity in a semantically correct manner, thereby optimizing the quality of relationships in the database. An algorithm is proposed that is able to propagate a fusion operation through the entire database. The algorithm is based on a framework of first and second order fusion functions on the one hand, and conflict resolution strategies on the other hand. It is shown how classical strategies for maintaining referential integrity, such as delete cascading, are highly specialized cases of the proposed framework. Experimental results are reported that (i) show the efficiency of the proposed algorithm and (ii) show the differences in quality between several second order fusion functions. It is shown that some strategies easily outperform delete cascading.","authors":["Antoon Bronselaer","Daan Van Britsom","Guy De Tré"],"meta":["May 2015IEEE Transactions on Knowledge and Data Engineering 27(5):1330-1342","DOI:10.1109/TKDE.2014.2365807","Project: Multi-valued Data Fusion"],"references":["266644550_Weak_Preservation_of_Multi-Valued_Fusion","245836253_Data_Fusion_in_Three_Steps_Resolving_Inconsistencies_at_Schema_Tuple-_and_Value-level","234814585_Automatic_data_fusion_with_HumMer","228358563_A_duplicate_detection_benchmark_for_XML_and_relational_data","221651662_Declarative_Data_Fusion_-_Syntax_Semantics_and_Implementation","220964752_Large-Scale_Deduplication_with_Constraints_Using_Dedupalog","220814996_Collective_Object_Identification","220566228_Data_Fusion","220345064_Collective_Entity_Resolution_In_Relational_Data","220282903_Collective_Entity_Resolution_In_Relational_Data","3297646_Duplicate_Record_Detection_A_Survey","2363539_An_Efficient_Domain-Independent_Algorithm_for_Detecting_Approximately_Duplicate_Database_Records","267176541_Robustness_of_Multiset_Merge_Functions","265775504_An_optimal_theory_of_record_linkage","243765821_On_inference_from_inconsistent_premisses","241080187_A_framework_for_multiset_merging","228057942_A_Theory_for_Record_Linkage","224167132_Aspects_of_object_merging","222675193_Fusionplex_Resolution_of_data_inconsistencies_in_the_integration_of_heterogeneous_information_sources","221214100_Reference_Reconciliation_in_Complex_Information_Spaces","220687977_Data_Quality_Concepts_Methodologies_and_Techniques","220423134_A_Relational_Model_of_Data_for_Large_Shared_Data_Banks","200034304_A_Relational_Model_for_Large_Shared_Data_Banks","2538935_Eliminating_Fuzzy_Duplicates_in_Data_Warehouses"]}