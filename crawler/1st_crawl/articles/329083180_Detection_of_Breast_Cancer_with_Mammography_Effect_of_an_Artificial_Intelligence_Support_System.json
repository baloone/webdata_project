{"id":"329083180_Detection_of_Breast_Cancer_with_Mammography_Effect_of_an_Artificial_Intelligence_Support_System","abstract":"Purpose To compare breast cancer detection performance of radiologists reading mammographic examinations unaided versus supported by an artificial intelligence (AI) system. Materials and Methods An enriched retrospective, fully crossed, multireader, multicase, HIPAA-compliant study was performed. Screening digital mammographic examinations from 240 women (median age, 62 years; range, 39-89 years) performed between 2013 and 2017 were included. The 240 examinations (100 showing cancers, 40 leading to false-positive recalls, 100 normal) were interpreted by 14 Mammography Quality Standards Act-qualified radiologists, once with and once without AI support. The readers provided a Breast Imaging Reporting and Data System score and probability of malignancy. AI support provided radiologists with interactive decision support (clicking on a breast region yields a local cancer likelihood score), traditional lesion markers for computer-detected abnormalities, and an examination-based cancer likelihood score. The area under the receiver operating characteristic curve (AUC), specificity and sensitivity, and reading time were compared between conditions by using mixed-models analysis dof variance and generalized linear models for multiple repeated measurements. Results On average, the AUC was higher with AI support than with unaided reading (0.89 vs 0.87, respectively; P = .002). Sensitivity increased with AI support (86% [86 of 100] vs 83% [83 of 100]; P = .046), whereas specificity trended toward improvement (79% [111 of 140]) vs 77% [108 of 140]; P = .06). Reading time per case was similar (unaided, 146 seconds; supported by AI, 149 seconds; P = .15). The AUC with the AI system alone was similar to the average AUC of the radiologists (0.89 vs 0.87). Conclusion Radiologists improved their cancer detection at mammography when using an artificial intelligence system for support, without requiring additional reading time. Published under a CC BY 4.0 license. See also the editorial by Bahl in this issue.","authors":["Alejandro Rodr√≠guez-Ruiz","Elizabeth Krupinski","Jan-Jurre Mordang","Kathy Schilling"],"meta":["November 2018Radiology 290(2):181371","DOI:10.1148/radiol.2018181371"],"references":["323072309_Applying_Data-driven_Imaging_Biomarker_in_Mammography_for_Breast_Cancer_Screening_Preliminary_Study","315005037_Does_Reader_Performance_with_Digital_Breast_Tomosynthesis_Vary_according_to_Experience_with_Two-dimensional_Mammography","313857891_A_Survey_on_Deep_Learning_in_Medical_Image_Analysis","313815380_Deep_Learning_in_Mammography_Diagnostic_Accuracy_of_a_Multipurpose_Image_Analysis_Software_in_the_Detection_of_Breast_Cancer","305039790_Characteristics_and_prognosis_of_interval_cancers_after_biennial_screen-film_or_full-field_digital_screening_mammography","295623041_Short-Term_Outcomes_of_Screening_Mammography_Using_Computer-Aided_Detection_A_Population-Based_Study_of_Medicare_Enrollees","320334891_Radiologist_shortage_leaves_patient_care_at_risk_warns_royal_college","316690849_Will_Machine_Learning_Tip_the_Balance_in_Breast_Cancer_Screening","305825605_Large_Scale_Deep_Learning_for_Computer_Aided_Detection_of_Mammographic_Lesions","291268881_Errata_to_Power_Estimation_for_Multireader_ROC_Methods_An_Updated_and_Unified_Approach_Acad_Radiol_18_2011_129-142"]}