{"id":"330203109_Learnability_can_be_undecidable","abstract":"The mathematical foundations of machine learning play a key role in the development of the field. They improve our understanding and provide tools for designing new learning paradigms. The advantages of mathematics, however, sometimes come with a cost. Gödel and Cohen showed, in a nutshell, that not everything is provable. Here we show that machine learning shares this fate. We describe simple scenarios where learnability cannot be proved nor refuted using the standard axioms of mathematics. Our proof is based on the fact the continuum hypothesis cannot be proved nor refuted. We show that, in some cases, a solution to the ‘estimating the maximum’ problem is equivalent to the continuum hypothesis. The main idea is to prove an equivalence between learnability and compression.","authors":["Shai Ben-David","Pavel Hrubeš","Shay Moran","Amir Shpilka"],"meta":["January 2019Nature Machine Intelligence 1(1)","DOI:10.1038/s42256-018-0002-3"],"references":["234794341_Scale-sensitive_Dimensions_Uniform_Convergence_and_Learnability","345734085_Sample_compression_schemes_for_VC_classes","306173107_The_optimal_sample_complexity_of_PAC_learning","304069726_Sample_Compression_Schemes_for_VC_Classes","267665795_Understanding_machine_learning_From_theory_to_algorithms","263003486_Optimal_Learners_for_Multiclass_Problems","239595717_Theory_of_Pattern_Recognition_In_Russian","239546749_Statistical_Learning_Theory","234793335_A_theory_of_the_learnable","234778795_Learnability_Stability_and_Uniform_Convergence","233784971_On_the_Uniform_Convergence_of_Relative_Frequencies_of_Events_to_Their_Probabilities","225069855_Multiclass_Learning_Approaches_A_Theoretical_Comparison_withImplications","225035594_The_Independence_of_the_Continuum_Hypothesis","222450295_Efficient_Distribution-free_Learning_of_Probabilistic_Concepts","222441166_Characterizations_of_Learnability_for_Classes_of_0_n-Valued_Functions"]}