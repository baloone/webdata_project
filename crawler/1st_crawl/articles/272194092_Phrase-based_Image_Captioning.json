{"id":"272194092_Phrase-based_Image_Captioning","abstract":"Generating a novel textual description of an image is an interesting problem\nthat connects computer vision and natural language processing. In this paper,\nwe present a simple model that is able to generate descriptive sentences given\na sample image. This model has a strong focus on the syntax of the\ndescriptions. We train a purely bilinear model that learns a metric between an\nimage representation (generated from a previously trained Convolutional Neural\nNetwork) and phrases that are used to described them. The system is then able\nto infer phrases from a given image sample. Based on caption syntax statistics,\nwe propose a simple language model that can produce relevant descriptions for a\ngiven test image using the phrases inferred. Our approach, which is\nconsiderably simpler than state-of-the-art models, achieves comparable results\nin two popular datasets for the task: Flickr30k and the recently proposed\nMicrosoft COCO.","authors":["RÃ©mi Lebret","Pedro O. Pinheiro","Ronan Collobert"],"meta":["February 2015","SourcearXiv"],"references":["319770438_Long-Term_Recurrent_Convolutional_Networks_for_Visual_Recognition_and_Description","319770160_Show_and_Tell_A_Neural_Image_Caption_Generator","284576917_Glove_Global_Vectors_for_Word_Representation","269722517_Rehabilitation_of_Count-Based_Models_for_Word_Vector_Representations","269636281_Translating_Videos_to_Natural_Language_Using_Deep_Recurrent_Neural_Networks","329975395_Grounded_Compositional_Semantics_for_Finding_and_Describing_Images_with_Sentences","319770249_Deep_Visual-Semantic_Alignments_for_Generating_Image_Descriptions","309076254_Gradientbased_learning_applied_to_document_recognition","285896121_Learning_word_embeddings_efficiently_with_noise-contrastive_estimation","269339562_Deep_Visual-Semantic_Alignments_for_Generating_Image_Descriptions"]}