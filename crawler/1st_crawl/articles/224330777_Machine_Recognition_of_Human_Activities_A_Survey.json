{"id":"224330777_Machine_Recognition_of_Human_Activities_A_Survey","abstract":"The past decade has witnessed a rapid proliferation of video cameras in all walks of life and has resulted in a tremendous explosion of video content. Several applications such as content-based video annotation and retrieval, highlight extraction and video summarization require recognition of the activities occurring in the video. The analysis of human activities in videos is an area with increasingly important consequences from security and surveillance to entertainment and personal archiving. Several challenges at various levels of processing-robustness against errors in low-level processing, view and rate-invariant representations at midlevel processing and semantic representation of human activities at higher level processing-make this problem hard to solve. In this review paper, we present a comprehensive survey of efforts in the past couple of decades to address the problems of representation, recognition, and learning of human activities from video and related applications. We discuss the problem at two major levels of complexity: 1) \"actions\" and 2) \"activities.\" \"Actions\" are characterized by simple motion patterns typically executed by a single human. \"Activities\" are more complex and involve coordinated actions among a small number of humans. We will discuss several approaches and classify them according to their ability to handle varying degrees of complexity as interpreted above. We begin with a discussion of approaches to model the simplest of action classes known as atomic or primitive actions that do not require sophisticated dynamical modeling. Then, methods to model actions with more complex dynamics are discussed. The discussion then leads naturally to methods for higher level representation of complex activities.","authors":["Pavan K. Turaga","Rama Chellappa","V.S. Subrahmanian","Octavian Udrea"],"meta":["December 2008IEEE Transactions on Circuits and Systems for Video Technology 18(11):1473 - 1488","DOI:10.1109/TCSVT.2008.2005594","SourceIEEE Xplore"],"references":["319770307_Learning_and_recognizing_human_dynamics_in_video_sequences","305263025_An_Efficient_Context-Free_Parsing_Algorithm","285842809_Petri_Nets_Properties_Analysis_and_Applications","285599593_A_Global_Geometric_Framework_for_Nonlinear_Dimensionality_Reduction","284688924_Object_tracking_A_Survey","284035345_Nonlinear_Dimensionality_Reduction_by_Locally_Linear_Embedding","283921280_Visual_Pattern_Recognition_by_Moment_Invariants","278253413_The_Holy_Grail_of_content-based_media_analysis","273134799_Estimating_the_Dimension_of_a_Model","271512887_Learning_in_Graphical_Models"]}