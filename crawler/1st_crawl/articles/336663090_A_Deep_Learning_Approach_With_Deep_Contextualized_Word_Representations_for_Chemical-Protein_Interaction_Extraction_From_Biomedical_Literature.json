{"id":"336663090_A_Deep_Learning_Approach_With_Deep_Contextualized_Word_Representations_for_Chemical-Protein_Interaction_Extraction_From_Biomedical_Literature","abstract":"Mining interactions between chemicals and proteins/genes is of crucial relevance for clinical medicine, adverse drug effects, and pharmacological research. Although chemicalâ€“protein interactions (CPIs) can be manually extracted, this process is expensive and time-consuming. Therefore, it is of considerable significance to automatically extract CPIs from biomedical literature. Currently, the popular methods for CPI extraction are based on deep learning to avoid sophisticated handcrafted features derived from linguistic analyses. However, the performance of existing methods is usually unsatisfactory. The reasons may be that (1) traditional word-embedding methods cannot adequately model context information, and (2) it is difficult to effectively distinguish which words play critical roles in long biomedical sentences. In this study, we propose a novel Deep-contextualized Stacked Bi-LSTM model (DS-LSTM) to tackle the drawbacks of existing methods. Specifically, our model mainly consists of three components: deep contextualized word representations, the entity attention mechanism, and stacked bidirectional long short-term memory networks (Bi-LSTMs). The deep contextualized word representations are introduced to effectively model complex characteristics of word use (e.g., syntax and semantics) and the variations of these words in the context (i.e., to model polysemy), thereby generating context information. The entity attention mechanism is applied to prioritize the weights of words associated with target entities to distinguish which words play critical roles in long biomedical sentences. We evaluate our model on the CHEMPROT corpus. Our approach achieves a micro-averaged F-score of 69.44%, which is significantly higher than existing state-of-the-art methods. Experimental results show that our approach can adequately model context information, effectively distinguish which words play critical roles in long biomedical sentences and, therefore, improve the overall performance.","authors":["Cong Sun","Zhihao Yang","Ling Luo","Lei Wang"],"meta":["October 2019IEEE Access 7:1-1","DOI:10.1109/ACCESS.2019.2948155"],"references":["330262856_Extracting_chemical-protein_interactions_from_literature_using_sentence_structure_analysis_and_feature_engineering","330035276_Potent_pairing_ensemble_of_long_short-term_memory_networks_and_support_vector_machine_for_chemical-protein_relation_extraction","328448745_LPTK_a_linguistic_pattern-aware_dependency_tree_kernel_approach_for_the_BioCreative_VI_CHEMPROT_task","326491420_Extracting_chemical-protein_relations_with_ensembles_of_SVM_and_deep_learning_models","326447277_Improving_the_learning_of_chemical-protein_interactions_from_literature_using_transfer_learning_and_specialized_word_embeddings","326157925_Chemical-gene_relation_extraction_using_recursive_neural_network","323217640_Deep_contextualized_word_representations","320691716_Drug-drug_Interaction_Extraction_via_Hierarchical_RNNs_on_Sequence_and_Shortest_Dependency_Paths","332755136_Extracting_chemical-protein_interactions_from_biomedical_literature_via_granular_attention_based_recurrent_neural_networks","325445489_Deep_Contextualized_Word_Representations"]}