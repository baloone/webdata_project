{"id":"315667264_Efficient_Processing_of_Deep_Neural_Networks_A_Tutorial_and_Survey","abstract":"Deep neural networks (DNNs) are currently widely used for many artificial intelligence (AI) applications including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Accordingly, techniques that enable efficient processing of deep neural network to improve energy-efficiency and throughput without sacrificing performance accuracy or increasing hardware cost are critical to enabling the wide deployment of DNNs in AI systems. This article aims to provide a comprehensive tutorial and survey about the recent advances towards the goal of enabling efficient processing of DNNs. Specifically, it will provide an overview of DNNs, discuss various platforms and architectures that support DNNs, and highlight key trends in recent efficient processing techniques that reduce the computation cost of DNNs either solely via hardware design changes or via joint hardware design and network algorithm changes. It will also summarize various development resources that can enable researchers and practitioners to quickly get started on DNN design, and highlight important benchmarking metrics and design considerations that should be used for evaluating the rapidly growing number of DNN hardware designs, optionally including algorithmic co-design, being proposed in academia and industry. The reader will take away the following concepts from this article: understand the key design considerations for DNNs; be able to evaluate different DNN hardware implementations with benchmarks and comparison metrics; understand trade-offs between various architectures and platforms; be able to evaluate the utility of various DNN design techniques for efficient processing; and understand of recent implementation trends and opportunities.","authors":["Vivienne Sze","Yu-Hsin Chen","Tien-Ju Yang","Joel S. Emer"],"meta":["March 2017Proceedings of the IEEE 105(12)","DOI:10.1109/JPROC.2017.2761740"],"references":["319858391_Scalpel_Customizing_DNN_Pruning_to_the_Underlying_Hardware_Parallelism","320971375_Deep_Learning_with_Low_Precision_by_Half-Wave_Gaussian_Quantization","320968382_Xception_Deep_Learning_with_Depthwise_Separable_Convolutions","320968331_Designing_Energy-Efficient_Convolutional_Neural_Networks_Using_Energy-Aware_Pruning","320967094_Cognitive_Mapping_and_Planning_for_Visual_Navigation","319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation","319770367_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation","319770334_Deep_Compression_Compressing_Deep_Neural_Networks_with_Pruning_Trained_Quantization_and_Huffman_Coding","319770272_Delving_Deep_into_Rectifiers_Surpassing_Human-Level_Performance_on_ImageNet_Classification","319770264_Regularization_of_Neural_Networks_using_DropConnect"]}