{"id":"350813838_Heidelberg_colorectal_data_set_for_surgical_data_science_in_the_sensor_operating_room","abstract":"Image-based tracking of medical instruments is an integral part of surgical data science applications. Previous research has addressed the tasks of detecting, segmenting and tracking medical instruments based on laparoscopic video data. However, the proposed methods still tend to fail when applied to challenging images and do not generalize well to data they have not been trained on. This paper introduces the Heidelberg Colorectal (HeiCo) data set - the first publicly available data set enabling comprehensive benchmarking of medical instrument detection and segmentation algorithms with a specific emphasis on method robustness and generalization capabilities. Our data set comprises 30 laparoscopic videos and corresponding sensor data from medical devices in the operating room for three different types of laparoscopic surgery. Annotations include surgical phase labels for all video frames as well as information on instrument presence and corresponding instance-wise segmentation masks for surgical instruments (if any) in more than 10,000 individual frames. The data has successfully been used to organize international competitions within the Endoscopic Vision Challenges 2017 and 2019.","authors":["Lena Maier-Hein","Martin Wagner","Tobias Ro√ü","Annika Reinke"],"meta":["April 2021Scientific Data 8(1):101","DOI:10.1038/s41597-021-00882-2","Project: Surgical Data Science"],"references":["348811639_Methods_and_open-source_toolkit_for_analyzing_and_visualizing_challenge_results","347223966_Comparative_validation_of_multi-instance_instrument_segmentation_in_endoscopy_Results_of_the_ROBUST-MIS_2019_challenge","343801549_BIAS_Transparent_reporting_of_biomedical_image_analysis_challenges","329349361_Why_rankings_of_biomedical_image_analysis_competitions_should_be_interpreted_with_care","321324833_Exploiting_the_potential_of_unlabeled_endoscopic_video_data_with_self-supervised_learning","319651707_Surgical_data_science_for_next-generation_interventions","336393023_Learning_Where_to_Look_While_Tracking_Instruments_in_Robot-Assisted_Surgery","333200315_Video-based_surgical_skill_assessment_using_3D_convolutional_neural_networks","327515710_Inter-observer_variability_of_manual_contour_delineation_of_structures_in_CT","312075258_A_Dataset_and_Benchmarks_for_Segmentation_and_Recognition_of_Gestures_in_Robotic_Surgery"]}