{"id":"339550723_Speech_emotion_recognition_with_deep_convolutional_neural_networks","abstract":"The speech emotion recognition (or, classification) is one of the most challenging topics in data science. In this work, we introduce a new architecture, which extracts mel-frequency cepstral coefficients, chromagram, mel-scale spectrogram, Tonnetz representation, and spectral contrast features from sound files and uses them as inputs for the one-dimensional Convolutional Neural Network for the identification of emotions using samples from the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS), Berlin (EMO-DB), and Interactive Emotional Dyadic Motion Capture (IEMOCAP) datasets. We utilize an incremental method for modifying our initial model in order to improve classification accuracy. All of the proposed models work directly with raw sound data without the need for conversion to visual representations, unlike some previous approaches. Based on experimental results, our best-performing model outperforms existing frameworks for RAVDESS and IEMOCAP, thus setting the new state-of-the-art. For the EMO-DB dataset, it outperforms all previous works except one but compares favorably with that one in terms of generality, simplicity, and applicability. Specifically, the proposed framework obtains 71.61% for RAVDESS with 8 classes, 86.1% for EMO-DB with 535 samples in 7 classes, 95.71% for EMO-DB with 520 samples in 7 classes, and 64.3% for IEMOCAP with 4 classes in speaker-independent audio classification tasks.","authors":["Dias Issa","M. Fatih Demirci","Adnan Yazici"],"meta":["May 2020Biomedical Signal Processing and Control 59:101894","DOI:10.1016/j.bspc.2020.101894"],"references":["335829398_Data_Augmentation_Using_GANs_for_Speech_Emotion_Recognition","330398273_Multimodal_Speech_Emotion_Recognition_Using_Audio_and_Text","328777063_librosa_Audio_and_Music_Signal_Analysis_in_Python","325187111_The_Ryerson_Audio-Visual_Database_of_Emotional_Speech_and_Song_RAVDESS_A_dynamic_multimodal_set_of_facial_and_vocal_expressions_in_North_American_English","322070397_Spectrogram_based_multi-task_audio_classification","319343259_Emotion_Recognition_in_Sound","319058788_Recognition_of_Emotional_Speech_with_Convolutional_Neural_Networks_by_Means_of_Spectral_Estimates","315638464_Speech_Emotion_Recognition_from_Spectrograms_with_Deep_Convolutional_Neural_Network","312039806_Continuous_Wavelet_Transform_based_Speech_Emotion_Recognition","310814393_Application_of_fuzzy_C-means_clustering_algorithm_to_spectral_features_for_emotion_classification_from_speech","307889334_The_INTERSPEECH_2016_Computational_Paralinguistics_Challenge_Deception_Sincerity_and_Native_Language","307831143_An_experimental_study_of_speech_emotion_recognition_based_on_deep_convolutional_neural_networks","297277484_Adieu_Features_End-to-end_Speech_Emotion_Recognition_using_a_Deep_Convolutional_Recurrent_Network","282355750_High-level_Feature_Representation_using_Recurrent_Neural_Network_for_Speech_Emotion_Recognition","273393526_Speech_Emotion_Recognition_Using_Fourier_Parameters","267213794_Speech_Emotion_Recognition_Using_Deep_Neural_Network_and_Extreme_Learning_Machine","261399453_Deep_learning_for_robust_feature_generation_in_audiovisual_emotion_recognition","221491017_A_database_of_German_emotional_speech","220147568_IEMOCAP_Interactive_emotional_dyadic_motion_capture_database","200806168_Detecting_harmonic_change_in_musical_audio","344962460_Real_Time_Multiple_Face_Recognition_A_Deep_Learning_Approach","335830068_Self-Attention_for_Speech_Emotion_Recognition","335829625_Towards_Robust_Speech_Emotion_Recognition_Using_Deep_Residual_Networks_for_Speech_Enhancement","332790943_Speech_Emotion_Recognition_Using_Deep_Neural_Network_Considering_Verbal_and_Nonverbal_Speech_Sounds","330046158_Speech_emotion_recognition_using_deep_1D_2D_CNN_LSTM_networks","326638635_3-D_Convolutional_Recurrent_Neural_Networks_With_Attention_Model_for_Speech_Emotion_Recognition","325431658_Improvement_on_Speech_Emotion_Recognition_Based_on_Deep_Convolutional_Neural_Networks","312559508_Speech_emotion_recognition_using_convolutional_and_Recurrent_Neural_Networks","309612198_Voice_recognition_based_on_adaptive_MFCC_and_deep_learning","304372202_Cross-corpus_acoustic_emotion_recognition_from_singing_and_speaking_A_multi-task_learning_approach","286512696_Deep_Residual_Learning_for_Image_Recognition","284567760_Speech_Emotion_Recognition_Using_CNN","282540984_The_Geneva_Minimalistic_Acoustic_Parameter_Set_GeMAPS_for_Voice_Research_and_Affective_Computing","261050596_Evaluation_of_MPEG-7_Descriptors_for_Speech_Emotional_Recognition","232598212_A_scale_for_the_measurement_of_the_psychological_magnitude_pitch","220120082_Automatic_speech_emotion_recognition_using_modulation_spectral_features","3968978_Music_type_classification_by_spectral_contrast_feature"]}