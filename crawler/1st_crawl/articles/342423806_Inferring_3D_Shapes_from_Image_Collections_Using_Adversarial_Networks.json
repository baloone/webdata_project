{"id":"342423806_Inferring_3D_Shapes_from_Image_Collections_Using_Adversarial_Networks","abstract":"We investigate the problem of learning a probabilistic distribution over three-dimensional shapes given two-dimensional views of multiple objects taken from unknown viewpoints. Our approach called projective generative adversarial network (PrGAN) trains a deep generative model of 3D shapes whose projections (or renderings) matches the distribution of the provided 2D views. The addition of a differentiable projection module allows us to infer the underlying 3D shape distribution without access to any explicit 3D or viewpoint annotation during the learning phase. We show that our approach produces 3D shapes of comparable quality to GANs trained directly on 3D data. Experiments also show that the disentangled representation of 2D shapes into geometry and viewpoint leads to a good generative model of 2D shapes. The key advantage of our model is that it estimates 3D shape, viewpoint, and generates novel views from an input image in a completely unsupervised manner. We further investigate how the generative models can be improved if additional information such as depth, viewpoint or part segmentations is available at training time. To this end, we present new differentiable projection operators that can be used to learn better 3D generative models. Our experiments show that PrGAN can successfully leverage extra visual cues to create more diverse and accurate shapes.","authors":["Matheus Gadelha","Aartika Rai","Subhransu Maji","Rui Wang"],"meta":["November 2020International Journal of Computer Vision 128(1)","DOI:10.1007/s11263-020-01335-w"],"references":["332814865_Shape_Generation_using_Spatially_Partitioned_Point_Clouds","329270452_Paparazzi_Surface_editing_by_way_of_multi-view_image_processing","339555692_Shape_Reconstruction_Using_Differentiable_Projections_and_Deep_Priors","338513453_A_Bayesian_Perspective_on_the_Deep_Image_Prior","329748618_A_Papier-Mache_Approach_to_Learning_3D_Surface_Generation","329747067_Multi-view_Consistency_as_Supervisory_Signal_for_Learning_Shape_and_Pose_Prediction","329743891_Neural_3D_Mesh_Renderer","329275627_Differentiable_Monte_Carlo_ray_tracing_through_edge_sampling","328128554_Learning_Category-Specific_Mesh_Reconstruction_from_Image_Collections_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Part_XV","328108311_Multiresolution_Tree_Networks_for_3D_Point_Cloud_Processing_15th_European_Conference_Munich_Germany_September_8-14_2018_Proceedings_Part_VII","325636034_3D_Shape_Reconstruction_from_Sketches_via_Multi-view_Convolutional_Networks","325635092_3D_Shape_Induction_from_2D_Views_of_Multiple_Objects","323904618_Learning_Category-Specific_Mesh_Reconstruction_from_Image_Collections","322418930_Multi-view_Consistency_as_Supervisory_Signal_for_Learning_Shape_and_Pose_Prediction","320968205_A_Point_Set_Generation_Network_for_3D_Object_Reconstruction_from_a_Single_Image"]}