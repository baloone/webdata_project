{"id":"228414554_Benchmark_precision_and_random_initial_state","abstract":"The applications of software benchmarks place an obvious demand on the precision of the benchmark results. An intu­ itive and frequently employed approach to obtaining precise enough benchmark results is having the benchmark collect a large number of samples that are simply averaged or other­ wise statistically processed. We show that this approach ignores an inherent and unavoidable nondeterminism in the initial state of the system that is evaluated, often leading to an implausible estimate of result precision. We proceed by out­ lining the sources of nondeterminism in a typical system, illustrating the impact of the nondeterminism on selected classes of benchmarks. Finally, we suggest a method for quantitatively assessing the influence of nondeterminism on a benchmark, as well as approach that provides a plausible esti­ mate of result precision in face of the nondeterminism.","authors":["Tomas Kalibera","Lubomír Bulej","Petr Tůma"],"meta":["July 2005","Conference: International Symposium on Performance Evaluation of Computer and Telecommunication Systems (SPECTS)At: Cherry Hill, New Jersey, USA"],"references":["220253217_Repeated_results_analysis_for_middleware_regression_benchmarking","2954437_SPEC_as_a_Performance_Evaluation_Measure"]}