{"id":"315668107_Deep_Residual_Learning_for_Instrument_Segmentation_in_Robotic_Surgery","abstract":"Detection, tracking, and pose estimation of surgical instruments are crucial tasks for computer assistance during minimally invasive robotic surgery. In the majority of cases, the first step is the automatic segmentation of surgical tools. Prior work has focused on binary segmentation, where the objective is to label every pixel in an image as tool or background. We improve upon previous work in two major ways. First, we leverage recent techniques such as deep residual learning and dilated convolutions to advance binary-segmentation performance. Second, we extend the approach to multi-class segmentation, which lets us segment different parts of the tool, in addition to background. We demonstrate the performance of this method on the MICCAI Endoscopic Vision Challenge Robotic Instruments dataset.","authors":["Daniil Pakhomov","Vittal Premachandran","Max Allan","Mahdi Azizian"],"meta":["March 2017"],"references":["305770331_Real-Time_Segmentation_of_Non-Rigid_Surgical_Tools_based_on_Deep_Learning_and_Tracking","283641391_Image_Based_Surgical_Instrument_Pose_Estimation_with_Multi-class_Labelling_and_Optical_Flow","319770168_Fully_Convolutional_Networks_for_Semantic_Segmentation","311609041_Deep_Residual_Learning_for_Image_Recognition","305719371_Medical_Robotics_and_Computer-Integrated_Surgery","303812083_DeepLab_Semantic_Image_Segmentation_with_Deep_Convolutional_Nets_Atrous_Convolution_and_Fully_Connected_CRFs","301921832_Fully_convolutional_networks_for_semantic_segmentation","286512696_Deep_Residual_Learning_for_Image_Recognition","284579148_Multi-Scale_Context_Aggregation_by_Dilated_Convolutions","282545365_Detecting_Surgical_Tools_by_Modelling_Local_Appearance_and_Global_Shape"]}