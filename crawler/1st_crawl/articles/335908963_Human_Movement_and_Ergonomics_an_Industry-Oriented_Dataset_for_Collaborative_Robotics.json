{"id":"335908963_Human_Movement_and_Ergonomics_an_Industry-Oriented_Dataset_for_Collaborative_Robotics","abstract":"Improving work conditions in industry is a major challenge that can be addressed with new emerging technologies such as collaborative robots. Machine learning techniques can improve the performance of those robots, by endowing them with a degree of awareness of the human state and ergonomics condition. The availability of appropriate datasets to learn models and test prediction and control algorithms, however, remains an issue. This article presents a dataset of human motions in industry-like activities, fully labeled according to the ergonomics assessment worksheet EAWS, widely used in industries such as car manufacturing. Thirteen participants performed several series of activities, such as screwing and manipulating loads under different conditions, resulting in more than 5 hours of data. The dataset contains the participants’ whole-body kinematics recorded both with wearable inertial sensors and marker-based optical motion capture, finger pressure force, video recordings, and annotations by three independent annotators of the performed action and the adopted posture following the EAWS postural grid. Sensor data are available in different formats to facilitate their reuse. The dataset is intended for use by researchers developing algorithms for classifying, predicting, or evaluating human motion in industrial settings, as well as researchers developing collaborative robotics solutions that aim at improving the workers’ ergonomics. The annotation of the whole dataset following an ergonomics standard makes it valuable for ergonomics-related applications, but we expect its use to be broader in the robotics, machine learning, and human movement communities.","authors":["Pauline Maurice","Adrien Malaisé","Clélie Amiot","Nicolas Paris"],"meta":["October 2019The International Journal of Robotics Research 38(1)","DOI:10.1177/0278364919882089"],"references":["332469880_Task_allocation_for_improved_ergonomics_in_Human-Robot_Collaborative_Assembly","330496505_Activity_Recognition_for_Ergonomics_Assessment_of_Industrial_Tasks_With_Automatic_Feature_Selection","330337418_Optimizing_Contextual_Ergonomics_Models_in_Human-Robot_Interaction","326905814_ErgoTac_A_Tactile_Feedback_Interface_for_Improving_Human_Ergonomics_in_Workplaces","325871439_Improved_Human-Robot_Interaction_A_manipulability_based_approach","338509384_Deep_High-Resolution_Representation_Learning_for_Human_Pose_Estimation","335140469_Activity_recognition_in_manufacturing_The_roles_of_motion_capture_and_sEMGinertial_wearables_in_detecting_fine_vs_gross_motion","334526467_OpenPose_Realtime_Multi-Person_2D_Pose_Estimation_Using_Part_Affinity_Fields","327811654_Planning_Ergonomic_Sequences_of_Actions_in_Human-Robot_Interaction","326719204_Online_Human_Muscle_Force_Estimation_for_Fatigue_Management_in_Human-Robot_Co-Manipulation"]}