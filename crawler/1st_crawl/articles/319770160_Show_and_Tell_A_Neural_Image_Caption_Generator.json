{"id":"319770160_Show_and_Tell_A_Neural_Image_Caption_Generator","abstract":"Automatically describing the content of an image is a fundamental problem in\nartificial intelligence that connects computer vision and natural language\nprocessing. In this paper, we present a generative model based on a deep\nrecurrent architecture that combines recent advances in computer vision and\nmachine translation and that can be used to generate natural sentences\ndescribing an image. The model is trained to maximize the likelihood of the\ntarget description sentence given the training image. Experiments on several\ndatasets show the accuracy of the model and the fluency of the language it\nlearns solely from image descriptions. Our model is often quite accurate, which\nwe verify both qualitatively and quantitatively. For instance, while the\ncurrent state-of-the-art BLEU score (the higher the better) on the Pascal\ndataset is 25, our approach yields 59, to be compared to human performance\naround 69. We also show BLEU score improvements on Flickr30k, from 55 to 66,\nand on SBU, from 19 to 27.","authors":["Oriol Vinyals","Alexander Toshev","Samy Bengio","Dumitru Erhan"],"meta":["November 2014"],"references":["305196650_Going_deeper_with_convolutions","329977566_T_ree_T_alk_Composition_and_Compression_of_Trees_for_Image_Descriptions","329975395_Grounded_Compositional_Semantics_for_Finding_and_Describing_Images_with_Sentences","319770465_Sequence_to_Sequence_Learning_with_Neural_Networks","319770439_Efficient_Estimation_of_Word_Representations_in_Vector_Space","319770357_DeCAF_A_Deep_Convolutional_Activation_Feature_for_Generic_Visual_Recognition","312714920_Improving_Image-Sentence_Embeddings_Using_Large_Weakly_Annotated_Photo_Collections","303721259_From_image_descriptions_to_visual_denotations_New_similarity_metrics_for_semantic_inference_over_event_descriptions","290345348_Image_description_using_visual_dependency_representations","268155634_Unifying_Visual-Semantic_Embeddings_with_Multimodal_Neural_Language_Models"]}