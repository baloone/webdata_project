{"id":"330723512_Ea-GANs_Edge-aware_Generative_Adversarial_Networks_for_Cross-modality_MR_Image_Synthesis","abstract":"Magnetic resonance imaging (MRI) is a widely used medical imaging protocol that can be configured to provide different contrast between the tissues in human body. By setting different scanning parameters, each MR imaging modality reflects the unique visual characteristic of scanned body part, benefiting the subsequent analysis from multiple perspectives. To utilise the complementary information from multiple imaging modalities, cross-modality MR image synthesis has aroused increasing research interest recently. However, most existing methods only focus on minimising pixel/voxel-wise intensity difference, but ignore the textural details of image content structure, which affects the quality of synthesised images. In this paper, we propose edge-aware generative adversarial networks (Ea- GANs) for cross-modality MR image synthesis. Specifically, we integrate edge information, which reflects the textural structure of image content and depicts the boundaries of different objects in images, to reduce this gap. Corresponding to different learning strategies, two frameworks are proposed, i.e., a generator-induced Ea-GAN (gEa-GAN) and a discriminator-induced Ea-GAN (dEa- GAN). The gEa-GAN incorporates the edge information via its generator, while the dEa-GAN further does this from both generator and discriminator so that the edge similarity is also adversarially learned. In addition, the proposed Ea-GANs are 3D based, and utilise hierarchical features to capture contextual information. Experimental results demonstrate that the proposed Ea-GANs, especially the dEa-GAN, outperform multiple state-ofthe- art methods for cross-modality MR image synthesis in both qualitative and quantitative measures. Moreover, the dEa-GAN also shows excellent generality to generic image synthesis tasks on benchmark datasets about facades, maps, and cityscapes.","authors":["Biting Yu","Luping Zhou","Lei Wang","Yinghuan Shi"],"meta":["January 2019IEEE Transactions on Medical Imaging PP(99):1-1","DOI:10.1109/TMI.2019.2895894"],"references":["328681922_Automatic_Brain_Labeling_via_Multi-Atlas_Guided_Fully_Convolutional_Networks","326184248_Synthesizing_Retinal_and_Neuronal_Images_with_Generative_Adversarial_Nets","325472723_GAN-based_synthetic_brain_MR_image_generation","323746639_An_Introduction_to_Image_Synthesis_with_Generative_Adversarial_Nets","322652335_MRI_Image-to-Image_Translation_for_Cross-Modality_Image_Registration_and_Segmentation","322060135_Unpaired_Image-to-Image_Translation_Using_Cycle-Consistent_Adversarial_Networks","321657521_Cross-Modality_Image_Synthesis_via_Weakly-Coupled_and_Geometry_Co-Regularized_Joint_Dictionary_Learning","321125257_Freehand_Ultrasound_Image_Simulation_with_Spatially-Conditioned_Generative_Adversarial_Networks","320966887_Image-to-Image_Translation_with_Conditional_Adversarial_Networks","319638632_Synthesis_of_Positron_Emission_Tomography_PET_Images_via_Multi-channel_Generative_Adversarial_Networks_GANs","319524751_Synthetic_Medical_Images_from_Dual_Generative_Adversarial_Networks","319235821_Sharpness-Aware_Low-Dose_CT_Denoising_Using_Conditional_Generative_Adversarial_Network","317300140_Deep_Generative_Adversarial_Networks_for_Compressed_Sensing_Automates_MRI","316779826_Simultaneous_Super-Resolution_and_Cross-Modality_Synthesis_of_3D_Medical_Images_using_Weakly-Supervised_Joint_Convolutional_Sparse_Coding","316079422_Validation_of_a_Regression_Technique_for_Segmentation_of_White_Matter_Hyperintensities_in_Alzheimer's_Disease","315710637_Unpaired_Image-to-Image_Translation_using_Cycle-Consistent_Adversarial_Networks","310610633_Image-to-Image_Translation_with_Conditional_Adversarial_Networks","305881127_Improved_Techniques_for_Training_GANs","304226155_3D_U-Net_Learning_Dense_Volumetric_Segmentation_from_Sparse_Annotation","301880609_The_Cityscapes_Dataset_for_Semantic_Urban_Scene_Understanding","301878860_Efficient_Multi-Scale_3D_CNN_with_fully_connected_CRF_for_Accurate_Brain_Lesion_Segmentation","333909972_Deep_learning_approaches_using_2D_and_3D_convolutional_neural_networks_for_generating_male_pelvic_synthetic_CT_from_MRI","331360852_Image_Synthesis_in_Multi-Contrast_MRI_With_Conditional_Generative_Adversarial_Networks","325519064_3D_cGAN_based_cross-modality_MR_image_synthesis_for_brain_tumor_segmentation","325516387_Adversarial_synthesis_learning_enables_segmentation_without_target_modality_ground_truth","323914410_3D_conditional_generative_adversarial_networks_for_high-quality_PET_image_estimation_at_low_dose","323867727_Cross-modality_image_synthesis_from_unpaired_data_using_CycleGAN_Effects_of_gradient_consistency_loss_and_training_data_size","323672719_Medical_Image_Synthesis_with_Deep_Convolutional_Adversarial_Networks","323510108_Male_pelvic_synthetic_CT_generation_from_T1-weighted_MRI_using_2D_and_3D_convolutional_neural_networks","323269743_Isotropic_Reconstruction_of_MR_Images_Using_3D_Patch-Based_Self-Similarity_Learning","322848455_Conversion_and_Time-to-Conversion_Predictions_of_Mild_Cognitive_Impairment_using_Low-Rank_Affinity_Pursuit_Denoising_and_Matrix_Completion","321994209_Adversarial_Synthesis_Learning_Enables_Segmentation_Without_Target_Modality_Ground_Truth","321747972_End-to-end_Adversarial_Retinal_Image_Synthesis","321658445_Generation_of_Structural_MR_Images_from_Amyloid_PET_Application_to_MR-Less_Quantification","321160843_Unsupervised_Reverse_Domain_Adaptation_for_Synthetic_Medical_Images_via_Adversarial_Training","320590845_Biomedical_Data_Augmentation_Using_Generative_Adversarial_Neural_Networks","320476280_Multimodal_MR_Synthesis_via_Modality-Invariant_Latent_Representation","320026610_Deep_MR_to_CT_Synthesis_Using_Unpaired_Data","319770355_Generative_Adversarial_Nets","319770168_Fully_Convolutional_Networks_for_Semantic_Segmentation","313072707_3D_U-Net_Learning_Dense_Volumetric_Segmentation_from_Sparse_Annotation","311754161_V-Net_Fully_Convolutional_Neural_Networks_for_Volumetric_Medical_Image_Segmentation","309822231_Personalized_Radiotherapy_Planning_Based_on_a_Computational_Tumor_Growth_Model","307957904_Random_forest_regression_for_magnetic_resonance_image_synthesis","305193694_U-Net_Convolutional_Networks_for_Biomedical_Image_Segmentation","305084697_Extended_Modality_Propagation_Image_Synthesis_of_Pathological_Cases","303505510_Fully_Convolutional_Networks_for_Semantic_Segmentation","303027313_Semi-Supervised_Tripled_Dictionary_Learning_for_Standard-dose_PET_Image_Prediction_using_Low-dose_PET_and_Multimodal_MRI","301921832_Fully_convolutional_networks_for_semantic_segmentation","286512696_Deep_Residual_Learning_for_Image_Recognition","284779495_Why_Does_Synthesized_Data_Improve_Multi-sequence_Classification","276923248_U-Net_Convolutional_Networks_for_Biomedical_Image_Segmentation","280870503_Using_image_synthesis_for_multi-channel_registration_of_different_image_modalities","280691128_Estimating_CT_Image_from_MRI_Data_Using_Structured_Random_Forest_and_Auto-context_Model","276296154_Brain_Tumor_Segmentation_with_Deep_Neural_Networks"]}