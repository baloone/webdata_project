{"id":"319702980_ACCELERATED_FORWARD-BACKWARD_ALGORITHMS_WITH_PERTURBATIONS_APPLICATION_TO_TIKHONOV_REGULARIZATION","abstract":"In a Hilbert space H, we consider accelerated forward-backward methods in the presence of perturbations, approximations, errors. They aim at solving structured convex minimization problems min(Φ + Ψ), where Φ : H → R is a continuously differentiable convex function whose gradient is Lipschitz continuous, and Ψ : H → R ∪ {+∞} is a proper lower-semicontinuous convex function. Precisely, given (α k) a general sequence of nonnegative numbers, we analyze the rate of convergence of the Inertial Forward-Backward algorithm with perturbation (IFB) pert y k = x k + α k (x k − x k−1) x k+1 = prox sΨ (y k − sΦ(y k) + sg k). The sequence (g k) in H takes into account the presence of perturbations, or errors in the algorithm. We obtain convergence rates for the values (Φ + Ψ)(x k) → min(Φ + Ψ) and convergence of the sequences generated by the (IFB) pert algorithm under conditions involving only the sequences (α k) and (g k) jointly. We first consider the general case where the only hypothesis that is made on g k is an appropriate summability property. This extends the recent work [6] of Attouch-Cabot which was devoted to the unperturbed case. Then we consider the case g k = −ε k y k with lim k ε k = 0, which corresponds to the introduction of a vanishing Tikhonov regularization in the algorithm. In this case, when ε k does not tend to zero too rapidly, we obtain strong ergodic convergence of the iterates to the solution of minimal norm. Taking a general sequence (α k) allows to cover a wide range of accelerated methods. In addition to the case α k = 1 − α k which improves FISTA on several points when α > 3, our results apply equally well to α k = 1 − α k r , and to Polyak's heavy ball method (α k constant). In this way, we show in a unifying way that these algorithms are robust with respect to perturbations.","authors":["Hedy Attouch","Alexandre Cabot","Zaki Chbani","Hassan Riahi"],"meta":["October 2018Journal of Optimization Theory and Applications 179(1)","DOI:10.1007/s10957-018-1369-3","Project: Dynamics with asymptotic vanishing damping"],"references":["317673689_Rate_of_convergence_of_the_Nesterov_accelerated_gradient_method_in_the_subcritical_case_alpha_leq_3","311221666_A_differential_equation_for_modeling_Nesterov's_accelerated_gradient_method_Theory_and_insights","328895887_Convergence_rate_of_inertial_Forward-Backward_algorithm_beyond_Nesterov's_rule","325446879_Computational_complexity","323785674_Convergence_Rates_of_Inertial_Forward-Backward_Algorithms","318382572_Asymptotic_stabilization_of_inertial_gradient_dynamics_with_time-dependent_viscosity","315573860_Convex_Analysis_and_Monotone_Operator_Theory_in_Hilbert_Spaces","315385151_Convex_Optimization_in_Normed_Spaces","312690325_Proximal_splitting_methods_in_signal_processing","312453300_Proximal_algorithms"]}