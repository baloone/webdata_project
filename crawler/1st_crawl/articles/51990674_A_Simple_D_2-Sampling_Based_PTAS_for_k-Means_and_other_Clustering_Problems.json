{"id":"51990674_A_Simple_D_2-Sampling_Based_PTAS_for_k-Means_and_other_Clustering_Problems","abstract":"Given a set of points $P \\subset \\mathbb{R}^d$, the $k$-means clustering\nproblem is to find a set of $k$ {\\em centers} $C = \\{c_1,...,c_k\\}, c_i \\in\n\\mathbb{R}^d,$ such that the objective function $\\sum_{x \\in P} d(x,C)^2$,\nwhere $d(x,C)$ denotes the distance between $x$ and the closest center in $C$,\nis minimized. This is one of the most prominent objective functions that have\nbeen studied with respect to clustering.\n$D^2$-sampling \\cite{ArthurV07} is a simple non-uniform sampling technique\nfor choosing points from a set of points. It works as follows: given a set of\npoints $P \\subseteq \\mathbb{R}^d$, the first point is chosen uniformly at\nrandom from $P$. Subsequently, a point from $P$ is chosen as the next sample\nwith probability proportional to the square of the distance of this point to\nthe nearest previously sampled points.\n$D^2$-sampling has been shown to have nice properties with respect to the\n$k$-means clustering problem. Arthur and Vassilvitskii \\cite{ArthurV07} show\nthat $k$ points chosen as centers from $P$ using $D^2$-sampling gives an\n$O(\\log{k})$ approximation in expectation. Ailon et. al. \\cite{AJMonteleoni09}\nand Aggarwal et. al. \\cite{AggarwalDK09} extended results of \\cite{ArthurV07}\nto show that $O(k)$ points chosen as centers using $D^2$-sampling give $O(1)$\napproximation to the $k$-means objective function with high probability. In\nthis paper, we further demonstrate the power of $D^2$-sampling by giving a\nsimple randomized $(1 + \\epsilon)$-approximation algorithm that uses the\n$D^2$-sampling in its core.","authors":["Ragesh Jaiswal","Amit Kumar","Sandeep Sen"],"meta":["January 2012Algorithmica 70(1)","DOI:10.1007/s00453-013-9833-9","SourcearXiv"],"references":["234804011_Applications_of_weighted_Voronoi_diagrams_and_randomization_to_variance-based-clustering","309715704_Least_squares_quantization_in_PCM","305092466_The_effectiveness_of_lloyd-type_methods_for_the_k-means_problem","303802749_Indexing_by_Latent_Semantic_Analysis","303151754_Least_squares_quantization","285205564_Turning_Big_data_into_tiny_data_Constant-size_coresets_for_k-means_PCA_and_projective_clustering","279584158_How_slow_is_the_k-means_method","243183177_On_k-Median_clustering_in_high_dimensions","238310890_Richard_Harshman_Indexing_by_Latent_Semantic_Analysis","228057706_Indexing_By_Latent_Semantic_Analysis"]}