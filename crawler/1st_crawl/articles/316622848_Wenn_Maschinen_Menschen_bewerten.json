{"id":"316622848_Wenn_Maschinen_Menschen_bewerten","authors":["Konrad Lischka"],"meta":["May 2017","DOI:10.11586/2017025"],"references":["306071857_Predictions_put_into_practice_a_quasi-experimental_evaluation_of_Chicago's_predictive_policing_pilot","306032039_False_Positives_False_Negatives_and_False_Analyses_A_Rejoinder_to_Machine_Bias_There's_Software_Used_Across_the_Country_to_Predict_Future_Criminals_And_it's_Biased_Against_Blacks","335042212_Does_Credit_Scoring_Produce_a_Disparate_Impact","318391540_Crime_is_Terribly_Revealing_Information_Technology_and_Police_Productivity","317996961_Disparate_Impact_in_Big_Data_Policing","316148690_Post-bac_admission_an_algorithmically_constrained_free_choice","309963438_Fake_glasses_fool_face_recognition_software","306300024_Combining_satellite_imagery_and_machine_learning_to_predict_poverty","288630219_Predictive_Policing_-_eine_Bestandsaufnahme","286690845_The_scored_society_Due_process_for_automated_predictions"]}