{"id":"331295573_REQ-YOLO_A_Resource-Aware_Efficient_Quantization_Framework_for_Object_Detection_on_FPGAs","abstract":"Deep neural networks (DNNs), as the basis of object detection, will play a key role in the development of future autonomous systems with full autonomy. The autonomous systems have special requirements of real-time, energy-e cient implementations of DNNs on a power-budgeted system. Two research thrusts are dedicated to per- formance and energy e ciency enhancement of the inference phase of DNNs. The first one is model compression techniques while the second is e cient hardware implementations. Recent researches on extremely-low-bit CNNs such as binary neural network (BNN) and XNOR-Net replace the traditional oating point operations with bi- nary bit operations, signi cantly reducing memory bandwidth and storage requirement, whereas suffering non-negligible accuracy loss and waste of digital signal processing (DSP) blocks on FPGAs. To overcome these limitations, this paper proposes REQ-YOLO, a resource aware, systematic weight quantization framework for object detection, considering both algorithm and hardware resource aspects in object detection. We adopt the block-circulant matrix method and propose a heterogeneous weight quantization using Alternative Direction Method of Multipliers (ADMM), an e ective optimization technique for general, non-convex optimization problems. To achieve real-time, highly efficient implementations on FPGA, we present the detailed hardware implementation of block circulant matrices on CONV layers and de- velop an e cient processing element (PE) structure supporting the heterogeneous weight quantization, CONV data ow and pipelining techniques, design optimization, and a template-based automatic synthesis framework to optimally exploit hardware resource. Experimental results show that our proposed REQ-YOLO framework can signi cantly compress the YOLO model while introducing very small accuracy degradation. The related codes are here: https://github.com/Anonymous788/heterogeneous_ADMM_YOLO.","authors":["Caiwen Ding","Shuo Wang","Ning Liu","Kaidi Xu"],"meta":["February 2019","DOI:10.1145/3289602.3293904","Conference: the 2019 ACM/SIGDA International Symposium"],"references":["328778467_TGPA_tile-grained_pipeline_architecture_for_low_latency_CNN_inference","323375650_A_Lightweight_YOLOv2_A_Binarized_CNN_with_A_Parallel_Support_Vector_Regression_for_an_FPGA","323373772_C-LSTM_Enabling_Efficient_LSTM_using_Structured_Compression_Techniques_on_FPGAs","319391648_CirCNN_Accelerating_and_Compressing_Deep_Neural_Networks_Using_Block-CirculantWeight_Matrices","317574806_Automated_Systolic_Array_Architecture_Synthesis_for_High_Throughput_CNN_Inference_on_FPGAs","314153532_Theoretical_Properties_for_Neural_Networks_with_Weight_Matrices_of_Low_Displacement_Rank","313263619_ESE_Efficient_Speech_Recognition_Engine_with_Sparse_LSTM_on_FPGA","311754552_Fused-layer_CNN_accelerators","287853408_Quantized_Convolutional_Neural_Networks_for_Mobile_Devices","284476540_Fixed_Point_Quantization_of_Deep_Convolutional_Networks","260666581_Pipelined_Architectures_for_Real-Valued_FFT_and_Hermitian-Symmetric_IFFT_With_Real_Datapaths","258386321_High-Level_Synthesis_Productivity_Performance_and_Software_Constraints","220659463_The_Pascal_Visual_Object_Classes_VOC_challenge","220416607_Distributed_Optimization_and_Statistical_Learning_via_the_Alternating_Direction_Method_of_Multipliers","330889812_Evaluating_Fast_Algorithms_for_Convolutional_Neural_Networks_on_FPGAs","325864379_SpWA_an_efficient_sparse_winograd_convolutional_neural_networks_accelerator_on_FPGAs","324387691_YOLOv3_An_Incremental_Improvement","323091798_Convolutional_SVM_Networks_for_Object_Detection_in_UAV_Imagery","322905389_Hardware_Implementation_and_Optimization_of_Tiny-YOLO_Network","320967941_YOLO9000_Better_Faster_Stronger","319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation","319770323_EIE_Efficient_Inference_Engine_on_Compressed_Deep_Neural_Network","318830298_Deep_Learning_at_Alibaba","318125227_Evaluating_Fast_Algorithms_for_Convolutional_Neural_Networks_on_FPGAs","317576355_A_Comprehensive_Framework_for_Synthesizing_Stencil_Algorithms_on_FPGAs_using_OpenCL_Model","317574945_FlexCL_An_Analytical_Performance_Model_for_OpenCL_Workloads_on_Flexible_FPGAs","317574943_Exploring_Heterogeneous_Algorithms_for_Accelerating_Deep_Convolutional_Neural_Networks_on_FPGAs","313645220_Batch_Renormalization_Towards_Reducing_Minibatch_Dependence_in_Batch-Normalized_Models","311791725_FINN_A_Framework_for_Fast_Scalable_Binarized_Neural_Network_Inference","311609522_You_Only_Look_Once_Unified_Real-Time_Object_Detection","311609041_Deep_Residual_Learning_for_Image_Recognition","311491247_Going_Deeper_with_Embedded_FPGA_Platform_for_Convolutional_Neural_Network","308277265_A_Unified_Multi-scale_Deep_Convolutional_Neural_Network_for_Fast_Object_Detection","308277088_XNOR-Net_ImageNet_Classification_Using_Binary_Convolutional_Neural_Networks","307799804_Deep_learning_convolutional_networks","301367952_Optimizing_FPGA-based_Accelerator_Design_for_Deep_Convolutional_Neural_Networks","283471201_BinaryConnect_Training_Deep_Neural_Networks_with_binary_weights_during_propagations","275669302_Fast_r-cnn","272194743_Batch_Normalization_Accelerating_Deep_Network_Training_by_Reducing_Internal_Covariate_Shift","269935079_Adam_A_Method_for_Stochastic_Optimization","267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks","258374356_Rich_Feature_Hierarchies_for_Accurate_Object_Detection_and_Semantic_Segmentation","229099884_An_Algorithm_for_the_Machine_Calculation_of_Complex_Fourier_Series","228389368_Mathematics_of_the_discrete_fourier_transform_DFT","224210095_Comparing_performance_and_energy_efficiency_of_FPGAs_and_GPUs_for_high_productivity_computing","3325938_An_efficient_pipelined_FFT_architecture"]}