{"id":"301848040_Overdispersed_Black-Box_Variational_Inference","abstract":"We introduce overdispersed black-box variational inference, a method to reduce the variance of the Monte Carlo estimator of the gradient in black-box variational inference. Instead of taking samples from the variational distribution, we use importance sampling to take samples from an overdispersed distribution in the same exponential family as the variational approximation. Our approach is general since it can be readily applied to any exponential family distribution, which is the typical choice for the variational approximation. We run experiments on two non-conjugate probabilistic models to show that our method effectively reduces the variance, and the overhead introduced by the computation of the proposal parameters and the importance weights is negligible. We find that our overdispersed importance sampling scheme provides lower variance than black-box variational inference, even when the latter uses twice the number of samples. This results in faster convergence of the black-box inference procedure.","authors":["Francisco Ruiz","Michalis K. Titsias","David M. Blei"],"meta":["March 2016"],"references":["283762228_Generalized_Multiple_Importance_Sampling","329469526_Exponential_Dispersion_Models","319770229_Auto-Encoding_Variational_Bayes","319770134_Stochastic_Backpropagation_and_Approximate_Inference_in_Deep_Generative_Models","287408893_Doubly_stochastic_variational_bayes_for_non-conjugate_inference","284476307_Variational_Gaussian_Process","283658966_Hierarchical_Variational_Models","281487457_Importance_Weighted_Autoencoders","280104192_Black-Box_Policy_Search_with_Probabilistic_Programs","279964320_Simple_statistical_gradient-following_algorithms_for_connectionist_reinforcement_learning"]}