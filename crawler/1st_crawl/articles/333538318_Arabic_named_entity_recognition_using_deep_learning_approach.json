{"id":"333538318_Arabic_named_entity_recognition_using_deep_learning_approach","abstract":"Most of the Arabic Named Entity Recognition (NER) systems depend massively on external resources and handmade feature engineering to achieve state-of-the-art results. To overcome such limitations, we proposed, in this paper, to use deep learning approach to tackle the Arabic NER task. We introduced a neural network architecture based on bidirectional Long Short-Term Memory (LSTM) and Conditional Random Fields (CRF) and experimented with various commonly used hyperparameters to assess their effect on the overall performance of our system. Our model gets two sources of information about words as input: pre-trained word embeddings and character-based representations and eliminated the need for any task-specific knowledge or feature engineering. We obtained state-of-the-art result on the standard ANERcorp corpus with an F1 score of 90.6%.","authors":["Ismail El Bazi","Nabil Laachfoubi"],"meta":["June 2019International Journal of Electrical and Computer Engineering 9(3):2025","DOI:10.11591/ijece.v9i3.pp2025-2032"],"references":["336888234_Sentimental_Analysis_of_Twitter_Data_using_Classifier_Algorithms","332578851_Deep_Machine_Learning_and_Neural_Networks_An_Overview","323415940_Arabic_Named_Entity_Recognition_Using_Topic_Modeling","309660117_A_Coreference_Resolution_Approach_using_Morphological_Features_in_Arabic","308026508_WaveNet_A_Generative_Model_for_Raw_Audio","329740202_Squeeze-and-Excitation_Networks","322582509_Reporting_Score_Distributions_Makes_a_Difference_Performance_Study_of_LSTM-networks_for_Sequence_Tagging","319769994_A_Theoretically_Grounded_Application_of_Dropout_in_Recurrent_Neural_Networks","317558625_Attention_Is_All_You_Need","307955489_Distributed_representations_of_words_and_phrases_and_their_compositionality"]}