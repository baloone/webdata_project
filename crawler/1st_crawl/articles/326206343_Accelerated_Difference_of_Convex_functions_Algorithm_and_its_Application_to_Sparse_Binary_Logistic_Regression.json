{"id":"326206343_Accelerated_Difference_of_Convex_functions_Algorithm_and_its_Application_to_Sparse_Binary_Logistic_Regression","abstract":"In this work, we present a variant of DCA (Difference of Convex function Algorithm) with the aim to improve its convergence speed. The proposed algorithm, named Accelerated DCA (ADCA), consists in incorporating the Nesterov's acceleration technique into DCA. We first investigate ADCA for solving the standard DC program and rigorously study its convergence properties and the convergence rate. Secondly, we develop ADCA for a special case of the standard DC program whose the objective function is the sum of a differentiable with L-Lipschitz gradient function (possibly nonconvex) and a nonsmooth DC function. We exploit the special structure of the problem to propose an efficient DC decomposition for which the corresponding ADCA scheme is inexpensive. As an application, we consider the sparse binary logistic regression problem. Numerical experiments on several benchmark datasets illustrate the efficiency of our algorithm and its superiority over well-known methods.","authors":["Duy Nhat PHAN","Le Hoai Minh","Hoai An Le Thi"],"meta":["July 2018","DOI:10.24963/ijcai.2018/190","Conference: Twenty-Seventh International Joint Conference on Artificial Intelligence {IJCAI-18}"],"references":["275670577_Splitting_Methods_with_Variable_Metric_for_Kurdyka-Lojasiewicz_Functions_and_General_Convergence_Rates","220589510_On_the_convergence_of_the_proximal_algorithm_for_nonsmooth_functions_involving_analytic_features","265587896_Convex_analysis_approach_to_dc_programming_Theory_Algorithm_and_Applications","225263857_The_DC_Difference_of_Convex_Functions_Programming_and_DCA_Revisited_with_DC_Models_of_Real_World_Nonconvex_Optimization_Problems","224567393_Fast_Gradient-Based_Algorithms_for_Constrained_Total_Variation_Image_Denoising_and_Deblurring_Problems"]}