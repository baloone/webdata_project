{"id":"333515959_Insights_and_approaches_using_deep_learning_to_classify_wildlife","abstract":"The implementation of intelligent software to identify and classify objects and individuals in visual fields is a technology of growing importance to operatives in many fields, including wildlife conservation and management. To non-experts, the methods can be abstruse and the results mystifying. Here, in the context of applying cutting edge methods to classify wildlife species from camera-trap data, we shed light on the methods themselves and types of features these methods extract to make efficient identifications and reliable classifications. The current state of the art is to employ convolutional neural networks (CNN) encoded within deep-learning algorithms. We outline these methods and present results obtained in training a CNN to classify 20 African wildlife species with an overall accuracy of 87.5% from a dataset containing 111,467 images. We demonstrate the application of a gradient-weighted class-activation-mapping (Grad-CAM) procedure to extract the most salient pixels in the final convolution layer. We show that these pixels highlight features in particular images that in some cases are similar to those used to train humans to identify these species. Further, we used mutual information methods to identify the neurons in the final convolution layer that consistently respond most strongly across a set of images of one particular species. We then interpret the features in the image where the strongest responses occur, and present dataset biases that were revealed by these extracted features. We also used hierarchical clustering of feature vectors (i.e., the state of the final fully-connected layer in the CNN) associated with each image to produce a visual similarity dendrogram of identified species. Finally, we evaluated the relative unfamiliarity of images that were not part of the training set when these images were one of the 20 species “known” to our CNN in contrast to images of the species that were “unknown” to our CNN.","authors":["Zhongqi Miao","Kaitlyn Gaynor","Jiayun Wang","Ziwei Liu"],"meta":["May 2019Scientific Reports 9(1)","DOI:10.1038/s41598-019-44565-w"],"references":["325758611_Machine_learning_to_classify_animal_species_in_camera_trap_images_applications_in_ecology","319164005_Evaluating_Visual_Conversational_Agents_via_Cooperative_Human-AI_Games","317663500_A_review_of_camera_trapping_for_conservation_behaviour_research","315382917_Automatically_identifying_wild_animals_in_camera_trap_images_with_deep_learning","332089096_Visual_Cortex_and_Deep_Networks_Learning_Invariant_Representations","327000784_Machine_learning_for_image_based_species_identification","322929400_Visual_Interpretability_for_Deep_Learning_a_Survey","322058942_Grad-CAM_Visual_Explanations_from_Deep_Networks_via_Gradient-Based_Localization","319770291_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition","319501432_The_Devil_is_in_the_Tails_Fine-grained_Classification_in_the_Wild"]}