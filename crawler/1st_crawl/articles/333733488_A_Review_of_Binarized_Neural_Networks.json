{"id":"333733488_A_Review_of_Binarized_Neural_Networks","abstract":"In this work, we review Binarized Neural Networks (BNNs). BNNs are deep neural networks that use binary values for activations and weights, instead of full precision values. With binary values, BNNs can execute computations using bitwise operations, which reduces execution time. Model sizes of BNNs are much smaller than their full precision counterparts. While the accuracy of a BNN model is generally less than full precision models, BNNs have been closing accuracy gap and are becoming more accurate on larger datasets like ImageNet. BNNs are also good candidates for deep learning implementations on FPGAs and ASICs due to their bitwise efficiency. We give a tutorial of the general BNN methodology and review various contributions, implementations and applications of BNNs.","authors":["Taylor Simons","Lee Dah-Jye"],"meta":["June 2019Electronics 8(6):661","DOI:10.3390/electronics8060661"],"references":["333374783_Low_Bit-width_Convolutional_Neural_Network_on_RRAM","331216639_A_Fully_Onchip_Binarized_Convolutional_Neural_Network_FPGA_Impelmentation_with_Accurate_Inference","330591229_A_new_hardware_implementation_approach_of_BNNs_based_on_nonlinear_2T2R_synaptic_cell","330470173_Low_Bits_Binary_Neural_Network_for_Vad_and_Wakeup","329740375_SYQ_Learning_Symmetric_Quantization_for_Efficient_Deep_Neural_Networks","329733296_FINN-_R_An_End-to-End_Deep-Learning_Framework_for_Fast_Exploration_of_Quantized_Neural_Networks","329623777_Computing-in-Memory_with_SRAM_and_RRAM_for_Binary_Neural_Networks","329599563_Lightening_the_Load_with_Highly_Accurate_Storage-_and_Energy-Efficient_LightNNs","329599490_High-Efficiency_Convolutional_Ternary_Neural_Networks_with_Custom_Adder_Trees_and_Weight_Compression","329481282_FINN-L_Library_Extensions_and_Design_Trade-Off_Analysis_for_Variable_Precision_LSTM_Networks_on_FPGAs"]}