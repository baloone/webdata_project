{"id":"325411384_Learning_to_detect_localize_and_recognize_many_text_objects_in_document_images_from_few_examples","abstract":"The current trend in object detection and localization is to learn predictions with high capacity deep neural networks trained on a very large amount of annotated data and using a high amount of processing power. In this work, we particularly target the detection of text in document images and we propose a new neural model which directly predicts object coordinates. The particularity of our contribution lies in the local computations of predictions with a new form of local parameter sharing which keeps the overall amount of trainable parameters low. Key components of the model are spatial 2D-LSTM recurrent layers which convey contextual information between the regions of the image. We show that this model is more powerful than the state of the art in applications where training data are not as abundant as in the classical configuration of natural images and Imagenet/Pascal-VOC tasks. The proposed model also facilitates the detection of many objects in a single image and can deal with inputs of variable sizes without resizing. To enhance the localization precision of the coordinate regressor, we limit the amount of information produced by the local model components and propose two different regression strategies: (i) separately predict lower-left and upper-right corners of each object bounding box, followed by combinatorial pairing; (ii) only predict the left side of the objects and estimate the right position jointly with text recognition. These strategies lead to good full-page text recognition results in heterogeneous documents. Experiments have been performed on a document analysis task, the localization of the text lines in the Maurdor dataset.","authors":["Bastien Moysset","Christopher Kermorvant","Christian Wolf"],"meta":["September 2018International Journal on Document Analysis and Recognition (IJDAR) 21(2)","DOI:10.1007/s10032-018-0305-2"],"references":["319770289_Deep_Neural_Networks_for_Object_Detection","316432841_Arbitrary-Oriented_Scene_Text_Detection_via_Rotation_Proposals","332814130_Deformable_Part-based_Fully_Convolutional_Network_for_Object_Detection","322780204_Convolutional_Neural_Networks_for_Page_Segmentation_of_Historical_Document_Images","320971439_Deep_Matching_Prior_Network_Toward_Tighter_Multi-oriented_Text_Detection","319770430_Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation","319770327_Multi-Scale_Context_Aggregation_by_Dilated_Convolutions","319770168_Fully_Convolutional_Networks_for_Semantic_Segmentation","319769911_Faster_R-CNN_Towards_Real-Time_Object_Detection_with_Region_Proposal_Networks","318560287_Deformable_Part-based_Fully_Convolutional_Network_for_Object_Detection","314258514_Deep_Matching_Prior_Network_Toward_Tighter_Multi-oriented_Text_Detection","313527089_Distinctive_image_features_from_scale-invariant_key_points","311611550_Synthetic_Data_for_Text_Localisation_in_Natural_Images","311611062_Inside-Outside_Net_Detecting_Objects_in_Context_with_Skip_Pooling_and_Recurrent_Neural_Networks","311610815_Multi-oriented_Text_Detection_with_Fully_Convolutional_Networks"]}