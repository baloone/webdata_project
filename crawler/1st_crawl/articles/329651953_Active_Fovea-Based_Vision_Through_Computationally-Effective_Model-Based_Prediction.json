{"id":"329651953_Active_Fovea-Based_Vision_Through_Computationally-Effective_Model-Based_Prediction","abstract":"What motivates an action in the absence of a definite reward? Taking the case of visuomotor control, we consider a minimal control problem that is how select the next saccade, in a sequence of discrete eye movements, when the final objective is to better interpret the current visual scene. The visual scene is modeled here as a partially-observed environment, with a generative model explaining how the visual data is shaped by action. This allows to interpret different action selection metrics proposed in the literature, including the Salience, the Infomax and the Variational Free Energy, under a single information theoretic construct, namely the view-based Information Gain. Pursuing this analytic track, two original action selection metrics named the Information Gain Lower Bound (IGLB) and the Information Gain Upper Bound (IGUB) are then proposed. Showing either a conservative or an optimistic bias regarding the Information Gain, they strongly simplify its calculation. An original fovea-based visual scene decoding setup is then proposed, with numerical experiments highlighting different facets of artificial fovea-based vision. A first and principal result is that state-of-the-art recognition rates are obtained with fovea-based saccadic exploration, using less than 10% of the original image's data. Those satisfactory results illustrate the advantage of mixing predictive control with accurate state-of-the-art predictors, namely a deep neural network. A second result is the sub-optimality of some classical action-selection metrics widely used in the literature, that is not manifest with finely-tuned inference models, but becomes patent when coarse or faulty models are used. Last, a computationally-effective predictive model is developed using the IGLB objective, with pre-processed visual scan-path read-out from memory, bypassing computationally-demanding predictive calculations. This last simplified setting is shown effective in our case, showing both a competing accuracy and a good robustness to model flaws.","authors":["Emmanuel Dauc√©"],"meta":["December 2018Frontiers in Neurorobotics 12","DOI:10.3389/fnbot.2018.00076","Project: Active inference"],"references":["303698546_VIME_Variational_Information_Maximizing_Exploration","303496415_Sequential_Neural_Models_with_Stochastic_Layers","319284083_Curiosity-Driven_Exploration_by_Self-Supervised_Prediction","316955874_Curiosity-driven_Exploration_by_Self-supervised_Prediction","312653276_Topography_of_the_layer_of_rods_and_cones_in_the_human_retina","310627938_Active_Inference_A_Process_Theory","304813319_Active_multi-view_object_recognition_A_unifying_view_on_online_feature_selection_and_view_planning","292136499_A_saliency-based_search_mechanism_for_overt_and_covert_shifts_of_visual_attention","285483611_Learning_to_generate_artificial_fovea_trajectories_for_target_detection","284004486_Simple_Algorithmic_Principles_of_Discovery_Subjective_Beauty_Selective_Attention_Curiosity_Creativity"]}