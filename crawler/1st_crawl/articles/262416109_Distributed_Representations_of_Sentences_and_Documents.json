{"id":"262416109_Distributed_Representations_of_Sentences_and_Documents","abstract":"Many machine learning algorithms require the input to be represented as a\nfixed-length feature vector. When it comes to texts, one of the most common\nfixed-length features is bag-of-words. Despite their popularity, bag-of-words\nfeatures have two major weaknesses: they lose the ordering of the words and\nthey also ignore semantics of the words. For example, \"powerful,\" \"strong\" and\n\"Paris\" are equally distant. In this paper, we propose Paragraph Vector, an\nunsupervised algorithm that learns fixed-length feature representations from\nvariable-length pieces of texts, such as sentences, paragraphs, and documents.\nOur algorithm represents each document by a dense vector which is trained to\npredict words in the document. Its construction gives our algorithm the\npotential to overcome the weaknesses of bag-of-words models. Empirical results\nshow that Paragraph Vectors outperforms bag-of-words models as well as other\ntechniques for text representations. Finally, we achieve new state-of-the-art\nresults on several text classification and sentiment analysis tasks.","authors":["Quoc V. Le","Tomas Mikolov"],"meta":["May 2014","SourcearXiv"],"references":["266201822_Natural_Language_Processing_Almost_from_Scratch","257069350_Modeling_Documents_with_Deep_Boltzmann_Machines","228452494_Dynamic_Pooling_and_Unfolding_Recursive_Autoencoders_for_Paraphrase_Detection","221345755_Parsing_Natural_Scenes_and_Natural_Language_with_Recursive_Neural_Networks","221101423_Estimating_Linear_Models_for_Compositional_Distributional_Semantics","220873867_Learning_Word_Vectors_for_Sentiment_Analysis","220873681_Word_Representations_A_Simple_and_General_Method_for_Semi-Supervised_Learning","45904528_From_Frequency_to_Meaning_Vector_Space_Models_of_Semantics","319770369_Distributed_Representations_of_Words_and_Phrases_and_their_Compositionality","319770263_Reasoning_With_Neural_Tensor_Networks_for_Knowledge_Base_Completion","312375903_Neural_Probabilistic_Language_Models","291295837_Reasoning_with_neural_tensor_networks_for_knowledge_base_completion","291286882_DeViSE_A_deep_visual-semantic_embedding_model","289958448_A_neural_autoregressive_topic_model","285895924_Linguistic_regularities_in_continuous_space_word_representations","266458936_Statistical_Language_Models_Based_on_Neural_Networks","262204398_Baselines_and_Bigrams_Simple_Good_Sentiment_and_Topic_Classification","262201777_Improving_word_representations_via_global_context_and_multiple_word_prototypes","256663215_Exploiting_Similarities_among_Languages_for_Machine_Translation","229091480_Learning_Representations_by_Back_Propagating_Errors","224716280_Fisher_Kernels_on_Visual_Vocabularies_for_Image_Categorization","221618232_A_Scalable_Hierarchical_Distributed_Language_Model","221345848_A_unified_architecture_for_natural_language_processing_Deep_neural_networks_with_multitask_learning","221013323_Semi-Supervised_Recursive_Autoencoders_for_Predicting_Sentiment_Distributions","221013069_Compositional_Matrix-Space_Models_for_Sentiment_Analysis","220016375_Large-scale_image_retrieval_with_compressed_Fisher_vectors","51119064_Composition_in_Distributional_Models_of_Semantics","2463681_Exploiting_Generative_Models_in_Discriminative_Classifiers"]}