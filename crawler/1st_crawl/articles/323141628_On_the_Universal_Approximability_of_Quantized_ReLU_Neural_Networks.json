{"id":"323141628_On_the_Universal_Approximability_of_Quantized_ReLU_Neural_Networks","abstract":"Compression is a key step to deploy large neural networks on resource-constrained platforms. As a popular compression technique, quantization constrains the number of distinct weight values and thus reducing the number of bits required to represent and store each weight. In this paper, we study the representation power of quantized neural networks. First, we prove the universal approximability of quantized ReLU networks. Then we provide upper bounds of storage size given the approximation error bound and the bit-width of weights for function-independent and function-dependent structures. To the best of the authors' knowledge, this is the first work on the universal approximability as well as the associated storage size bound of quantized neural networks.","authors":["Yukun Ding","Jinglan Liu","Yiyu Shi"],"meta":["February 2018"],"references":["321511025_Adaptive_Quantization_for_Deep_Neural_Network","320796791_Towards_Effective_Low-bitwidth_Convolutional_Neural_Networks","320582768_Learning_Discrete_Weights_Using_the_Local_Reparameterization_Trick","319035722_Universal_Function_Approximation_by_Deep_Neural_Nets_with_Bounded_Width_and_ReLU_Activations","317425461_Training_Quantized_Nets_A_Deeper_Understanding","315667264_Efficient_Processing_of_Deep_Neural_Networks_A_Tutorial_and_Survey","314153532_Theoretical_Properties_for_Neural_Networks_with_Weight_Matrices_of_Low_Displacement_Rank","313645102_Incremental_Network_Quantization_Towards_Lossless_CNNs_with_Low-Precision_Weights","308896188_Error_bounds_for_approximations_with_deep_ReLU_networks","308844880_Sparse_Convolutional_Neural_Networks","308457764_Quantized_Neural_Networks_Training_Neural_Networks_with_Low_Precision_Weights_and_Activations","301878495_SqueezeNet_AlexNet-level_accuracy_with_50x_fewer_parameters_and_05MB_model_size","261368736_Exploiting_Linear_Structure_Within_Convolutional_Networks_for_Efficient_Evaluation","243026406_Approximation_by_superposition_of_sigmoidal_and_radial_basis_functions","319770334_Deep_Compression_Compressing_Deep_Neural_Networks_with_Pruning_Trained_Quantization_and_Huffman_Coding","318814425_Extremely_Low_Bit_Neural_Network_Squeeze_the_Last_Bit_Out_with_ADMM","311458156_Towards_the_Limit_of_Network_Quantization","311430286_Trained_Ternary_Quantization","308277088_XNOR-Net_ImageNet_Classification_Using_Binary_Convolutional_Neural_Networks","306187229_Learning_Structured_Sparsity_in_Deep_Neural_Networks","301876620_Hardware-oriented_Approximation_of_Convolutional_Neural_Networks","283471201_BinaryConnect_Training_Deep_Neural_Networks_with_binary_weights_during_propagations","282181009_Provable_approximation_properties_for_deep_neural_networks","277959043_Learning_both_Weights_and_Connections_for_Efficient_Neural_Networks","275974753_Empirical_Evaluation_of_Rectified_Activations_in_Convolutional_Network"]}