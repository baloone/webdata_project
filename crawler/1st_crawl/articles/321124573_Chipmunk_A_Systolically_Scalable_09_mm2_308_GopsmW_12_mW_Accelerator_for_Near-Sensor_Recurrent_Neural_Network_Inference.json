{"id":"321124573_Chipmunk_A_Systolically_Scalable_09_mm2_308_GopsmW_12_mW_Accelerator_for_Near-Sensor_Recurrent_Neural_Network_Inference","abstract":"Recurrent neural networks (RNNs) are state-of-the-art in voice awareness/understanding and speech recognition. On-device computation of RNNs on low-power mobile and wearable devices would be key to applications such as zero-latency voice-based human-machine interfaces. Here we present Chipmunk, a small (<1 mm${}^2$) hardware accelerator for Long-Short Term Memory RNNs in UMC 65 nm technology capable to operate at a measured peak efficiency up to 3.08 Gop/s/mW at 1.24 mW peak power. To implement big RNN models without incurring in huge memory transfer overhead, multiple Chipmunk engines can cooperate to form a single systolic array. In this way, the Chipmunk architecture in a 75 tiles configuration can achieve real-time phoneme extraction on a demanding RNN topology proposed by Graves et al., consuming less than 13 mW of average power.","authors":["Francesco Conti","Lukas Cavigelli","Gianna Paulin","Igor Susmelj"],"meta":["November 2017","Project: BRAINSEE"],"references":["317613363_In-Datacenter_Performance_Analysis_of_a_Tensor_Processing_Unit","315667264_Efficient_Processing_of_Deep_Neural_Networks_A_Tutorial_and_Survey","315054919_YodaNN_An_Architecture_for_Ultralow_Power_Binary-Weight_CNN_Acceleration","313263619_ESE_Efficient_Speech_Recognition_Engine_with_Sparse_LSTM_on_FPGA","311737048_An_IoT_Endpoint_System-on-Chip_for_Secure_and_Energy-Efficient_Near-Sensor_Analytics","305417715_A_803_GOpsW_Convolutional_Network_Accelerator","320091463_Hardware_accelerators_for_recurrent_neural_networks_on_FPGA","317722873_The_microsoft_2016_conversational_speech_recognition_system","316946835_Hardware_architecture_of_Bidirectional_Long_Short-Term_Memory_Neural_Network_for_Optical_Character_Recognition","314296599_142_DNPU_An_81TOPSW_reconfigurable_CNN-RNN_processor_for_general-purpose_deep_neural_networks"]}