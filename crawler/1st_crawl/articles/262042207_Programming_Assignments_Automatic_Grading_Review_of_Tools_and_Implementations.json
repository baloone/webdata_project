{"id":"262042207_Programming_Assignments_Automatic_Grading_Review_of_Tools_and_Implementations","abstract":"Automatic grading of programming assignments is an important topic in academic research. It aims at improving the level of feedback given to students and optimizing the professor’s time. Its importance is more remarkable as the amount and complexity of assignments increases. Several studies have reported the development of software tools to support this process. They usually consider particular deployment scenarios and specific requirements of the interested institution. However, the quantity and diversity of these tools makes it difficult to get a quick and accurate idea of their features. This paper reviews an ample set of tools for automatic grading of programming assignments. The review includes a description of every tool selected and their key features. Among others, the key features analyzed include the programming language used to build the tool, the programming languages supported for grading, the criteria applied in the evaluation process, the work mode (as a plugin, as an independent tool, etc.), the logical and deployment architectures, and the communications technology used. Then, implementations and operation results are described with quantitative and qualitative indicators to understand how successful the tools were. Quantitative indicators include number of courses, students, tasks, submissions considered for tests, and acceptance percentage after tests. Qualitative indicators include motivation, support, and skills improvement. A comparative analysis among the tools is shown, and as result a set of common gaps detected is provided. The lack of normalized evaluation criteria for assignments is identified as a key gap in the reviewed tools. Thus, an evaluation metrics frame to grade programming assignments is proposed. The results indicate that many of the analyzed features highly depend on the current technology infrastructure that supports the teaching process. Therefore, they are a limiting factor in reusing the tools in new implementation cases. Another fact is the inability to support new programming languages, which is limited by tools’ updates. On metrics for evaluation process, the set of analyzed tools showed much diversity and inflexibility. Knowing which implementation features are always specific and particular independently of the project, and which others could be common will be helpful before the implementation and operation of a tool. Considering how much flexibility could be attained in the evaluation process will be helpful to design a new tool, which will be used not only in particular cases, and to define the automation level of the evaluation process.","authors":["Julio C. Caiza","Jose M. Del Alamo"],"meta":["January 2013","Conference: 7th International Technology, Education and Development ConferenceAt: Valencia (Spain)"],"references":["275652921_A_Virtual_Programming_Lab_for_Moodle_with_automatic_assessment_and_anti-plagiarism_features","257717161_Java_Programming_Assessment_Tool_for_Assignment_Module_in_Moodle_E-learning_System","237228089_Hacia_la_Evaluacion_Continua_Automatica_de_Practicas_de_Programacion","216714976_Review_of_recent_systems_for_automatic_assessment_of_programming_assignments","318760435_Design_and_Implementation_of_an_Automated_System_for_Assessment_of_Computer_Programming_Assignments","311465388_Towards_generic_and_flexible_web_services_for_e-assessment","233834599_PETCHA_A_programming_exercises_teaching_assistant","224171612_Automatic_programming_assessment_and_test_data_generation_a_review_on_its_approaches","220424604_Automatic_grading_programs","220140316_Ability-training-oriented_automated_assessment_in_introductory_programming_course","220094452_Automated_assessment_and_experiences_of_teaching_programming","48457063_Automatic_Grading_of_Programming_Assignments","4007218_Diagram-based_CBA_using_DATsys_and_CourseMaster"]}