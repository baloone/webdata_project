{"id":"330806491_Evaluating_research_and_researchers_by_the_journal_impact_factor_Is_it_better_than_coin_flipping","abstract":"The journal impact factor (JIF) is the average of the number of citations of the papers published in a journal, calculated according to a specific formula; it is extensively used for the evaluation of research and researchers. The method assumes that all papers in a journal have the same scientific merit, which is measured by the JIF of the publishing journal. This implies that the number of citations measures scientific merits but the JIF does not evaluate each individual paper by its own number of citations. Therefore, in the comparative evaluation of two papers, the use of the JIF implies a risk of failure, which occurs when a paper in the journal with the lower JIF is compared to another with fewer citations in the journal with the higher JIF. To quantify this risk of failure, this study calculates the failure probabilities, taking advantage of the lognormal distribution of citations. In two journals whose JIFs are ten-fold different, the failure probability is low. However, in most cases when two papers are compared, the JIFs of the journals are not so different. Then, the failure probability can be close to 0.5, which is equivalent to evaluating by coin flipping.","authors":["Ricardo Brito","Alonso Rodriguez-Navarro"],"meta":["February 2019Journal of Informetrics 13(1):314-324","DOI:10.1016/j.joi.2019.01.009"],"references":["319664093_Use_of_the_journal_impact_factor_as_a_criterion_for_the_selection_of_junior_researchers_A_rejoinder_on_a_comment_by_Peters_2017","319386846_Why_not_to_use_the_journal_impact_factor_as_a_criterion_for_the_selection_of_junior_researchers_A_comment_on_Bornmann_and_Williams_2017","318316216_Core_Elements_in_the_Process_of_Citing_Publications_A_Conceptual_Overview_of_the_Literature","317711705_Can_the_Journal_Impact_Factor_Be_Used_as_a_Criterion_for_the_Selection_of_Junior_Researchers_A_Large-Scale_Empirical_Study_Based_on_ResearcherID_Data","317066696_Indicators_as_judgment_devices_An_empirical_study_of_citizen_bibliometrics_in_research_evaluation","315807992_Science_deserves_to_be_judged_by_its_contents_not_by_its_wrapping_Revisiting_Seglen's_work_on_journal_impact_and_research_evaluation","308152662_Professional_and_Citizen_Bibliometrics_Complementarities_and_ambivalences_in_the_development_and_use_of_indicators","301837310_Citations_Indicators_of_Quality_The_Impact_Fallacy","242915706_Relative_indicators_and_relational_charts_for_comparative_assessment_of_publication_output_and_citation_impact","235633880_How_to_evaluate_individual_researchers_working_in_the_natural_and_life_sciences_meaningfully_A_proposal_of_methods_based_on_percentiles_of_citations","235521593_How_good_is_research_really-Measuring_the_citation_impact_of_publications_with_percentiles_increases_correct_assessments_and_fair_comparisons","225953173_Cross-field_normalization_of_scientometric_indicators","220364575_Citations_versus_Journal_Impact_Factor_as_Proxy_of_Quality_Could_the_Latter_Ever_Be_Preferable","40455314_A_Conceptual_and_Empirical_Examination_of_Justifications_for_Dichotomization","325835103_How_will_you_judge_me_if_not_by_impact_factor","322194152_Double_rank_analysis_for_research_assessment","318564276_Bias_against_novelty_in_science_A_cautionary_tale_for_users_of_bibliometric_indicators","312083461_Citation_success_index_-_An_intuitive_pair-wise_journal_comparison_metric","305322064_Citation_count_distributions_for_large_monodisciplinary_journals","305310978_Beat_it_impact_factor_Publishing_elite_turns_against_controversial_metric","279968736_A_review_of_the_literature_on_citation_impact_indicators","220365058_History_of_the_journal_impact_factor_Contingencies_and_consequences","220230934_A_combined_bibliometric_indicator_to_predict_article_impact","14154390_Why_the_Impact_Factor_of_Journals_Should_Not_Be_Used_for_Evaluating_Research","11952712_Impact_factors_and_why_they_won't_go_away"]}