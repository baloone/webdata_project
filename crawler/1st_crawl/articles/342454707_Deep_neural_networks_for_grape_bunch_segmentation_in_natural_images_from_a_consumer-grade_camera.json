{"id":"342454707_Deep_neural_networks_for_grape_bunch_segmentation_in_natural_images_from_a_consumer-grade_camera","abstract":"Precision agriculture relies on the availability of accurate knowledge of crop phenotypic traits at the sub-field level. While visual inspection by human experts has been traditionally adopted for phenotyping estimations, sensors mounted on field vehicles are becoming valuable tools to increase accuracy on a narrower scale and reduce execution time and labor costs, as well. In this respect, automated processing of sensor data for accurate and reliable fruit detection and characterization is a major research challenge, especially when data consist of low-quality natural images. This paper investigates the use of deep learning frameworks for automated segmentation of grape bunches in color images from a consumer-grade RGB-D camera, placed on-board an agricultural vehicle. A comparative study, based on the estimation of two image segmentation metrics, i.e. the segmentation accuracy and the well-known Intersection over Union (IoU), is presented to estimate the performance of four pre-trained network architectures, namely the AlexNet, the GoogLeNet, the VGG16, and the VGG19. Furthermore, a novel strategy aimed at improving the segmentation of bunch pixels is proposed. It is based on an optimal threshold selection of the bunch probability maps, as an alternative to the conventional minimization of cross-entropy loss of mutually exclusive classes. Results obtained in field tests show that the proposed strategy improves the mean segmentation accuracy of the four deep neural networks in a range between 2.10 and 8.04%. Besides, the comparative study of the four networks demonstrates that the best performance is achieved by the VGG19, which reaches a mean segmentation accuracy on the bunch class of 80.58%, with IoU values for the bunch class of 45.64%.","authors":["Roberto Marani","Annalisa Milella","Antonio Petitti","Giulio Reina"],"meta":["April 2021Precision Agriculture 22(6)","DOI:10.1007/s11119-020-09736-0"],"references":["337095005_Deep_Learning_Techniques_for_Grape_Plant_Species_Identification_in_Natural_Images","334305860_Deep_learning_for_in-field_image-based_grapevine_downy_mildew_identification","333225582_In_Vino_Veritas_Estimating_Vineyard_Grape_Yield_from_Images_Using_Deep_Learning","332099654_Color-_depth-_and_shape-based_3D_fruit_detection","331986420_In_Vino_Veritas_Estimating_Vineyard_Grape_Yield_from_Images_Using_Deep_Learning","331423658_Deep_learning_for_real-time_fruit_detection_and_orchard_fruit_load_estimation_benchmarking_of_'MangoYOLO'","328665003_LiDAR-only_based_navigation_algorithm_for_an_autonomous_agricultural_robot","338513354_Generalized_Intersection_Over_Union_A_Metric_and_a_Loss_for_Bounding_Box_Regression","334306346_Deep_learning-based_image_segmentation_for_grape_bunch_detection","330057489_In-field_high_throughput_grapevine_phenotyping_with_a_consumer-grade_depth_camera"]}