{"id":"338413762_A_novel_non-linear_modifier_for_adaptive_illumination_normalization_for_robust_face_recognition","abstract":"In this paper, a novel approach is presented for adaptive illumination normalization for face recognition under varying illuminations due to change in angle of light projection. Illumination normalization is performed over some of the low frequency discrete Cosine transform (DCT) coefficients which are computed adaptively based upon the significance of alteration of these coefficients. These are, then, modified using a non-linear modifier. The significance of the proposed approach is that the approach is adaptive in normalizing the illumination from the face images as the number of low frequency DCT coefficients that need to be modified using non-linear modifier are selected on the basis of variations of illumination present in the image. This variation in the illumination is also used in developing the non-linear modifier. The proposed approach is important in such a way that the level of illumination variations decides the computations needed i.e. lesser in comparison to the other existing state-of-art approaches as large number of frequency coefficients are not altered. The proposed approach is tested over various face databases: YALE B, Extended YALE B, CMU PIE, AR and YALE face database. The experimental results clearly reveal that the performance of the proposed approach is significantly better than the existing approaches of illumination normalization for face recognition. With the proposed approach, 100% accuracy is attained on all the subsets of YALE B, CMU PIE and on Subset 3 of Extended YALE B database. Promising results are achieved over remaining face databases as well.","authors":["Virendra P. Vishwakarma","Sahil Dalal"],"meta":["May 2020Multimedia Tools and Applications 79(6)","DOI:10.1007/s11042-019-08537-6","Project: Illumination Normalization in Face Recognition"],"references":["329263099_An_efficient_hybrid_DWT-fuzzy_filter_in_DCT_domain_based_illumination_normalization_for_face_recognition","317139636_Pose-and-illumination-invariant_face_representation_via_a_triplet-loss_trained_deep_reconstruction_model","317083802_Eigenfaces_vs_Fisherfaces_Recognition_Using_Class_Specific_Linear_Projection","334008319_STAT_Spatial-Temporal_Attention_Mechanism_for_Video_Captioning","331607987_Cross-Modality_Bridging_and_Knowledge_Transferring_for_Image_Understanding","326729247_A_new_illumination_normalization_framework_via_homomorphic_filtering_and_reflectance_ratio_in_DWT_domain_for_face_recognition","325964722_An_improved_hybrid_illumination_normalisation_and_feature_extraction_model_for_face_recognition","325732347_An_improved_hybrid_illumination_normalisation_and_feature_extraction_model_for_face_recognition","325236536_An_Effective_Uyghur_Text_Detector_for_Complex_Background_Images","320600769_Directional_Illumination_Estimation_Sets_and_Multi-Level_Matching_Metric_for_Illumination-Robust_Face_Recognition"]}