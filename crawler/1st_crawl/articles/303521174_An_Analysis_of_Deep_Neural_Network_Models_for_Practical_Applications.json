{"id":"303521174_An_Analysis_of_Deep_Neural_Network_Models_for_Practical_Applications","abstract":"Since the emergence of Deep Neural Networks (DNNs) as a prominent technique in the field of computer vision, the ImageNet classification challenge has played a major role in advancing the state-of-the-art. While accuracy figures have steadily increased, the resource utilization of winning models has not been properly taken into account. In this work, we present a comprehensive analysis of important metrics in practical applications: accuracy, memory footprint, parameters, operations count, inference time and power consumption. Key findings are: (1) fully connected layers are largely inefficient for smaller batches of images; (2) accuracy and inference time are in a hyperbolic relationship; (3) energy constraint are an upper bound on the maximum achievable accuracy and model complexity; (4) the number of operations is a reliable estimate of the inference time. We believe our analysis provides a compelling set of information that help design and engineer efficient DNNs.","authors":["Alfredo Canziani","Adam Paszke","Eugenio Culurciello"],"meta":["May 2016"],"references":["266560893_cuDNN_Efficient_Primitives_for_Deep_Learning","265787949_Going_Deeper_with_Convolutions","265295439_ImageNet_Large_Scale_Visual_Recognition_Challenge","319770411_Torch7_A_Matlab-like_Environment_for_Machine_Learning","311609041_Deep_Residual_Learning_for_Image_Recognition","306281834_Rethinking_the_Inception_Architecture_for_Computer_Vision","286512696_Deep_Residual_Learning_for_Image_Recognition","285648386_Rethinking_the_Inception_Architecture_for_Computer_Vision","267960550_ImageNet_Classification_with_Deep_Convolutional_Neural_Networks","265385906_Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition","264890087_Torch7_A_Matlab-like_Environment_for_Machine_Learning"]}