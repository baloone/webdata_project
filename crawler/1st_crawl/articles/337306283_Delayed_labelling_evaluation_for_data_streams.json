{"id":"337306283_Delayed_labelling_evaluation_for_data_streams","abstract":"A large portion of the stream mining studies on classification rely on the availability of true labels immediately after making predictions. This approach is well exemplified by the test-then-train evaluation, where predictions immediately precede true label arrival. However, in many real scenarios, labels arrive with non-negligible latency. This raises the question of how to evaluate classifiers trained in such circumstances. This question is of particular importance when stream mining models are expected to refine their predictions between acquiring instance data and receiving its true label. In this work, we propose a novel evaluation methodology for data streams when verification latency takes place, namely continuous re-evaluation. It is applied to reference data streams and it is used to differentiate between stream mining techniques in terms of their ability to refine predictions based on newly arriving instances. Our study points out, discusses and shows empirically the importance of considering the delay of instance labels when evaluating classifiers for data streams.","authors":["Maciej Grzenda","Heitor Murilo Gomes","Albert Bifet"],"meta":["September 2020Data Mining and Knowledge Discovery 34(1)","DOI:10.1007/s10618-019-00654-y","Project: MOA (Massive Online Analytics) Open Source Software"],"references":["329397374_Adaptive_random_forests_for_data_stream_regression","317579226_Adaptive_random_forests_for_evolving_data_stream_classification","300414739_Classification_of_Evolving_Data_Streams_with_Infinitely_Delayed_Labels","299970682_Efficient_Online_Evaluation_of_Big_Data_Stream_Classifiers","282907128_Learning_in_Nonstationary_Environments_A_Survey","327606791_Classification_And_Regression_Trees","313524724_Database_mining_A_performance_perspective","313450101_Handling_delayed_labels_in_temporally_evolving_data_streams","297613383_Adaptive_Model_Rules_from_Data_Streams","288906520_Random_forests"]}