{"id":"326487822_XNOR_Neural_Engine_a_Hardware_Accelerator_IP_for_216_fJop_Binary_Neural_Network_Inference","abstract":"Binary Neural Networks (BNNs) are promising to deliver accuracy comparable to conventional deep neural networks at a fraction of the cost in terms of memory and energy. In this paper, we introduce the XNOR Neural Engine (XNE), a fully digital configurable hardware accelerator IP for BNNs, integrated within a microcontroller unit (MCU) equipped with an autonomous I/O subsystem and hybrid SRAM / standard cell memory. The XNE is able to fully compute convolutional and dense layers in autonomy or in cooperation with the core in the MCU to realize more complex behaviors. We show post-synthesis results in 65nm and 22nm technology for the XNE IP and post-layout results in 22nm for the full MCU indicating that this system can drop the energy cost per binary operation to 21.6fJ per operation at 0.4V, and at the same time is flexible and performant enough to execute state-of-the-art BNN topologies such as ResNet-34 in less than 2.2mJ per frame at 8.9 fps.","authors":["Francesco Conti","Pasquale Davide Schiavone","Luca Benini"],"meta":["July 2018IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems PP(99):1-1","DOI:10.1109/TCAD.2018.2857019"],"references":["325635451_XNORBIN_A_95_TOpsW_hardware_accelerator_for_binary_convolutional_neural_networks","324959130_Design_Automation_for_Binarized_Neural_Networks_A_Quantum_Leap_Opportunity","322608787_DroNet_Learning_to_Fly_by_Driving","321930684_BRein_Memory_A_Single-Chip_BinaryTernary_Reconfigurable_in-Memory_Deep_Neural_Network_Accelerator_Achieving_14_TOPS_at_06_W","326642432_Always-ON_visual_node_with_a_hardware-software_event-based_binarized_neural_network_inference_engine","324645788_Minimum_energy_quantized_neural_networks","323822352_An_always-on_38mJ86_CIFAR-10_mixed-signal_binary_CNN_processor_with_all_memory_on_chip_in_28nm_CMOS","323820505_Conv-RAM_An_energy-efficient_SRAM_with_embedded_convolution_computation_for_low-power_CNN-based_machine_learning_applications","323820181_UNPU_A_506TOPSW_unified_deep_neural_network_accelerator_with_1b-to-16b_fully-variable_weight_bit-precision","323818005_A_65nm_4Kb_algorithm-dependent_computing-in-memory_SRAM_unit-macro_with_23ns_and_558TOPSW_fully_parallel_product-sum_operation_for_binary_DNN_edge_processors"]}