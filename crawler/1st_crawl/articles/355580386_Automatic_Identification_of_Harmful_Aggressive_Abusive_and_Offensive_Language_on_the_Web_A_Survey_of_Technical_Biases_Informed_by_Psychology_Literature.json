{"id":"355580386_Automatic_Identification_of_Harmful_Aggressive_Abusive_and_Offensive_Language_on_the_Web_A_Survey_of_Technical_Biases_Informed_by_Psychology_Literature","abstract":"The automatic detection of conflictual languages (harmful, aggressive, abusive, and offensive languages) is essential to provide a healthy conversation environment on the Web. To design and develop detection systems that are capable of achieving satisfactory performance, a thorough understanding of the nature and properties of the targeted type of conflictual language is of great importance. The scientific communities investigating human psychology and social behavior have studied these languages in details, but their insights have only partially reached the computer science community.\nIn this survey, we aim both at systematically characterizing the conceptual properties of online conflictual languages, and at investigating the extent to which they are reflected in state-of-the-art automatic detection systems. Through an analysis of psychology literature, we provide a reconciled taxonomy that denotes the ensemble of conflictual languages typically studied in computer science. We then characterize the conceptual mismatches that can be observed in the main semantic and contextual properties of these languages and their treatment in computer science works; and systematically uncover resulting technical biases in the design of machine learning classification models and the dataset created for their training. Finally, we discuss diverse research opportunities for the computer science community and reflect on broader technical and structural issues.","authors":["Agathe Balayn","Jie Yang","Zoltán Szlávik","Alessandro Bozzon"],"meta":["September 2021ACM Transactions on Social Computing 4(3):1-56","DOI:10.1145/3479158"],"references":["356181052_Data_and_its_discontents_A_survey_of_dataset_development_and_use_in_machine_learning_research","352224617_Excavating_AI_the_politics_of_images_in_machine_learning_training_sets","352112242_What_do_You_Mean_Interpreting_Image_Classification_with_Crowdsourced_Concept_Extraction_and_Analysis","350745102_Demographic_Word_Embeddings_for_Racism_Detection_on_Twitter","350658863_Internet_social_media_and_online_hate_speech_Systematic_review","348703844_Racism_Hate_Speech_and_Social_Media_A_Systematic_Review_and_Critique","348183591_Arabic_Offensive_Language_Detection_with_Attention-based_Deep_Neural_Networks","345354339_Detecting_weak_and_strong_Islamophobic_hate_speech_on_social_media","345102058_Resources_and_benchmark_corpora_for_hate_speech_detection_a_systematic_review","346473597_The_Harm_in_Hate_Speech","344722263_SemEval-2019_Task_5_Multilingual_Detection_of_Hate_Speech_Against_Immigrants_and_Women_in_Twitter","343923967_Hate_speech_detection_and_racial_bias_mitigation_in_social_media_based_on_BERT_model","343303469_Contextualizing_Hate_Speech_Classifiers_with_Post-hoc_Explanation","344722265_STUFIIT_at_SemEval-2019_Task_5_Multilingual_Hate_Speech_Detection_on_Twitter_with_MUSE_and_ELMo_Embeddings","343302513_Toxicity_Detection_Does_Context_Really_Matter"]}