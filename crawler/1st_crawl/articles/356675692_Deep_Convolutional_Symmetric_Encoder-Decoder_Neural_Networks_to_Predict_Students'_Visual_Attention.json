{"id":"356675692_Deep_Convolutional_Symmetric_Encoder-Decoder_Neural_Networks_to_Predict_Students'_Visual_Attention","abstract":"Prediction of visual attention is a new and challenging subject, and to the best of our knowledge, there are not many pieces of research devoted to the anticipation of students’ cognition when solving tests. The aim of this paper is to propose, implement, and evaluate a machine learning method that is capable of predicting saliency maps of students who participate in a learning task in the form of quizzes based on quiz questionnaire images. Our proposal utilizes several deep encoder–decoder symmetric schemas which are trained on a large set of saliency maps generated with eye tracking technology. Eye tracking data were acquired from students, who solved various tasks in the sciences and natural sciences (computer science, mathematics, physics, and biology). The proposed deep convolutional encoder–decoder network is capable of producing accurate predictions of students’ visual attention when solving quizzes. Our evaluation showed that predictions are moderately positively correlated with actual data with a coefficient of 0.547 ± 0.109. It achieved better results in terms of correlation with real saliency maps than state-of-the-art methods. Visual analyses of the saliency maps obtained also correspond with our experience and expectations in this field. Both source codes and data from our research can be downloaded in order to reproduce our results.","authors":["Tomasz Hachaj","Anna Stolińska","Magdalena Andrzejewska","P. Czerski"],"meta":["November 2021Symmetry 13(12):2246","DOI:10.3390/sym13122246"],"references":["341474619_Classification_of_Students'_Conceptual_Understanding_in_STEM_Education_using_Their_Visual_Attention_Distributions_A_Comparison_of_Three_Machine-Learning_Approaches","340934497_Eye-tracking_and_artificial_intelligence_to_enhance_motivation_and_learning","339055546_Applying_Machine_Learning_in_Science_Assessment_A_Systematic_Review","354823456_The_Predictive_Power_of_Eye-Tracking_Data_in_an_Interactive_AR_Learning_Environment","352935045_Using_Eye_Tracking_for_Research_on_Learning_and_Computational_Thinking","346834249_Classification_of_Learning_Styles_in_Multimedia_Learning_Using_Eye-Tracking_and_Machine_Learning","346347412_Early_Prediction_of_Visitor_Engagement_in_Science_Museums_with_Multimodal_Learning_Analytics","345873816_Eye_tracking_algorithms_techniques_tools_and_applications_with_an_emphasis_on_machine_learning_and_Internet_of_Things_technologies","339903835_CPSX_Using_AI-Machine_Learning_for_Mapping_Human-Human_Interaction_and_Measurement_of_CPS_Teamwork_Skills","338676483_Mobile_Eye-tracking_for_Research_in_Diverse_Educational_Settings","338174486_The_use_of_eye_tracking_technology_to_explore_learning_and_performance_within_virtual_reality_and_mixed_reality_settings_a_scoping_review","333500321_Deep_learning_investigation_for_chess_player_attention_prediction_using_eye-tracking_and_game_data","332773343_Visual_Analysis_Method_of_Online_Learning_Path_Based_on_Eye_Tracking_Data","332732341_Gaze_Information_Channel_in_Cognitive_Comprehension_of_Poster_Reading","335782267_Eye_tracking_-_The_overlooked_method_to_measure_cognition_in_neurodegeneration"]}