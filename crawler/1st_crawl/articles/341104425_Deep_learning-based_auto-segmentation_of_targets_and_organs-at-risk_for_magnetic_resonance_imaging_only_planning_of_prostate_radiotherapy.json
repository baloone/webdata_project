{"id":"341104425_Deep_learning-based_auto-segmentation_of_targets_and_organs-at-risk_for_magnetic_resonance_imaging_only_planning_of_prostate_radiotherapy","abstract":"Background and purpose: \nMagnetic resonance (MR) only radiation therapy for prostate treatment provides superior contrast for defining targets and organs-at-risk (OARs). This study aims to develop a deep learning model to leverage this advantage to automate the contouring process.\n\nMaterials and methods: \nSix structures (bladder, rectum, urethra, penile bulb, rectal spacer, prostate and seminal vesicles) were contoured and reviewed by a radiation oncologist on axial T2-weighted MR image sets from 50 patients, which constituted expert delineations. The data was split into a 40/10 training and validation set to train a two-dimensional fully convolutional neural network, DeepLabV3+, using transfer learning. The T2-weighted image sets were pre-processed to 2D false color images to leverage pre-trained (from natural images) convolutional layers' weights. Independent testing was performed on an additional 50 patient's MR scans. Performance comparison was done against a U-Net deep learning method. Algorithms were evaluated using volumetric Dice similarity coefficient (VDSC) and surface Dice similarity coefficient (SDSC).\n\nResults: \nWhen comparing VDSC, DeepLabV3+ significantly outperformed U-Net for all structures except urethra (P < 0.001). Average VDSC was 0.93 ± 0.04 (bladder), 0.83 ± 0.06 (prostate and seminal vesicles [CTV]), 0.74 ± 0.13 (penile bulb), 0.82 ± 0.05 (rectum), 0.69 ± 0.10 (urethra), and 0.81 ± 0.1 (rectal spacer). Average SDSC was 0.92 ± 0.1 (bladder), 0.85 ± 0.11 (prostate and seminal vesicles [CTV]), 0.80 ± 0.22 (penile bulb), 0.87 ± 0.07 (rectum), 0.85 ± 0.25 (urethra), and 0.83 ± 0.26 (rectal spacer).\n\nConclusion: \nA deep learning-based model produced contours that show promise to streamline an MR-only planning workflow in treating prostate cancer.","authors":["Sharif Elguindi","Michael J Zelefsky","Jue Jiang","Harini Veeraraghavan"],"meta":["October 2019Physics and Imaging in Radiation Oncology 12:80-86","DOI:10.1016/j.phro.2019.11.006"],"references":["328362440_Multi-region_segmentation_of_bladder_cancer_structures_in_MRI_with_progressive_dilated_convolutional_networks","327645591_Deep_learning_to_achieve_clinically_applicable_segmentation_of_head_and_neck_anatomy_for_radiotherapy","323302730_Recurrent_Residual_Convolutional_Neural_Network_based_on_U-Net_R2U-Net_for_Medical_Image_Segmentation","321945039_Deep_Deconvolutional_Neural_Network_for_Target_Segmentation_of_Nasopharyngeal_Cancer_in_Planning_Computed_Tomography_Images","319462000_Transfer_Learning_for_Domain_Adaptation_in_MRI_Application_in_Brain_Lesion_Segmentation","318574088_Clinical_workflow_for_MR-only_simulation_and_planning_in_prostate","328173797_Deep-learning-based_detection_and_segmentation_of_organs_at_risk_in_nasopharyngeal_carcinoma_computed_tomographic_images_for_radiotherapy_planning","327977510_A_novel_MRI_Segmentation_method_using_CNN_based_Correction_Network_for_MRI_Guided_Adaptive_Radiotherapy","323027025_Encoder-Decoder_with_Atrous_Separable_Convolution_for_Semantic_Image_Segmentation","320968382_Xception_Deep_Learning_with_Depthwise_Separable_Convolutions"]}