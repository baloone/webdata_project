{"id":"343961576_Development_and_Validation_of_the_Computational_Thinking_Concepts_and_Skills_Test","abstract":"Calls for standardized and validated measures of computational thinking have been made repeatedly in recent years. Still, few such tests have been created and even fewer have undergone rigorous psychometric evaluation and been made available to researchers. The purpose of this study is to report our work in developing and validating a test of computational thinking concepts and skills and to compare different scoring methods for the test. This computational thinking exam is intended to be used in computing education research as a common measure of computational thinking so that the research community will be able to make more meaningful comparisons across samples and studies. The Computational Thinking Concepts and Skills Test (CTCAST) was administered to students in several courses, evaluated and revised, and then administered to another group of students. Part of the revision included changing half of the items to a multiple-select format. The test scores using the three scoring methods were compared to each other and to scores on a different test of core computer science knowledge. Results indicate the CTCAST and the test of core computer science knowledge measure similar, but not identical, aspects of studentsâ€™ knowledge and skills, and that item level statistics vary according to the scoring method that is used. Recommendations for using and scoring the test are presented.","authors":["Markeya S. Peteranetz","Patrick M. Morrow","Leen-Kiat Soh"],"meta":["March 2020"],"references":["321414660_Multiple_true-false_items_a_comparison_of_scoring_algorithms","317013386_Exploring_Bebras_Tasks_Content_and_Performance_A_Multinational_Study","310818888_Replication_Validation_and_Use_of_a_Language_Independent_CS1_Knowledge_Assessment","290391277_COMPUTATIONAL_THINKING_TEST_DESIGN_GUIDELINES_AND_CONTENT_VALIDATION","274309848_Computational_Thinking","262256455_First_year_student_performance_in_a_test_for_computational_thinking","331299910_How_Many_Abilities_Can_We_Measure_in_Computational_Thinking_A_Study_on_Bebras_Challenge","308654282_Which_cognitive_abilities_underlie_computational_thinking_Criterion_validity_of_the_Computational_Thinking_Test","269936324_Motivational_and_Self-Regulated_Learning_Profiles_of_Students_Taking_a_Foundational_Engineering_Course","257604859_Profiles_of_Motivated_Self-Regulation_in_College_Computer_Science_Courses_Differences_in_Major_versus_Required_Non-Major_Courses","234002937_Information_value_of_Multiple_Response_questions","221536990_Developing_a_validated_assessment_of_fundamental_CS1_concepts","247728098_Multiple-Mark_Items_An_Alternative_Objective_Item_Format","247672040_Multiple_True-False_Items_A_Study_of_Interitem_Correlations_Scoring_Alternatives_and_Reliability_Estimation","240278584_A_Brief_Report_on_a_Comparison_of_Six_Scoring_Methods_for_Multiple_True-False_Items"]}