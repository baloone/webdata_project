{"id":"326381130_Using_Word_Embeddings_to_Retrieve_Semantically_Similar_Questions_in_Community_Question_Answering","abstract":"This paper focuses on question retrieval which is a crucial and tricky task in Community Question Answering (cQA). Question retrieval aims at finding historical questions that are semantically equivalent to the queried ones, assuming that the answers to the similar questions should also answer the new ones. The major challenges are the lexical gap problem as well as the verboseness in natural language. Most existing methods measure the similarity between questions based on the bag-of-words (BOWs) representation capturing no semantics between words. In this paper, we rely on word embeddings and TF-IDF for a meaningful vector representation of the questions. The similarity between questions is measured using cosine similarity based on their vector-based word representations. Experiments carried out on a real world data set from Yahoo! Answers show that our method is competetive.","authors":["Nouha Othman","Rim Faiz","Kamel Sma√Øli"],"meta":["May 2018","Project: ICNLSSP2017"],"references":["317040087_SemEval-2017_Task_3_Community_Question_Answering","309021705_Learning_Word_Embeddings_from_Wikipedia_for_Content-Based_Recommender_Systems","266201822_Natural_Language_Processing_Almost_from_Scratch","304562048_Representation_learning_for_very_short_texts_using_weighted_word_embedding_aggregation","303802749_Indexing_by_Latent_Semantic_Analysis","288904802_Learning_Continuous_Word_Embedding_with_Metadata_for_Question_Retrieval_in_Community_Question_Answering","284546072_Capturing_the_Semantics_of_Key_Phrases_Using_Multiple_Languages_for_Question_Retrieval","284346745_Question_Retrieval_with_High_Quality_Answers_in_Community_Question_Answering","283769321_Improving_question_retrieval_in_community_question_answering_using_world_knowledge","270877751_Latent_Semantic_Tensor_Indexing_for_Community-based_Question_Answering"]}