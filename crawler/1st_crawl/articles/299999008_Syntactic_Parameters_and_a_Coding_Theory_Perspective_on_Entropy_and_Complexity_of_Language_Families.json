{"id":"299999008_Syntactic_Parameters_and_a_Coding_Theory_Perspective_on_Entropy_and_Complexity_of_Language_Families","abstract":"We present a simple computational approach to assigning a measure of complexity and information/entropy to families of natural languages, based on syntactic parameters and the theory of error correcting codes. We associate to each language a binary string of syntactic parameters and to a language family a binary code, with code words the binary string associated to each language. We then evaluate the code parameters (rate and relative minimum distance) and the position of the parameters with respect to the asymptotic bound of error correcting codes and the Gilbertâ€“Varshamov bound. These bounds are, respectively, related to the Kolmogorov complexity and the Shannon entropy of the code and this gives us a computationally simple way to obtain estimates on the complexity and information, not of individual languages but of language families. This notion of complexity is related, from the linguistic point of view to the degree of variability of syntactic parameter across languages belonging to the same (historical) family.","authors":["Matilde Marcolli"],"meta":["April 2016Entropy 18(4):110","DOI:10.3390/e18040110"],"references":["319393405_An_Introduction_to_Kolmogorov_Complexity_and_Its_Applications","322622477_Information_measures_effective_complexity_and_total_information","316823954_A_Course_in_Mathematical_Logic_for_Mathematicians","316805467_An_Introduction_to_Kolmogorov_Complexity_and_Its_Applications","305186150_Syntactic_Phylogenetic_Trees","283117600_Prevalence_and_recoverability_of_syntactic_parameters_in_sparse_distributed_memories","278769696_Complexite_aleatoire_et_complexite_organisee","266920593_Algebraic-geometric_codes_Transl_from_the_Russian","262638411_Toward_a_syntactic_phylogeny_of_modern_Indo-European_languages","251204415_Language_Complexity_as_an_Evolving_Variable"]}